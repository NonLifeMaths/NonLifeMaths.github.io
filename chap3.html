<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Pure Premium | Non Life Insurance Mathematics</title>
  <meta name="description" content="Chapter 4 Pure Premium | Non Life Insurance Mathematics" />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Pure Premium | Non Life Insurance Mathematics" />
  <meta property="og:type" content="book" />
  
  
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Pure Premium | Non Life Insurance Mathematics" />
  
  
  

<meta name="author" content="Arthur Charpentier and Michel Denuit" />


<meta name="date" content="2023-08-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chap2.html"/>
<link rel="next" href="chap4.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Non Life Insurance Mathematics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="chap1.html"><a href="chap1.html"><i class="fa fa-check"></i><b>2</b> The risk and its contractual coverage</a>
<ul>
<li class="chapter" data-level="2.1" data-path="chap1.html"><a href="chap1.html#risk"><i class="fa fa-check"></i><b>2.1</b> Risk</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="chap1.html"><a href="chap1.html#did-you-say-risk"><i class="fa fa-check"></i><b>2.1.1</b> Did you say risk?</a></li>
<li class="chapter" data-level="2.1.2" data-path="chap1.html"><a href="chap1.html#the-reason-for-insurance-risquophobia"><i class="fa fa-check"></i><b>2.1.2</b> The reason for insurance: risquophobia</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="chap1.html"><a href="chap1.html#risk-management-methods"><i class="fa fa-check"></i><b>2.2</b> Risk management methods</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="chap1.html"><a href="chap1.html#caution-and-self-insurance"><i class="fa fa-check"></i><b>2.2.1</b> Caution and self-insurance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chap2.html"><a href="chap2.html"><i class="fa fa-check"></i><b>3</b> Actuarial risk modeling</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chap2.html"><a href="chap2.html#introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="chap2.html"><a href="chap2.html#probabilistic-description-of-risk"><i class="fa fa-check"></i><b>3.2</b> Probabilistic description of risk</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="chap2.html"><a href="chap2.html#events"><i class="fa fa-check"></i><b>3.2.1</b> Events</a></li>
<li class="chapter" data-level="3.2.2" data-path="chap2.html"><a href="chap2.html#elementary-events"><i class="fa fa-check"></i><b>3.2.2</b> Elementary events</a></li>
<li class="chapter" data-level="3.2.3" data-path="chap2.html"><a href="chap2.html#set-formalism"><i class="fa fa-check"></i><b>3.2.3</b> Set formalism</a></li>
<li class="chapter" data-level="3.2.4" data-path="chap2.html"><a href="chap2.html#properties-satisfied-by-the-set-of-events"><i class="fa fa-check"></i><b>3.2.4</b> Properties satisfied by the set of events</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="chap2.html"><a href="chap2.html#probability-calculation-and-lack-of-arbitrage-opportunity"><i class="fa fa-check"></i><b>3.3</b> Probability calculation and lack of arbitrage opportunity</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="chap2.html"><a href="chap2.html#the-notion-of-probability"><i class="fa fa-check"></i><b>3.3.1</b> The notion of probability</a></li>
<li class="chapter" data-level="3.3.2" data-path="chap2.html"><a href="chap2.html#risk-and-uncertainty"><i class="fa fa-check"></i><b>3.3.2</b> Risk and uncertainty</a></li>
<li class="chapter" data-level="3.3.3" data-path="chap2.html"><a href="chap2.html#probability-and-insurance-premium"><i class="fa fa-check"></i><b>3.3.3</b> Probability and insurance premium</a></li>
<li class="chapter" data-level="3.3.4" data-path="chap2.html"><a href="chap2.html#absence-of-arbitrage-opportunity"><i class="fa fa-check"></i><b>3.3.4</b> Absence of arbitrage opportunity</a></li>
<li class="chapter" data-level="3.3.5" data-path="chap2.html"><a href="chap2.html#property-of-additivity-for-incompatible-events"><i class="fa fa-check"></i><b>3.3.5</b> Property of additivity for incompatible events</a></li>
<li class="chapter" data-level="3.3.6" data-path="chap2.html"><a href="chap2.html#premiums-grow-with-risk"><i class="fa fa-check"></i><b>3.3.6</b> Premiums grow with risk</a></li>
<li class="chapter" data-level="3.3.7" data-path="chap2.html"><a href="chap2.html#fairness-property"><i class="fa fa-check"></i><b>3.3.7</b> Fairness property</a></li>
<li class="chapter" data-level="3.3.8" data-path="chap2.html"><a href="chap2.html#subadditivity-property"><i class="fa fa-check"></i><b>3.3.8</b> Subadditivity property</a></li>
<li class="chapter" data-level="3.3.9" data-path="chap2.html"><a href="chap2.html#poincaré-equality"><i class="fa fa-check"></i><b>3.3.9</b> Poincaré equality</a></li>
<li class="chapter" data-level="3.3.10" data-path="chap2.html"><a href="chap2.html#conditional-probability"><i class="fa fa-check"></i><b>3.3.10</b> Conditional probability</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="chap2.html"><a href="chap2.html#independent-events"><i class="fa fa-check"></i><b>3.4</b> Independent events</a></li>
<li class="chapter" data-level="3.5" data-path="chap2.html"><a href="chap2.html#multiplication-rule-bayes"><i class="fa fa-check"></i><b>3.5</b> Multiplication rule (Bayes)</a></li>
<li class="chapter" data-level="3.6" data-path="chap2.html"><a href="chap2.html#conditionally-independent-events"><i class="fa fa-check"></i><b>3.6</b> Conditionally independent events</a></li>
<li class="chapter" data-level="3.7" data-path="chap2.html"><a href="chap2.html#total-probability-theorem"><i class="fa fa-check"></i><b>3.7</b> Total probability theorem</a></li>
<li class="chapter" data-level="3.8" data-path="chap2.html"><a href="chap2.html#bayes-theorem"><i class="fa fa-check"></i><b>3.8</b> Bayes’ theorem</a></li>
<li class="chapter" data-level="3.9" data-path="chap2.html"><a href="chap2.html#random-variables"><i class="fa fa-check"></i><b>3.9</b> Random variables</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="chap2.html"><a href="chap2.html#definition"><i class="fa fa-check"></i><b>3.9.1</b> Definition</a></li>
<li class="chapter" data-level="3.9.2" data-path="chap2.html"><a href="chap2.html#distribution-function"><i class="fa fa-check"></i><b>3.9.2</b> Distribution function</a></li>
<li class="chapter" data-level="3.9.3" data-path="chap2.html"><a href="chap2.html#support-of-a-random-variable"><i class="fa fa-check"></i><b>3.9.3</b> Support of a random variable</a></li>
<li class="chapter" data-level="3.9.4" data-path="chap2.html"><a href="chap2.html#tail-or-survival-function"><i class="fa fa-check"></i><b>3.9.4</b> Tail (or Survival) function</a></li>
<li class="chapter" data-level="3.9.5" data-path="chap2.html"><a href="chap2.html#equality-in-distribution"><i class="fa fa-check"></i><b>3.9.5</b> Equality in distribution</a></li>
<li class="chapter" data-level="3.9.6" data-path="chap2.html"><a href="chap2.html#quantiles-and-generalized-inverses"><i class="fa fa-check"></i><b>3.9.6</b> Quantiles and generalized inverses</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="chap2.html"><a href="chap2.html#discrete-random-variables-and-counts"><i class="fa fa-check"></i><b>3.10</b> Discrete random variables and counts</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="chap2.html"><a href="chap2.html#notion"><i class="fa fa-check"></i><b>3.10.1</b> Notion</a></li>
<li class="chapter" data-level="3.10.2" data-path="chap2.html"><a href="chap2.html#uniform-discrete-variable"><i class="fa fa-check"></i><b>3.10.2</b> Uniform discrete variable</a></li>
<li class="chapter" data-level="3.10.3" data-path="chap2.html"><a href="chap2.html#bernoulli-variables"><i class="fa fa-check"></i><b>3.10.3</b> Bernoulli variables</a></li>
<li class="chapter" data-level="3.10.4" data-path="chap2.html"><a href="chap2.html#binomial-variable"><i class="fa fa-check"></i><b>3.10.4</b> Binomial variable</a></li>
<li class="chapter" data-level="3.10.5" data-path="chap2.html"><a href="chap2.html#geometric-variable"><i class="fa fa-check"></i><b>3.10.5</b> Geometric variable</a></li>
<li class="chapter" data-level="3.10.6" data-path="chap2.html"><a href="chap2.html#negative-binomial-variable"><i class="fa fa-check"></i><b>3.10.6</b> Negative binomial variable</a></li>
<li class="chapter" data-level="3.10.7" data-path="chap2.html"><a href="chap2.html#poissons-distribution"><i class="fa fa-check"></i><b>3.10.7</b> Poisson’s distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="chap2.html"><a href="chap2.html#continuous-random-variables"><i class="fa fa-check"></i><b>3.11</b> Continuous random variables</a>
<ul>
<li class="chapter" data-level="3.11.1" data-path="chap2.html"><a href="chap2.html#notion-1"><i class="fa fa-check"></i><b>3.11.1</b> Notion</a></li>
<li class="chapter" data-level="3.11.2" data-path="chap2.html"><a href="chap2.html#continuous-uniform-distribution"><i class="fa fa-check"></i><b>3.11.2</b> Continuous uniform distribution</a></li>
<li class="chapter" data-level="3.11.3" data-path="chap2.html"><a href="chap2.html#beta-distribution"><i class="fa fa-check"></i><b>3.11.3</b> Beta Distribution</a></li>
<li class="chapter" data-level="3.11.4" data-path="chap2.html"><a href="chap2.html#normal-or-gaussian-distribution"><i class="fa fa-check"></i><b>3.11.4</b> Normal (or Gaussian) distribution</a></li>
<li class="chapter" data-level="3.11.5" data-path="chap2.html"><a href="chap2.html#log-normal-variable"><i class="fa fa-check"></i><b>3.11.5</b> Log-normal variable</a></li>
<li class="chapter" data-level="3.11.6" data-path="chap2.html"><a href="chap2.html#negative-exponential-distribution"><i class="fa fa-check"></i><b>3.11.6</b> (Negative) exponential distribution</a></li>
<li class="chapter" data-level="3.11.7" data-path="chap2.html"><a href="chap2.html#gamma-distribution"><i class="fa fa-check"></i><b>3.11.7</b> Gamma distribution</a></li>
<li class="chapter" data-level="3.11.8" data-path="chap2.html"><a href="chap2.html#pareto-distribution"><i class="fa fa-check"></i><b>3.11.8</b> Pareto distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="chap2.html"><a href="chap2.html#random-vector"><i class="fa fa-check"></i><b>3.12</b> Random vector</a>
<ul>
<li class="chapter" data-level="3.12.1" data-path="chap2.html"><a href="chap2.html#definition-1"><i class="fa fa-check"></i><b>3.12.1</b> Definition</a></li>
<li class="chapter" data-level="3.12.2" data-path="chap2.html"><a href="chap2.html#distribution-function-1"><i class="fa fa-check"></i><b>3.12.2</b> Distribution function</a></li>
<li class="chapter" data-level="3.12.3" data-path="chap2.html"><a href="chap2.html#support-of-vector-xvec"><i class="fa fa-check"></i><b>3.12.3</b> Support of vector <span class="math inline">\(\Xvec\)</span></a></li>
<li class="chapter" data-level="3.12.4" data-path="chap2.html"><a href="chap2.html#independence"><i class="fa fa-check"></i><b>3.12.4</b> Independence</a></li>
<li class="chapter" data-level="3.12.5" data-path="chap2.html"><a href="chap2.html#gaussian-vector"><i class="fa fa-check"></i><b>3.12.5</b> Gaussian vector</a></li>
<li class="chapter" data-level="3.12.6" data-path="chap2.html"><a href="chap2.html#ellipticpart"><i class="fa fa-check"></i><b>3.12.6</b> Elliptical vectors</a></li>
<li class="chapter" data-level="3.12.7" data-path="chap2.html"><a href="chap2.html#definition-2"><i class="fa fa-check"></i><b>3.12.7</b> Definition</a></li>
<li class="chapter" data-level="3.12.8" data-path="chap2.html"><a href="chap2.html#multinomial-vector"><i class="fa fa-check"></i><b>3.12.8</b> Multinomial vector</a></li>
</ul></li>
<li class="chapter" data-level="3.13" data-path="chap2.html"><a href="chap2.html#conditional-variables"><i class="fa fa-check"></i><b>3.13</b> Conditional Variables</a>
<ul>
<li class="chapter" data-level="3.13.1" data-path="chap2.html"><a href="chap2.html#the-case-of-counting-variables"><i class="fa fa-check"></i><b>3.13.1</b> The case of counting variables</a></li>
<li class="chapter" data-level="3.13.2" data-path="chap2.html"><a href="chap2.html#the-case-of-continuous-variables"><i class="fa fa-check"></i><b>3.13.2</b> The case of continuous variables</a></li>
<li class="chapter" data-level="3.13.3" data-path="chap2.html"><a href="chap2.html#the-mixed-case-one-counting-variable-and-another-continuous"><i class="fa fa-check"></i><b>3.13.3</b> The mixed case: one counting variable and another continuous</a></li>
<li class="chapter" data-level="3.13.4" data-path="chap2.html"><a href="chap2.html#conditional-independence"><i class="fa fa-check"></i><b>3.13.4</b> Conditional independence</a></li>
</ul></li>
<li class="chapter" data-level="3.14" data-path="chap2.html"><a href="chap2.html#compound-distributions"><i class="fa fa-check"></i><b>3.14</b> Compound distributions</a>
<ul>
<li class="chapter" data-level="3.14.1" data-path="chap2.html"><a href="chap2.html#definition-4"><i class="fa fa-check"></i><b>3.14.1</b> Definition</a></li>
<li class="chapter" data-level="3.14.2" data-path="chap2.html"><a href="chap2.html#SecProdConv"><i class="fa fa-check"></i><b>3.14.2</b> Convolution product</a></li>
<li class="chapter" data-level="3.14.3" data-path="chap2.html"><a href="chap2.html#distribution-function-associated-with-a-compound-distribution"><i class="fa fa-check"></i><b>3.14.3</b> Distribution function associated with a compound distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.15" data-path="chap2.html"><a href="chap2.html#RiskTransformations"><i class="fa fa-check"></i><b>3.15</b> Transformations of risks and conventional damage clauses</a>
<ul>
<li class="chapter" data-level="3.15.1" data-path="chap2.html"><a href="chap2.html#concept"><i class="fa fa-check"></i><b>3.15.1</b> Concept</a></li>
<li class="chapter" data-level="3.15.2" data-path="chap2.html"><a href="chap2.html#DecOblig"><i class="fa fa-check"></i><b>3.15.2</b> The compulsory overdraft</a></li>
<li class="chapter" data-level="3.15.3" data-path="chap2.html"><a href="chap2.html#the-deductible"><i class="fa fa-check"></i><b>3.15.3</b> The deductible</a></li>
<li class="chapter" data-level="3.15.4" data-path="chap2.html"><a href="chap2.html#upper-limit-of-indemnity"><i class="fa fa-check"></i><b>3.15.4</b> (Upper) limit of indemnity</a></li>
<li class="chapter" data-level="3.15.5" data-path="chap2.html"><a href="chap2.html#technical-consequence-censored-data"><i class="fa fa-check"></i><b>3.15.5</b> Technical consequence: censored data</a></li>
<li class="chapter" data-level="3.15.6" data-path="chap2.html"><a href="chap2.html#poissons-distribution-and-damage-clauses"><i class="fa fa-check"></i><b>3.15.6</b> Poisson’s distribution and damage clauses</a></li>
<li class="chapter" data-level="3.15.7" data-path="chap2.html"><a href="chap2.html#perverse-effects-of-contractual-damage-clauses"><i class="fa fa-check"></i><b>3.15.7</b> Perverse effects of contractual damage clauses</a></li>
</ul></li>
<li class="chapter" data-level="3.16" data-path="chap2.html"><a href="chap2.html#exercises"><i class="fa fa-check"></i><b>3.16</b> Exercises</a></li>
<li class="chapter" data-level="3.17" data-path="chap2.html"><a href="chap2.html#bibliographical-notes"><i class="fa fa-check"></i><b>3.17</b> Bibliographical notes</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chap3.html"><a href="chap3.html"><i class="fa fa-check"></i><b>4</b> Pure Premium</a>
<ul>
<li class="chapter" data-level="4.1" data-path="chap3.html"><a href="chap3.html#introduction-1"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="chap3.html"><a href="chap3.html#pure-premium-and-mathematical-expectation"><i class="fa fa-check"></i><b>4.2</b> Pure Premium and Mathematical Expectation</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="chap3.html"><a href="chap3.html#mathematical-expectation"><i class="fa fa-check"></i><b>4.2.1</b> Mathematical Expectation</a></li>
<li class="chapter" data-level="4.2.2" data-path="chap3.html"><a href="chap3.html#probabilities-and-expectations-of-indicators"><i class="fa fa-check"></i><b>4.2.2</b> Probabilities and Expectations of Indicators</a></li>
<li class="chapter" data-level="4.2.3" data-path="chap3.html"><a href="chap3.html#determination-of-the-pure-premium"><i class="fa fa-check"></i><b>4.2.3</b> Determination of the Pure Premium</a></li>
<li class="chapter" data-level="4.2.4" data-path="chap3.html"><a href="chap3.html#mean-squared-error-is-it-a-must"><i class="fa fa-check"></i><b>4.2.4</b> Mean Squared Error, Is It a Must?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="chap3.html"><a href="chap3.html#variance"><i class="fa fa-check"></i><b>4.3</b> Variance</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="chap3.html"><a href="chap3.html#definition-5"><i class="fa fa-check"></i><b>4.3.1</b> Definition</a></li>
<li class="chapter" data-level="4.3.2" data-path="chap3.html"><a href="chap3.html#actuarial-interpretation"><i class="fa fa-check"></i><b>4.3.2</b> Actuarial Interpretation</a></li>
<li class="chapter" data-level="4.3.3" data-path="chap3.html"><a href="chap3.html#some-examples"><i class="fa fa-check"></i><b>4.3.3</b> Some Examples</a></li>
<li class="chapter" data-level="4.3.4" data-path="chap3.html"><a href="chap3.html#properties"><i class="fa fa-check"></i><b>4.3.4</b> Properties</a></li>
<li class="chapter" data-level="4.3.5" data-path="chap3.html"><a href="chap3.html#variance-of-common-distributions"><i class="fa fa-check"></i><b>4.3.5</b> Variance of Common Distributions</a></li>
<li class="chapter" data-level="4.3.6" data-path="chap3.html"><a href="chap3.html#variance-of-composite-distributions"><i class="fa fa-check"></i><b>4.3.6</b> Variance of Composite Distributions</a></li>
<li class="chapter" data-level="4.3.7" data-path="chap3.html"><a href="chap3.html#coefficient-of-variation-and-risk-pooling"><i class="fa fa-check"></i><b>4.3.7</b> Coefficient of Variation and Risk Pooling</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="chap3.html"><a href="chap3.html#insurance-and-bienaymé-chebyshev-inequality"><i class="fa fa-check"></i><b>4.4</b> Insurance and Bienaymé-Chebyshev Inequality</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="chap3.html"><a href="chap3.html#markovs-inequality"><i class="fa fa-check"></i><b>4.4.1</b> Markov’s Inequality</a></li>
<li class="chapter" data-level="4.4.2" data-path="chap3.html"><a href="chap3.html#bienaymé-chebyshev-inequality"><i class="fa fa-check"></i><b>4.4.2</b> Bienaymé-Chebyshev Inequality</a></li>
<li class="chapter" data-level="4.4.3" data-path="chap3.html"><a href="chap3.html#actuarial-interpretation-of-the-bienaymé-chebyshev-inequality"><i class="fa fa-check"></i><b>4.4.3</b> Actuarial Interpretation of the Bienaymé-Chebyshev Inequality</a></li>
<li class="chapter" data-level="4.4.4" data-path="chap3.html"><a href="chap3.html#conservative-nature-of-the-bienaymé-chebyshev-inequality"><i class="fa fa-check"></i><b>4.4.4</b> Conservative Nature of the Bienaymé-Chebyshev Inequality</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="chap3.html"><a href="chap3.html#insurance-and-law-of-large-numbers"><i class="fa fa-check"></i><b>4.5</b> Insurance and Law of Large Numbers</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="chap3.html"><a href="chap3.html#convergence-in-probability"><i class="fa fa-check"></i><b>4.5.1</b> Convergence in Probability</a></li>
<li class="chapter" data-level="4.5.2" data-path="chap3.html"><a href="chap3.html#convergence-of-average-claim-amount-per-policy-to-the-pure-premium"><i class="fa fa-check"></i><b>4.5.2</b> Convergence of Average Claim Amount per Policy to the Pure Premium</a></li>
<li class="chapter" data-level="4.5.3" data-path="chap3.html"><a href="chap3.html#case-of-flat-indemnity"><i class="fa fa-check"></i><b>4.5.3</b> Case of Flat Indemnity</a></li>
<li class="chapter" data-level="4.5.4" data-path="chap3.html"><a href="chap3.html#case-of-indemnity-compensation"><i class="fa fa-check"></i><b>4.5.4</b> Case of Indemnity Compensation</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="chap3.html"><a href="chap3.html#characteristic-functions"><i class="fa fa-check"></i><b>4.6</b> Characteristic Functions</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="chap3.html"><a href="chap3.html#probability-generating-function"><i class="fa fa-check"></i><b>4.6.1</b> Probability Generating Function</a></li>
<li class="chapter" data-level="4.6.2" data-path="chap3.html"><a href="chap3.html#laplace-transform"><i class="fa fa-check"></i><b>4.6.2</b> Laplace Transform</a></li>
<li class="chapter" data-level="4.6.3" data-path="chap3.html"><a href="chap3.html#moment-generating-function"><i class="fa fa-check"></i><b>4.6.3</b> Moment Generating Function</a></li>
<li class="chapter" data-level="4.6.4" data-path="chap3.html"><a href="chap3.html#hazard-rate"><i class="fa fa-check"></i><b>4.6.4</b> Hazard Rate</a></li>
<li class="chapter" data-level="4.6.5" data-path="chap3.html"><a href="chap3.html#stop-loss-premiums"><i class="fa fa-check"></i><b>4.6.5</b> Stop-Loss Premiums</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="chap3.html"><a href="chap3.html#Hetero"><i class="fa fa-check"></i><b>4.7</b> Heterogeneity and Mixtures</a></li>
<li class="chapter" data-level="4.8" data-path="chap3.html"><a href="chap3.html#context"><i class="fa fa-check"></i><b>4.8</b> Context</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="chap3.html"><a href="chap3.html#a-simple-example"><i class="fa fa-check"></i><b>4.8.1</b> A Simple Example…</a></li>
<li class="chapter" data-level="4.8.2" data-path="chap3.html"><a href="chap3.html#poisson-mixtures"><i class="fa fa-check"></i><b>4.8.2</b> Poisson Mixtures</a></li>
<li class="chapter" data-level="4.8.3" data-path="chap3.html"><a href="chap3.html#shakeds-theorem"><i class="fa fa-check"></i><b>4.8.3</b> Shaked’s Theorem</a></li>
<li class="chapter" data-level="4.8.4" data-path="chap3.html"><a href="chap3.html#composite-mixed-poisson-distributions"><i class="fa fa-check"></i><b>4.8.4</b> Composite Mixed Poisson Distributions</a></li>
<li class="chapter" data-level="4.8.5" data-path="chap3.html"><a href="chap3.html#exponential-mixtures"><i class="fa fa-check"></i><b>4.8.5</b> Exponential Mixtures</a></li>
<li class="chapter" data-level="4.8.6" data-path="chap3.html"><a href="chap3.html#identifiability-of-exponential-mixtures"><i class="fa fa-check"></i><b>4.8.6</b> Identifiability of Exponential Mixtures</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="chap3.html"><a href="chap3.html#pure-premium-in-segmented-universe"><i class="fa fa-check"></i><b>4.9</b> Pure Premium in Segmented Universe</a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="chap3.html"><a href="chap3.html#segmentation-techniques"><i class="fa fa-check"></i><b>4.9.1</b> Segmentation Techniques</a></li>
<li class="chapter" data-level="4.9.2" data-path="chap3.html"><a href="chap3.html#conditional-expectation"><i class="fa fa-check"></i><b>4.9.2</b> Conditional Expectation</a></li>
<li class="chapter" data-level="4.9.3" data-path="chap3.html"><a href="chap3.html#customization-of-premiums"><i class="fa fa-check"></i><b>4.9.3</b> Customization of Premiums</a></li>
<li class="chapter" data-level="4.9.4" data-path="chap3.html"><a href="chap3.html#segmentation-pooling-and-solidarity"><i class="fa fa-check"></i><b>4.9.4</b> Segmentation, Pooling, and Solidarity</a></li>
<li class="chapter" data-level="4.9.5" data-path="chap3.html"><a href="chap3.html#DeWit"><i class="fa fa-check"></i><b>4.9.5</b> Formalization of the Segmentation Concept</a></li>
<li class="chapter" data-level="4.9.6" data-path="chap3.html"><a href="chap3.html#drawbacks-resulting-from-extensive-segmentation"><i class="fa fa-check"></i><b>4.9.6</b> Drawbacks Resulting from Extensive Segmentation</a></li>
<li class="chapter" data-level="4.9.7" data-path="chap3.html"><a href="chap3.html#segmentation-and-information-asymmetry"><i class="fa fa-check"></i><b>4.9.7</b> Segmentation and Information Asymmetry</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="chap3.html"><a href="chap3.html#exercises-1"><i class="fa fa-check"></i><b>4.10</b> Exercises</a></li>
<li class="chapter" data-level="4.11" data-path="chap3.html"><a href="chap3.html#bibliographical-notes-1"><i class="fa fa-check"></i><b>4.11</b> Bibliographical notes</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chap4.html"><a href="chap4.html"><i class="fa fa-check"></i><b>5</b> Net Premium</a></li>
<li class="chapter" data-level="6" data-path="chap5.html"><a href="chap5.html"><i class="fa fa-check"></i><b>6</b> Measuring and Comparing Risks</a></li>
<li class="chapter" data-level="7" data-path="chap6.html"><a href="chap6.html"><i class="fa fa-check"></i><b>7</b> Collective Model</a></li>
<li class="chapter" data-level="8" data-path="chap7.html"><a href="chap7.html"><i class="fa fa-check"></i><b>8</b> Solvency</a></li>
<li class="chapter" data-level="9" data-path="chap8.html"><a href="chap8.html"><i class="fa fa-check"></i><b>9</b> Multiple Risks</a></li>
<li class="chapter" data-level="10" data-path="chap9.html"><a href="chap9.html"><i class="fa fa-check"></i><b>10</b> Prior Ratemaking</a></li>
<li class="chapter" data-level="11" data-path="chap10.html"><a href="chap10.html"><i class="fa fa-check"></i><b>11</b> Credibility</a></li>
<li class="chapter" data-level="12" data-path="chap11.html"><a href="chap11.html"><i class="fa fa-check"></i><b>12</b> Bonus-Malus</a></li>
<li class="chapter" data-level="13" data-path="chap12.html"><a href="chap12.html"><i class="fa fa-check"></i><b>13</b> Economics of Insurance</a></li>
<li class="chapter" data-level="14" data-path="chap13.html"><a href="chap13.html"><i class="fa fa-check"></i><b>14</b> Claims Reserving</a></li>
<li class="chapter" data-level="15" data-path="chap14.html"><a href="chap14.html"><i class="fa fa-check"></i><b>15</b> Large Risks</a></li>
<li class="chapter" data-level="16" data-path="chap15.html"><a href="chap15.html"><i class="fa fa-check"></i><b>16</b> Monte Carlo</a></li>
<li class="chapter" data-level="17" data-path="chap16.html"><a href="chap16.html"><i class="fa fa-check"></i><b>17</b> Conclusion</a></li>
<li class="chapter" data-level="" data-path="postface.html"><a href="postface.html"><i class="fa fa-check"></i>Postface</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Non Life Insurance Mathematics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chap3" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Chapter 4</span> Pure Premium<a href="chap3.html#chap3" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introduction-1" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Introduction<a href="chap3.html#introduction-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The pure premium represents the price of risk: it is the amount that the insurer must have to compensate (on average) policyholders for incurred claims, without surplus or deficit. The total pure premiums related to the portfolio must enable the insurer to fulfill its guarantee obligations. If the insurer wishes to retain profits (for example, to compensate shareholders or increase its capital), these will be added later. Hence, the pure premium is expected to be entirely used to compensate claims affecting policyholders: the entirety of the pure premium collected will thus be returned to policyholders in the form of indemnities.</p>
<p>The pure premium is calculated by considering various factors: the probability of occurrence or frequency of claims, the extent of losses, the insured amount, etc. In this work, we focus on insurance products with short-term and high-risk risks. This leads us to not explicitly model financial products, a simplification that has no consequence. This contrasts significantly with long-term and low-risk actuarial practices that characterize life insurance products. In such cases, explicit modeling of financial products is essential. In non-life insurance, neglecting financial products provides actuaries with an implicit safety margin.</p>
<p>The central concept justifying the existence of an insurance market is risk aversion or “risk-aversion.” This is the natural tendency of economic agents to avoid risk and protect themselves from the negative consequences of unforeseeable events. Of course, not everyone shares this sentiment, and those who do share it do not all do so to the same extent.</p>
<p>The formalization of the concept of risk aversion is quite difficult due to the diversity of human behavior. However, the concept of pure premium developed in this chapter allows for the objectification of risk aversion: an economic agent will now be considered risk-averse when they transfer all their risks to an insurer who charges them the pure premium. As we will see in the next chapter, the insurer is obliged to charge the insured a premium (sometimes significantly higher than the pure premium), which will explain a partial transfer of risks, even by risk-averse individuals.</p>
<div class="remark">
<p><span id="unlabeled-div-1" class="remark"><em>Remark</em>. </span>An economic agent is therefore considered risk-averse when faced with a choice between a random financial flow and a deterministic flow with the same mean, they will always prefer the latter. Thus, such a decision-maker will always prefer to receive €1 over the result of a coin toss game where they would win €2 if heads is obtained, and nothing otherwise. This formalization of risk aversion certainly has the advantage of objectivity and simplicity but unfortunately lacks subtlety. Indeed, many rational economic agents (meaning those with a correct perception of the risks they are exposed to and who protect themselves accordingly) buy lottery tickets (i.e., replace a deterministic amount, the price of the lottery ticket, with a random gain with a lower average). Thus, some of our readers might agree to play the coin toss game as described above, even if they are convinced of the utility of insurance contracts. It is therefore not uncommon for an individual to exhibit risk aversion only beyond a certain financial threshold and occasionally engage in irrational behavior below that threshold. If, in the above example, €1,000,000 is at stake, most readers will undoubtedly prefer to keep that million rather than risking it on a coin toss.</p>
</div>
</div>
<div id="pure-premium-and-mathematical-expectation" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Pure Premium and Mathematical Expectation<a href="chap3.html#pure-premium-and-mathematical-expectation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="mathematical-expectation" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Mathematical Expectation<a href="chap3.html#mathematical-expectation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="expectation-in-the-discrete-case" class="section level4 hasAnchor" number="4.2.1.1">
<h4><span class="header-section-number">4.2.1.1</span> Expectation in the Discrete Case<a href="chap3.html#expectation-in-the-discrete-case" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For each random variable, an important characteristic called the mean or expected value is associated. This is a probabilistic formalization of the well-known concept of the arithmetic mean (empirical version). For a counting variable <span class="math inline">\(N\)</span>, the expectation is defined as follows:
<span class="math display" id="eq:EspDisc">\[\begin{equation}
\mathbb{E}[N]=\sum_{ j\in{\mathbb{N}}}j\Pr[N=j].
\tag{4.1}
\end{equation}\]</span>
Therefore, it is an average of the possible values <span class="math inline">\(j\)</span> for <span class="math inline">\(N\)</span>, weighted by the probability that the variable <span class="math inline">\(N\)</span> takes these values.</p>
<div class="example">
<p><span id="exm:unlabeled-div-2" class="example"><strong>Example 4.1  (Mean of the Binomial Distribution) </strong></span>When <span class="math inline">\(N\sim\mathcal{B}in(m,q)\)</span>, we have
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[N]&amp;=&amp;\sum_{k=1}^m\frac{m!}{(k-1)!(m-k)!}q^k(1-q)^{m-k}\\
&amp;=&amp;mq\sum_{k=1}^m\Pr[\mathcal{B}in(m-1,q)=k-1]=mq.
\end{eqnarray*}\]</span></p>
</div>
<div class="example">
<p><span id="exm:ExMoyPoiss" class="example"><strong>Example 4.2  (Mean of the Poisson Distribution) </strong></span>When <span class="math inline">\(N\sim\mathcal{P}oi(\lambda)\)</span>, we have
<span class="math display" id="eq:MomPois1">\[\begin{eqnarray*}
\mathbb{E}[N] &amp; = &amp; \sum_{k=1}^{+\infty}k\exp(-\lambda)\frac{\lambda^k}{k!} \nonumber\\
&amp; = &amp; \exp(-\lambda)\sum_{k=0}^{+\infty}\frac{\lambda^{k+1}}{k!}=\lambda.
\tag{4.2}
\end{eqnarray*}\]</span></p>
</div>
</div>
<div id="expectation-in-the-continuous-case" class="section level4 hasAnchor" number="4.2.1.2">
<h4><span class="header-section-number">4.2.1.2</span> Expectation in the Continuous Case<a href="chap3.html#expectation-in-the-continuous-case" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>If <span class="math inline">\(X\)</span> is continuous and has <span class="math inline">\(f_X\)</span> as its probability density function, the mean is defined by
<span class="math display" id="eq:EspCont">\[\begin{equation}
\mathbb{E}[X]=\int_{x\in{\mathbb{R}}}xf_X(x)dx,
\tag{4.3}
\end{equation}\]</span>
which can be seen as a continuous analogue of the formula <a href="chap3.html#eq:EspDisc">(4.1)</a> used in the discrete case. As it involves an integral, it’s clear that for any real numbers <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>,
<span class="math display">\[
\mathbb{E}[aX+b]=a\mathbb{E}[X]+b
\]</span></p>
<p>the mathematical expectation is said to be a linear operator.</p>
<div class="example">
<p><span id="exm:unlabeled-div-3" class="example"><strong>Example 4.3  (Mean of the Normal Distribution) </strong></span>Let’s consider <span class="math inline">\(Z\sim\mathcal{N}or(0,1)\)</span>. The mean of <span class="math inline">\(Z\)</span> is then given by
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[Z]&amp;=&amp;\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}x\exp(-x^2/2)dx\\
&amp;=&amp;\frac{1}{\sqrt{2\pi}}
\Big[\exp(-x^2/2)\Big]_{-\infty}^{+\infty}=0.
\end{eqnarray*}\]</span>
Now let’s move to <span class="math inline">\(X\sim\mathcal{N}or(\mu,\sigma^2)\)</span>. Since <span class="math inline">\(X\stackrel{\text{law}}{=}\mu+\sigma Z\)</span>, we can write
<span class="math display">\[
\mathbb{E}[X]=\mathbb{E}[\mu+\sigma Z]=\mu
\]</span>
so that the first parameter of the normal distribution is its mean.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-4" class="example"><strong>Example 4.4  (Mean of the Gamma Distribution) </strong></span>When <span class="math inline">\(X\sim\mathcal{G}am(\alpha,\tau)\)</span>, the mean is given by
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[X]&amp;=&amp;\frac{1}{\Gamma(\alpha)}\int_0^{+\infty}x^\alpha \tau^\alpha\exp(-x\tau)dx\\
&amp;=&amp;\frac{\Gamma(\alpha+1)}{\tau\Gamma(\alpha)}=\frac{\alpha}{\tau}.
\end{eqnarray*}\]</span></p>
</div>
</div>
<div id="expectation-and-lebesgue-stieltjes-integral" class="section level4 hasAnchor" number="4.2.1.3">
<h4><span class="header-section-number">4.2.1.3</span> Expectation and Lebesgue-Stieltjes Integral<a href="chap3.html#expectation-and-lebesgue-stieltjes-integral" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To unify <a href="chap3.html#eq:EspDisc">(4.1)</a> and <a href="chap3.html#eq:EspCont">(4.3)</a>, as well as to handle variables that are neither discrete nor continuous, we will use the Lebesgue-Stieltjes formalism. This formalism allows us to unify and generalize the expressions <a href="chap3.html#eq:EspDisc">(4.1)</a> and <a href="chap3.html#eq:EspCont">(4.3)</a> given earlier into
<span class="math display" id="eq:DefEsp">\[\begin{equation}
\mathbb{E}[X]=\int_{x\in{\mathbb{R}}}xdF_X(x),
\tag{4.4}
\end{equation}\]</span>
where <span class="math inline">\(dF_X\)</span> is the differential of the distribution function <span class="math inline">\(F_X\)</span>. Below, we provide the most common case for actuaries (without going into the general treatment of this mathematical tool).</p>
<p>Since the distribution function <span class="math inline">\(F_X\)</span> of <span class="math inline">\(X\)</span> is bounded and non-decreasing, it can have at most a countable number of points of discontinuity. Let <span class="math inline">\({d_1,d_2,\ldots}\)</span> be the set of these points, and define
<span class="math display">\[\begin{eqnarray*}
F_X^{(d)}(t)&amp;=&amp;\sum_{d_n\leq t}{F_X(d_n)-F_X(d_n-)}\\
&amp;=&amp;\sum_{d_n\leq t}\Pr[X=d_n]
\end{eqnarray*}\]</span>
and
<span class="math display">\[\begin{eqnarray*}
F_X^{(c)}(t)&amp;=&amp;F_X(t)-F_X^{(d)}(t).
\end{eqnarray*}\]</span>
Most of the time in actuarial science, <span class="math inline">\(F_X^{(c)}\)</span> can be represented as
<span class="math display">\[
F_X^{(c)}(t)=\int_{x\leq t}f_X^{(c)}(x)dx,
\]</span>
so the mean of <span class="math inline">\(X\)</span> is defined as follows (applying a similar reasoning to <a href="chap3.html#eq:EspDisc">(4.1)</a> for <span class="math inline">\(F_X^{(d)}\)</span> and <a href="chap3.html#eq:EspCont">(4.3)</a> for <span class="math inline">\(F_X^{(c)}\)</span>):
<span class="math display" id="eq:FormuleLS">\[\begin{eqnarray}
\mathbb{E}[X]&amp;=&amp;\int_{x\in{\mathbb{R}}}xdF_X(x)\nonumber\\
&amp;=&amp;\sum_{n\geq 1}d_n{F_X(d_n)-F_X(d_n-)}\nonumber\\
&amp;&amp;+\int_{x\in{\mathbb{R}}}xf_X^{(c)}(x)dx.\tag{4.5}
\end{eqnarray}\]</span>
Thus, we see that the mass points <span class="math inline">\(d_1,d_2,\ldots\)</span> contribute to <span class="math inline">\(\mathbb{E}[X]\)</span> through the first sum, while the rest of the real line contributes to <span class="math inline">\(\mathbb{E}[X]\)</span> through the second sum. The differential <span class="math inline">\(dF_X\)</span> that in the example above is
<span class="math display">\[
dF_X(x)=\left\{
\begin{array}{l}
F_X(d_n)-F_X(d_n-),\text{ if }x=d_n,\\
f_X^{(c)}(x),\text{ otherwise},
\end{array}
\right.
\]</span>
can thus be interpreted as the chance that the event <span class="math inline">\({X=x}\)</span> occurs (note that <span class="math inline">\(dF_X(x)\)</span> is a probability only when <span class="math inline">\(x=d_n\)</span>, in which case it is <span class="math inline">\(\Pr[X=d_n]\)</span>).</p>
<div class="example">
<p><span id="exm:unlabeled-div-5" class="example"><strong>Example 4.5  </strong></span>Let’s consider the random variable
<span class="math display">\[
S=\left\{
\begin{array}{l}
0,\text{ with probability }p,\\
Z,\text{ with probability }1-p,
\end{array}
\right.
\]</span>
where <span class="math inline">\(Z\sim\mathcal{G}am(\alpha,\tau)\)</span>. This type of construction is widely used in non-life insurance. Thus, <span class="math inline">\(S\)</span> represents the total cost of claims incurred by a policy in the portfolio, while <span class="math inline">\(Z\)</span> designates the cost of claims when they occur.
We can decompose the cumulative distribution function <span class="math inline">\(F_S\)</span> of <span class="math inline">\(S\)</span> into a discrete component
<span class="math display">\[
F_S^{(d)}(s)=\left\{
\begin{array}{l}
0,\text{ if }s&lt;0,\\
p,\text{ if }s\geq 0,
\end{array}
\right.
\]</span>
and a continuous component <span class="math inline">\(F_S^{(c)}\)</span> equal to <span class="math inline">\(1-p\)</span> times the cumulative distribution function associated with the <span class="math inline">\(\mathcal{G}am(\alpha,\tau)\)</span> distribution. The expectation of <span class="math inline">\(S\)</span> then becomes, by virtue of <a href="chap3.html#eq:FormuleLS">(4.5)</a>
<span class="math display">\[
\mathbb{E}[S]=0\times p + (1-p)\times \frac{\alpha}{\tau}= (1-p)\frac{\alpha}{\tau}.
\]</span></p>
</div>
<p>Requiring a pure premium of amount <span class="math inline">\(\int xdF_X(x)\)</span> should (on average) enable the insurer to cover the amount of claims, without surplus or deficit. Indeed, we weigh each possible claim amount <span class="math inline">\(x\)</span> by its “probability” <span class="math inline">\(dF_X(x)\)</span>, before “summing” over all these values (the integral can be seen as a sum over a non-denumerable infinity of terms). This is akin to subscribing to a series of insurance policies, each guaranteeing a payment of <span class="math inline">\(x\)</span>when the event <span class="math inline">\(\{X=x\}\)</span> occurs.</p>
<p>Therefore, this is a reasonable definition of the pure premium. We will delve more deeply into the connections between mathematical expectation and pure premium in the remainder of this chapter.</p>
<div class="remark">
<p><span id="unlabeled-div-6" class="remark"><em>Remark</em>. </span>It is important at this stage to emphasize that the mathematical expectation can very well be infinite. For instance, consider to convince ourselves <span class="math inline">\(X\sim\mathcal{P}ar(\alpha,\theta)\)</span>. Then, if <span class="math inline">\(\alpha&gt;1\)</span>, we have
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[X] &amp; = &amp;
\int_{x=0}^{+\infty}x\frac{\alpha\theta^\alpha}{(x+\theta)^{\alpha+1}}dx \\
&amp; = &amp; -\left[\frac{x\theta^\alpha}{(x+\theta)^\alpha}\right]_{x=0}^{+\infty}
+\int_{x=0}^{+\infty}\frac{\theta^\alpha}{(x+\theta)^{\alpha}}dx=\frac{\theta}{\alpha-1}.
\end{eqnarray*}\]</span>
However, if <span class="math inline">\(\alpha&lt;1\)</span>, <span class="math inline">\(\mathbb{E}[X]=+\infty\)</span>.</p>
</div>
</div>
<div id="linearity-of-expectation" class="section level4 hasAnchor" number="4.2.1.4">
<h4><span class="header-section-number">4.2.1.4</span> Linearity of Expectation<a href="chap3.html#linearity-of-expectation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>When it comes to sums or integrals, mathematical expectation is linear. This means that for any random variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>, and real constants <span class="math inline">\(c_0\)</span>, <span class="math inline">\(c_1\)</span>, and <span class="math inline">\(c_2\)</span>, the equality
<span class="math display">\[
\mathbb{E}[c_0+c_1X_1+c_2X_2]=c_0+c_1\mathbb{E}[X_1]+c_2\mathbb{E}[X_2]
\]</span>
always holds.</p>
</div>
<div id="alternative-representations-of-mathematical-expectation" class="section level4 hasAnchor" number="4.2.1.5">
<h4><span class="header-section-number">4.2.1.5</span> Alternative Representations of Mathematical Expectation<a href="chap3.html#alternative-representations-of-mathematical-expectation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The mathematical expectation defined earlier by formula <a href="chap3.html#eq:DefEsp">(4.4)</a> can be computed in many other ways. Here, we detail some alternative expressions.</p>
<div class="proposition">
<p><span id="prp:RepEsp" class="proposition"><strong>Proposition 4.1  </strong></span>Let <span class="math inline">\(X\)</span> be a positive, continuous random variable with a cumulative distribution function <span class="math inline">\(F_X\)</span>. The mathematical expectation of <span class="math inline">\(X\)</span> can be expressed as
<span class="math display">\[
\mathbb{E}[X]=\int_{x\in{\mathbb{R}}^+}\overline{F}_X(x)dx.
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-7" class="proof"><em>Proof</em>. </span>To convince ourselves of the truth of the result, we simply write
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[X]&amp;=&amp;\int_{t\in{\mathbb{R}}^+}tdF_X(t)=
\int_{t=0}^{+\infty}\int_{x=0}^tdxdF_X(t)\\
&amp; = &amp; \int_{x=0}^{+\infty}\int_{t=x}^{+\infty}dF_X(t)dx
=\int_{x\in{\mathbb{R}}^+}\overline{F}_X(x)dx.
\end{eqnarray*}\]</span></p>
</div>
<p>Thus, the mathematical expectation of a random variable with a lower-bounded support can be expressed as the integral of the survival function. It is evident that it is the rate of decay towards 0 of the survival function that renders the expectation infinite, and thus the risk uninsurable.</p>
<div class="example">
<p><span id="exm:unlabeled-div-8" class="example"><strong>Example 4.6  (Mean of the negative exponential distribution) </strong></span>When <span class="math inline">\(X\sim\mathcal{E}xp(\theta)\)</span>, Property <a href="chap3.html#prp:RepEsp">4.1</a> yields
<span class="math display">\[
\mathbb{E}[X]=\int_{x=0}^{+\infty}\exp(-\theta x)dx=\frac{1}{\theta}.
\]</span></p>
</div>
<p>Let’s now turn to counting variables and establish a result similar to Property <a href="chap3.html#prp:RepEsp">4.1</a>.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-9" class="proposition"><strong>Proposition 4.2  </strong></span>Let <span class="math inline">\(N\)</span> be a counting random variable. The mathematical expectation of <span class="math inline">\(N\)</span> can be expressed as
<span class="math display">\[
\mathbb{E}[N]=\sum_{k=0}^{+\infty}\Pr[N&gt;k].
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-10" class="proof"><em>Proof</em>. </span>Since the random variable <span class="math inline">\(N\)</span> takes values in <span class="math inline">\({\mathbb{N}}\)</span>, we have
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[N]&amp;=&amp;\Pr[N=1]+2\Pr[N=2]+3\Pr[N=3]+\ldots\\
&amp;=&amp;\Pr[N=1]+\Pr[N=2]+\Pr[N=3]+\ldots\\
&amp;&amp;\Pr[N=2]+\Pr[N=3]+\ldots\\
&amp;&amp;\Pr[N=3]+\ldots\\
&amp;=&amp;\Pr[N\geq 1]+\Pr[N\geq 2]+\Pr[N\geq 3]+\ldots\\
&amp;=&amp;\sum_{k=1}^{+\infty}\Pr[N\geq k]=\sum_{k=0}^{+\infty}\Pr[N&gt;k].
\end{eqnarray*}\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-11" class="example"><strong>Example 4.7  (Mean of the discrete uniform distribution) </strong></span>When <span class="math inline">\(N\sim\mathcal{DU}ni(n)\)</span>, we have
<span class="math display">\[
\mathbb{E}[N]=\sum_{k=0}^{n-1}\frac{n-k}{n+1}=\frac{n}{2}.
\]</span></p>
</div>
</div>
<div id="means-of-common-distributions" class="section level4 hasAnchor" number="4.2.1.6">
<h4><span class="header-section-number">4.2.1.6</span> Means of Common Distributions<a href="chap3.html#means-of-common-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The means associated with common distributions are summarized in Table <a href="chap3.html#tab:MoyUs">4.1</a>.</p>
<table>
<caption><span id="tab:MoyUs">Table 4.1: </span>Mathematical expectation of common probability distributions.</caption>
<colgroup>
<col width="22%" />
<col width="19%" />
<col width="25%" />
<col width="32%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Probability Law</th>
<th align="center">Expectation</th>
<th align="center">Probability Law</th>
<th align="center">Expectation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{DU}ni(n)\)</span></td>
<td align="center"><span class="math inline">\(\frac{n}{2}\)</span></td>
<td align="center"><span class="math inline">\(\mathcal{N}or(\mu,\sigma^2)\)</span></td>
<td align="center"><span class="math inline">\(\mu\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{B}er(q)\)</span></td>
<td align="center"><span class="math inline">\(q\)</span></td>
<td align="center"><span class="math inline">\(\mathcal{LN}or(\mu,\sigma^2)\)</span></td>
<td align="center"><span class="math inline">\(\exp(\mu+\frac{\sigma^2}{2})\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{B}in(m,q)\)</span></td>
<td align="center"><span class="math inline">\(mq\)</span></td>
<td align="center"><span class="math inline">\(\mathcal{E}xp(\theta)\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{\theta}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{G}eo(q)\)</span></td>
<td align="center"><span class="math inline">\(\frac{1-q}{q}\)</span></td>
<td align="center"><span class="math inline">\(\mathcal{Gam}(\alpha,\tau)\)</span></td>
<td align="center"><span class="math inline">\(\frac{\alpha}{\tau}\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{NB}in(\alpha,q)\)</span></td>
<td align="center"><span class="math inline">\(\frac{\alpha(1-q)}{q}\)</span></td>
<td align="center"><span class="math inline">\(\mathcal{Par}(\alpha,\theta)\)</span></td>
<td align="center"><span class="math inline">\(\frac{\theta}{\alpha-1}\)</span> if <span class="math inline">\(\alpha&gt;1\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{P}oi(\lambda)\)</span></td>
<td align="center"><span class="math inline">\(\lambda\)</span></td>
<td align="center"><span class="math inline">\(\mathcal{Bet}(\alpha,\beta)\)</span></td>
<td align="center"><span class="math inline">\(\frac{\alpha}{\alpha +\beta}\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="mean-of-compound-distributions" class="section level4 hasAnchor" number="4.2.1.7">
<h4><span class="header-section-number">4.2.1.7</span> Mean of Compound Distributions<a href="chap3.html#mean-of-compound-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let’s consider <span class="math inline">\(S\)</span> of the form <a href="#eq:LoiComp">(<strong>??</strong>)</a>, i.e. <span class="math inline">\(S=\sum_{i=1}^NX_i\)</span> with <span class="math inline">\(X_i\)</span>, <span class="math inline">\(i=1,2,\ldots\)</span> independent and identically distributed, and independent of <span class="math inline">\(N\)</span>. We would like to know the average claims amount over the year. This is given by the following property.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-12" class="proposition"><strong>Proposition 4.3  </strong></span>For <span class="math inline">\(S\)</span> of the form <a href="#eq:LoiComp">(<strong>??</strong>)</a>, <span class="math inline">\(\mathbb{E}[S]=\mathbb{E}[N]\mathbb{E}[X_1]\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-13" class="proof"><em>Proof</em>. </span>It’s enough to write
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[S] &amp; = &amp; \sum_{k=1}^{+\infty}\Pr[N=k]\mathbb{E}\left[\sum_{i=1}^kX_i\right] \\
&amp; = &amp; \left(\sum_{k=1}^{+\infty}\Pr[N=k]k\right)\mathbb{E}[X_1]=\mathbb{E}[N]\mathbb{E}[X_1].
\end{eqnarray*}\]</span></p>
</div>
<p>This classical formula reads as
<span class="math display">\[
\text{average total claims amount}=\text{average number x average cost}.
\]</span>
However, this formula shouldn’t make us forget the conditions under which it is valid, namely the independence between the costs and the number of claims, and the independence and identical distribution of the costs.</p>
<div class="example">
<p><span id="exm:unlabeled-div-14" class="example"><strong>Example 4.8  (Mean of compound binomial and Poisson distributions) </strong></span>Referring to Table @ref(tab:MoyUs}, it’s easy to see that if <span class="math inline">\(N\sim\mathcal{B}in(m,q)\)</span> then <span class="math inline">\(\mathbb{E}[S]=mq\mathbb{E}[X_1]\)</span> and if <span class="math inline">\(N\sim\mathcal{P}oi(\lambda)\)</span> then <span class="math inline">\(\mathbb{E}[S]=\lambda\mathbb{E}[X_1]\)</span>.</p>
</div>
</div>
<div id="expectation-of-a-function" class="section level4 hasAnchor" number="4.2.1.8">
<h4><span class="header-section-number">4.2.1.8</span> Expectation of a Function<a href="chap3.html#expectation-of-a-function" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Given a random variable <span class="math inline">\(X\)</span> and a function <span class="math inline">\(g:{\mathbb{R}}\rightarrow {\mathbb{R}}\)</span> that is continuous or monotonic (these conditions ensure that <span class="math inline">\(g(X)\)</span> is always a random variable), we can be interested in the new random variable <span class="math inline">\(g(X)\)</span> and discuss the expectation of this variable, denoted as <span class="math inline">\(\mathbb{E}[g(X)]\)</span>. This is given by
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[g(X)]&amp;=&amp;\int_{x\in{\mathbb{R}}}g(x)dF_X(x)\\
&amp;=&amp;\sum_{n\geq 1}g(d_n)\{F_X(d_n)-F_X(d_n-)\}+\int_{x\in{\mathbb{R}}}g(x)f_X^{(c)}(x)dx
\end{eqnarray*}\]</span>
in the notations of <a href="chap3.html#eq:FormuleLS">(4.5)</a>.</p>
</div>
<div id="expectation-of-products-and-product-of-expectations" class="section level4 hasAnchor" number="4.2.1.9">
<h4><span class="header-section-number">4.2.1.9</span> Expectation of Products and Product of Expectations<a href="chap3.html#expectation-of-products-and-product-of-expectations" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Given a random vector <span class="math inline">\(\boldsymbol{X}\)</span> and a function <span class="math inline">\(g:{\mathbb{R}}^n\to{\mathbb{R}}\)</span>, we can consider the random variable <span class="math inline">\(g(\boldsymbol{X})\)</span>. We can then define the mathematical expectation of this variable as
<span class="math display">\[
\mathbb{E}[g(\boldsymbol{X})]=\int_{\boldsymbol{x}\in{\mathbb{R}}^n}g(\boldsymbol{x})dF_{\boldsymbol{X}}(\boldsymbol{x}),
\]</span>
where the differential is defined in a similar manner to the one-dimensional case.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-15" class="proposition"><strong>Proposition 4.4  </strong></span>If <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span> are independent, then for any functions <span class="math inline">\(g_1,g_2,\ldots,g_n:{\mathbb{R}}\to{\mathbb{R}}\)</span>,
<span class="math display">\[
\mathbb{E}\left[\prod_{i=1}^ng_i(X_i)\right]=\prod_{i=1}^n\mathbb{E}[g_i(X_i)].
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-16" class="proof"><em>Proof</em>. </span>If <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span> are independent random variables, then
<span class="math display">\[
dF_{\boldsymbol{X}}(\boldsymbol{x})=\prod_{i=1}^ndF_{X_i}(x_i)
\]</span>
and it’s easy to see that
<span class="math display">\[
\mathbb{E}[g_1(X_1)g_2(X_2)\ldots g_n(X_n)]=\mathbb{E}[g_1(X_1)]\mathbb{E}[g_2(X_2)]\ldots \mathbb{E}[g_n(X_n)]
\]</span>
as claimed.</p>
</div>
<p>The expectation of the product coincides with the product of the expectations when the random variables are independent.</p>
</div>
</div>
<div id="probabilities-and-expectations-of-indicators" class="section level3 hasAnchor" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Probabilities and Expectations of Indicators<a href="chap3.html#probabilities-and-expectations-of-indicators" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s consider the indicator function of the half-line <span class="math inline">\((-\infty,t]\)</span>, given by
<span class="math display">\[
g(x)=\mathbb{I}[x\leq t]=\left\{
\begin{array}{l}
1,\text{ if }x\leq t,\\
0,\text{ otherwise.}
\end{array}
\right.
\]</span>
The random variable
<span class="math display">\[
\mathbb{I}[X\leq t]=\left\{
\begin{array}{l}
1,\text{ if }X\leq t,\\
0,\text{ otherwise},
\end{array}
\right.
\]</span>
indicates whether <span class="math inline">\(X\)</span> takes a value less than or equal to <span class="math inline">\(t\)</span> (it’s called the indicator of the event <span class="math inline">\(\{X\leq t\}\)</span>). Clearly, <span class="math inline">\(\mathbb{I}[X\leq t]\sim\mathcal{B}er(F_X(t))\)</span>, so according to Table <a href="chap3.html#tab:MoyUs">4.1</a>,
<span class="math display">\[
\mathbb{E}\big[\mathbb{I}[X\leq t]\big]=F_X(t).
\]</span>
The expectation of an indicator variable thus coincides with the probability of the associated event. This illustrates the close relationship between mathematical expectation and probability (and explains why some textbooks present the entire theory of probability based on mathematical expectation).</p>
</div>
<div id="determination-of-the-pure-premium" class="section level3 hasAnchor" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> Determination of the Pure Premium<a href="chap3.html#determination-of-the-pure-premium" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(S\)</span> be the total claim amount related to a specific policy during an insurance period. To be precise, <span class="math inline">\(S\)</span> here represents the risk effectively transferred to the insurer, after applying conventional clauses related to damages (deductible, mandatory retention, or limit), and may not necessarily coincide with the loss suffered by the policyholder’s assets. Conventionally, the role of insurance is to replace a constant <span class="math inline">\(c\)</span> (the insurance premium) with the random variable <span class="math inline">\(S\)</span>. A reasonable way to determine <span class="math inline">\(c\)</span> would be to choose the constant that is “closest” to the random variable <span class="math inline">\(S\)</span>. The distance used to measure the proximity between <span class="math inline">\(S\)</span> and <span class="math inline">\(c\)</span> should consider the fact that <span class="math inline">\(c\)</span> must enable the insurer to compensate for losses without surplus or deficit. Thus, the distance should penalize both cases where <span class="math inline">\(c\)</span> is less than <span class="math inline">\(S\)</span> and cases where <span class="math inline">\(c\)</span> is greater than <span class="math inline">\(S\)</span>. A distance penalizing both over- and underestimation of the premium is the mean squared error
<span class="math display">\[
d_2(S,c)=\mathbb{E}[(S-c)^2].
\]</span></p>
<p>Now that we have established a measure <span class="math inline">\(d_2\)</span> of proximity, let’s try to find the constant <span class="math inline">\(c\)</span> that is closest to <span class="math inline">\(S\)</span>, i.e., the value of <span class="math inline">\(c\)</span> that minimizes <span class="math inline">\(d_2(S,c)\)</span>. To do this, we write
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[(S-c)^2]&amp;=&amp;\mathbb{E}[(S-\mathbb{E}[S]+\mathbb{E}[S]-c)^2]\\
&amp;=&amp;\mathbb{E}[(S-\mathbb{E}[S])^2]+2(\mathbb{E}[S]-c)\underbrace{\mathbb{E}[S-\mathbb{E}[S]]}_{=0}+(\mathbb{E}[S]-c)^2\\
&amp;=&amp;(\mathbb{E}[S]-c)^2+\text{constant with respect to }c
\end{eqnarray*}\]</span>
from which we deduce that the value of <span class="math inline">\(c\)</span> minimizing <span class="math inline">\(\mathbb{E}[(S-c)^2]\)</span> is none other than <span class="math inline">\(\mathbb{E}[S]\)</span>. Thus, <span class="math inline">\(\mathbb{E}[S]\)</span> is the closest constant to <span class="math inline">\(S\)</span> (in terms of the distance <span class="math inline">\(d_2\)</span> that we introduced earlier). If we want to replace <span class="math inline">\(S\)</span> with a constant, a natural choice is therefore <span class="math inline">\(\mathbb{E}[S]\)</span>.</p>
</div>
<div id="mean-squared-error-is-it-a-must" class="section level3 hasAnchor" number="4.2.4">
<h3><span class="header-section-number">4.2.4</span> Mean Squared Error, Is It a Must?<a href="chap3.html#mean-squared-error-is-it-a-must" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The distance <span class="math inline">\(d_2\)</span> used above is certainly not the only possible one, far from it. Any distance expressed as <span class="math inline">\(\mathbb{E}[g(S-c)]\)</span> where <span class="math inline">\(g\)</span> is non-negative, convex, symmetric, and such that <span class="math inline">\(g(0)=0\)</span> is a valid candidate. Indeed, these characteristics ensure that the pure premium obtained by minimizing this distance will be “closest to” <span class="math inline">\(S\)</span>. Thus, one could very well consider the mean absolute error
<span class="math display">\[
d_1(S,c)=\mathbb{E}[|S-c|].
\]</span>
Let’s calculate in this case the constant <span class="math inline">\(c\)</span> that minimizes <span class="math inline">\(d_1(S,c)\)</span>. To do this, we write
<span class="math display">\[
d_1(S,c)=\int_{s\leq c}(c-s)dF_S(s)+\int_{s&gt;c}(s-c)dF_S(s)
\]</span>
and then integrate by parts to obtain
<span class="math display">\[
d_1(S,c)=\int_{s\leq c}F_S(s)ds+\int_{s&gt;c}\overline{F}_S(s)ds.
\]</span>
By setting the first derivative of <span class="math inline">\(d_1(S,c)\)</span> with respect to <span class="math inline">\(c\)</span> to zero, we get
<span class="math display">\[
F_S(c)-\overline{F}_S(c)=0\Leftrightarrow F_S(c)=\frac{1}{2},
\]</span>
from which we deduce that the constant minimizing <span class="math inline">\(d_1(S,c)\)</span> is the median <span class="math inline">\(q_{1/2}\)</span>.</p>
<p>Pricing based on the median is equivalent to charging each insured a premium such that the amounts paid out by the company for half of them are less than it, while the amounts paid out for the other half will be greater than it. If the distribution of the claim amount is symmetric, mean and median are identical. However, in the field of insurance, asymmetry is the rule and the median is always well before the mean.</p>
<p>Let’s explain why the median is often not a good candidate for calculating the premium. Take car insurance, for instance. Every year, around 90% of policyholders do not cause any accidents and therefore do not incur any expenses for the company. Consequently, <span class="math inline">\(q_{1/2}=0\)</span>. However, it is difficult to conceive that the insurer would offer its coverage for free.</p>
</div>
</div>
<div id="variance" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Variance<a href="chap3.html#variance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="definition-5" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Definition<a href="chap3.html#definition-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Variance measures the spread of possible values for a random variable around its mean. It is defined as follows.</p>
<div class="definition">
<p><span id="def:unlabeled-div-17" class="definition"><strong>Definition 4.1  </strong></span>The variance of the random variable <span class="math inline">\(X\)</span>, denoted <span class="math inline">\(\mathbb{V}[X]\)</span>, is the second moment of this centered variable, i.e.,
<span class="math display">\[
\mathbb{V}[X]=\mathbb{E}[(X-\mathbb{E}[X])^2].
\]</span></p>
</div>
<p>It is, therefore, an average of the squared deviations <span class="math inline">\(x-\mathbb{E}[X]\)</span> between the realization <span class="math inline">\(x\)</span> of <span class="math inline">\(X\)</span> and its expected value <span class="math inline">\(\mathbb{E}[X]\)</span>. The variance of <span class="math inline">\(X\)</span> can also be expressed as
<span class="math display">\[\begin{eqnarray*}
\mathbb{V}[X]&amp;=&amp;\mathbb{E}\big[X^2-2\mathbb{E}[X]X+\{\mathbb{E}[X]\}^2\big]\\
&amp;=&amp;\mathbb{E}[X^2]-\{\mathbb{E}[X]\}^2.
\end{eqnarray*}\]</span>
Thus, the variance of <span class="math inline">\(X\)</span> is the expectation of the squared variable, subtracting the square of the expectation.</p>
<p>In the following, we will use the standard deviation of the random variables in question extensively, the definition of which is given below.</p>
<div class="definition">
<p><span id="def:unlabeled-div-18" class="definition"><strong>Definition 4.2  </strong></span>The positive square root of the variance is called the standard deviation.</p>
</div>
</div>
<div id="actuarial-interpretation" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Actuarial Interpretation<a href="chap3.html#actuarial-interpretation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Note that the variance has a clear interpretation in terms of the distance <span class="math inline">\(d_2\)</span> introduced earlier to determine the pure premium for a risk <span class="math inline">\(S\)</span>, as <span class="math inline">\(d_2(S,\mathbb{E}[S])=\mathbb{V}[S]\)</span>. So, the variance becomes very important here, as it measures the distance between the random expenses <span class="math inline">\(S\)</span> of the insurer and the pure premium <span class="math inline">\(\mathbb{E}[S]\)</span> that it will charge the insured. Thus, it’s a measure of the risk the insurer takes in replacing <span class="math inline">\(S\)</span> with <span class="math inline">\(\mathbb{E}[S]\)</span> (in terms of the distance <span class="math inline">\(d_2\)</span>).</p>
</div>
<div id="some-examples" class="section level3 hasAnchor" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Some Examples<a href="chap3.html#some-examples" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The significance of variance in probability and statistics also stems from its special role in the normal distribution.</p>
<div class="example">
<p><span id="exm:VarNmusigma" class="example"><strong>Example 4.9  (Variance associated with the Standard Normal Distribution) </strong></span>Let’s start with <span class="math inline">\(Z\sim\mathcal{N}or(0,1)\)</span>. Since <span class="math inline">\(\mathbb{E}[Z]=0\)</span>,
<span class="math display">\[
\mathbb{V}[Z]=\mathbb{E}[Z^2]=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}x^2\exp(-x^2/2)dx
\]</span>
which, by integrating by parts, gives
<span class="math display">\[\begin{eqnarray*}
\mathbb{V}[Z]&amp;=&amp;-\frac{1}{\sqrt{2\pi}}\Big[x\exp(-x^2/2)\Big]_{-\infty}^{+\infty}\\
&amp;&amp;+\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}\exp(-x^2/2)dx=1.
\end{eqnarray*}\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-19" class="example"><strong>Example 4.10  (Variance associated with the Poisson Distribution) </strong></span>When <span class="math inline">\(N\sim\mathcal{P}oi(\lambda)\)</span>,
<span class="math display" id="eq:MomPois2">\[\begin{eqnarray*}
\mathbb{E}[N^2] &amp; = &amp; \sum_{k=1}^{+\infty}k^2\exp(-\lambda)\frac{\lambda^k}{k!} \nonumber\\
&amp; = &amp; \exp(-\lambda)\sum_{k=0}^{+\infty}(k+1)\frac{\lambda^{k+1}}{k!}
=\lambda+\lambda^2,\tag{4.6}
\end{eqnarray*}\]</span>
so that
<span class="math display">\[
\mathbb{V}[N]=\mathbb{E}[N^2]-\lambda^2=\lambda.
\]</span>
Returning to Example <a href="chap3.html#exm:ExMoyPoiss">4.2</a>, we observe that the Poisson distribution stands out because
<span class="math display">\[
\mathbb{E}[N]=\mathbb{V}[N]=\lambda,
\]</span>
thus reflecting equidispersion and significantly limiting its applicability, as the sample mean and variance are often quite different.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-20" class="remark"><em>Remark</em>. </span>Not all random variables have finite variance. It is possible for a variable to have a finite mean (indicating insurability from an actuarial perspective), but an infinite variance, indicating significant risk for the insurer. This is the case for Pareto distributions with a tail index between 1 and 2. For instance, consider <span class="math inline">\(X\sim\mathcal{P}ar(\alpha,\theta)\)</span> with <span class="math inline">\(\alpha&gt;2\)</span>. Then,
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[X^2] &amp; = &amp;
\int_{x=0}^{+\infty}x^2\frac{\alpha\theta^\alpha}{(x+\theta)^{\alpha+1}}dx \\
&amp; = &amp; -\left[\frac{x^2\theta^\alpha}{(x+\theta)^\alpha}\right]_{x=0}^{+\infty}
+\int_{x=0}^{+\infty}2x\frac{\theta^\alpha}{(x+\theta)^{\alpha}}dx \\
&amp; = &amp; \left[\frac{2x\theta^\alpha}{(x+\theta)^{\alpha-1}(-\alpha+1)}\right]_{x=0}^{+\infty}\\
&amp; &amp;  +\int_{x=0}^{+\infty}2\frac{\theta^\alpha}{(\alpha-1)(x+\theta)^{\alpha-1}}dx \\
&amp; = &amp; \frac{2\theta^2}{(\alpha-1)(\alpha-2)}.
\end{eqnarray*}\]</span>
If <span class="math inline">\(\alpha&lt;2\)</span>, then <span class="math inline">\(\mathbb{E}[X^2]=+\infty\)</span>. Therefore, if <span class="math inline">\(2&gt;\alpha&gt;1\)</span>,
<span class="math display">\[
\mathbb{E}[X]=\frac{\theta}{\alpha-1}&lt;+\infty\text{ and }\mathbb{V}[X]=+\infty.
\]</span></p>
</div>
</div>
<div id="properties" class="section level3 hasAnchor" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> Properties<a href="chap3.html#properties" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="invariance-under-translation" class="section level4 hasAnchor" number="4.3.4.1">
<h4><span class="header-section-number">4.3.4.1</span> Invariance under Translation<a href="chap3.html#invariance-under-translation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Note that
<span class="math display">\[
\mathbb{V}[S]=\mathbb{V}[S+c]
\]</span>
for any real constant <span class="math inline">\(c\)</span>. This reflects the intuitive idea that adding a real constant <span class="math inline">\(c\)</span> to a risk <span class="math inline">\(X\)</span> doesn’t make the insurer’s situation more dangerous. The insurer can simply charge a premium of <span class="math inline">\(\mathbb{E}[S]+c\)</span> instead of <span class="math inline">\(\mathbb{E}[S]\)</span>.</p>
</div>
<div id="change-of-scale" class="section level4 hasAnchor" number="4.3.4.2">
<h4><span class="header-section-number">4.3.4.2</span> Change of Scale<a href="chap3.html#change-of-scale" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For any constant <span class="math inline">\(c\)</span>, it’s easy to see that
<span class="math display">\[
\mathbb{V}[cS]=c^2\mathbb{V}[S],
\]</span>
so the variance is affected by a change in measurement units (for example, switching from euros to thousands of euros). This is why the coefficient of variation (see below) is introduced.</p>
<p>::: {.example name = “Variance associated with the Normal Distribution”}
For <span class="math inline">\(X\sim\mathcal{N}or(\mu,\sigma^2)\)</span>, we know that <span class="math inline">\(X=_{\text{dist}}\mu+\sigma Z\)</span> where <span class="math inline">\(Z\sim\mathcal{N}or(0,1)\)</span>, so according to Example <a href="chap3.html#exm:VarNmusigma">4.9</a>,
<span class="math display">\[
\mathbb{V}[X]=\mathbb{V}[\mu+\sigma Z]=\sigma^2.
\]</span>
Hence, the second parameter of the normal distribution is its variance.
:::</p>
</div>
<div id="additivity-for-independent-risks" class="section level4 hasAnchor" number="4.3.4.3">
<h4><span class="header-section-number">4.3.4.3</span> Additivity for Independent Risks<a href="chap3.html#additivity-for-independent-risks" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The following result shows how the variance of a sum of independent random variables decomposes.</p>
<div class="proposition">
<p><span id="prp:VarSum" class="proposition"><strong>Proposition 4.5  (Variance of a Sum of Independent Variables) </strong></span>If the random variables <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span> are independent, then
<span class="math display">\[
\mathbb{V}\left[\sum_{i=1}^nX_i\right]=\sum_{i=1}^n\mathbb{V}[X_i].
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-21" class="proof"><em>Proof</em>. </span>It’s sufficient to write
<span class="math display">\[\begin{eqnarray*}
\mathbb{V}\left[\sum_{i=1}^nX_i\right]&amp;=&amp;\mathbb{E}\left[\left(\sum_{i=1}^n(X_i-\mathbb{E}[X_i])\right)^2\right]\\
&amp;=&amp;\mathbb{E}\left[\left(\sum_{i=1}^n(X_i-\mathbb{E}[X_i])\right)\left(\sum_{j=1}^n(X_j-\mathbb{E}[X_j])\right)\right]\\
&amp;=&amp;\sum_{i\neq j}\mathbb{E}\big[X_i-\mathbb{E}[X_i]\big]\mathbb{E}\big[X_j-\mathbb{E}[X_j]\big]
+\sum_{i=1}^n\mathbb{E}\big[\big(X_i-\mathbb{E}[X_i]\big)^2\big]\\
&amp;=&amp;\sum_{i=1}^n\mathbb{V}[X_i].
\end{eqnarray*}\]</span></p>
</div>
<p>Thus, the variance of a sum of independent random variables is the sum of the variances of each of them.</p>
<div class="example">
<p><span id="exm:unlabeled-div-22" class="example"><strong>Example 4.11  (Variance associated with the Binomial Distribution) </strong></span>When <span class="math inline">\(N\sim\mathcal{B}in(m,q)\)</span>, <span class="math inline">\(N=_{\text{dist}}N_1+\ldots+N_m\)</span> where the <span class="math inline">\(N_i\)</span> are independent with distribution <span class="math inline">\(\mathcal{B}er(q)\)</span>. Property <a href="chap3.html#prp:VarSum">4.5</a> then gives
<span class="math display">\[
\mathbb{V}[N]=\sum_{k=1}^m\mathbb{V}[N_k]=mq(1-q).
\]</span>
So, the binomial distribution exhibits under-dispersion of data, as <span class="math inline">\(\mathbb{V}[N]&lt;\mathbb{E}[N]=mq\)</span>.</p>
</div>
</div>
</div>
<div id="variance-of-common-distributions" class="section level3 hasAnchor" number="4.3.5">
<h3><span class="header-section-number">4.3.5</span> Variance of Common Distributions<a href="chap3.html#variance-of-common-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The variances associated with common probability distributions are shown in Table <a href="chap3.html#tab:VarUs">4.2</a>. If we consider variance as a risk criterion, this table allows us to assess how the parameters influence the risk associated with the number or cost of losses.</p>
<table>
<caption><span id="tab:VarUs">Table 4.2: </span>Variances of common probability distributions</caption>
<thead>
<tr class="header">
<th align="center">Probability Law</th>
<th align="center">Variance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{DU}ni(n)\)</span></td>
<td align="center"><span class="math inline">\(\frac{n^2+n}{12}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{B}er(q)\)</span></td>
<td align="center"><span class="math inline">\(q(1-q)\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{B}in(m,q)\)</span></td>
<td align="center"><span class="math inline">\(mq(1-q)\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{G}eo(q)\)</span></td>
<td align="center"><span class="math inline">\(\frac{1-q}{q^2}\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{NB}in(\alpha,q)\)</span></td>
<td align="center"><span class="math inline">\(\frac{\alpha(1-q)}{q^2}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{P}oi(\lambda)\)</span></td>
<td align="center"><span class="math inline">\(\lambda\)</span></td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:VarUs">Table 4.2: </span></caption>
<colgroup>
<col width="33%" />
<col width="66%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Probability Law</th>
<th align="center">Variance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{N}or(\mu,\sigma^2)\)</span></td>
<td align="center"><span class="math inline">\(\sigma^2\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{LN}or(\mu,\sigma^2)\)</span></td>
<td align="center"><span class="math inline">\(\exp(2\mu+\sigma^2)(\exp(\sigma^2)-1)\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{E}xp(\theta)\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{\theta^2}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{Gam}(\alpha,\tau)\)</span></td>
<td align="center"><span class="math inline">\(\frac{\alpha}{\tau^2}\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{Par}(\alpha,\theta)\)</span></td>
<td align="center"><span class="math inline">\(\frac{\alpha\theta^2}{(\alpha-2)(\alpha-1)^2}\)</span> if <span class="math inline">\(\alpha&gt;2\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{Bet}(\alpha,\beta)\)</span></td>
<td align="center"><span class="math inline">\(\frac{\alpha\beta}{(\alpha+\beta+1)(\alpha+\beta)^2}\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{U}ni(a,b)\)</span></td>
<td align="center"><span class="math inline">\(\frac{(b-a)^2}{12}\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="variance-of-composite-distributions" class="section level3 hasAnchor" number="4.3.6">
<h3><span class="header-section-number">4.3.6</span> Variance of Composite Distributions<a href="chap3.html#variance-of-composite-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s now turn our attention to the variance of composite distributions. The following result indicates how the variance of a composite distribution can be decomposed in terms of the variance of the number of terms and the variance of each term.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-23" class="proposition"><strong>Proposition 4.6  </strong></span>If <span class="math inline">\(S\)</span> is of the form <a href="#eq:CompDist">(<strong>??</strong>)</a>, i.e., <span class="math inline">\(S=\sum_{i=1}^NX_i\)</span> where <span class="math inline">\(X_i\)</span>, <span class="math inline">\(i=1,2,\ldots\)</span>, are independent and identically distributed, and independent of <span class="math inline">\(N\)</span>, then its variance is given by
<span class="math display">\[\begin{eqnarray*}
\mathbb{V}[S]
&amp;=&amp;\mathbb{E}[N]\mathbb{V}[X_1]+\mathbb{V}[N]\mathbb{E}^2[X_1].
\end{eqnarray*}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-24" class="proof"><em>Proof</em>. </span>This comes from
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[S^2]&amp;=&amp;\mathbb{E}\left[\sum_{i=1}^N\sum_{j=1}^NX_iX_j\right]\\
&amp;=&amp;\mathbb{E}\left[\sum_{i=1}^NX_i^2\right]+\mathbb{E}\left[\sum_{i\neq j}^NX_iX_j\right]\\
&amp;=&amp;\mathbb{E}[N]\mathbb{E}[X_1^2]+\big(\mathbb{E}[X_1]\big)^2\big(\mathbb{E}[N^2]-\mathbb{E}[N]\big),
\end{eqnarray*}\]</span>
which gives the announced result after grouping terms.</p>
</div>
<p>We can interpret this decomposition of variance as follows. The first term can be thought of as <span class="math inline">\(\mathbb{V}[\sum_{i=1}^{\mathbb{E}[N]}X_i]\)</span> by considering momentarily <span class="math inline">\(\mathbb{E}[N]\)</span> as an integer. Thus, it represents the portion of the variance of <span class="math inline">\(S\)</span> attributed solely to the variability in the costs of losses <span class="math inline">\(X_1,X_2,\ldots\)</span>. The second term in the variance decomposition of <span class="math inline">\(S\)</span> can be viewed as <span class="math inline">\(\mathbb{V}[\sum_{i=1}^N\mathbb{E}[X_i]]\)</span>, i.e., the part of the variability in <span class="math inline">\(S\)</span> due to the variability in the number of losses, with their costs fixed at their mean value.</p>
<div class="example">
<p><span id="exm:unlabeled-div-25" class="example"><strong>Example 4.12  </strong></span>Several interesting special cases can be derived easily from Tables <a href="chap3.html#tab:MoyUs">4.1</a> and <a href="chap3.html#tab:VarUs">4.2</a>. If <span class="math inline">\(N\sim\mathcal{B}in(m,q)\)</span>, then
<span class="math display">\[
\mathbb{V}[S]=mq\Big(\mathbb{E}[X_1^2]-q\big(\mathbb{E}[X_1]\big)^2\Big).
\]</span>
If <span class="math inline">\(N\sim\mathcal{P}oi(\lambda)\)</span>, then
<span class="math display">\[
\mathbb{V}[S]=\lambda\mathbb{V}[X_1]+\lambda\mathbb{E}^2[X_1]=\lambda \mathbb{E}[X_1^2].
\]</span></p>
</div>
</div>
<div id="coefficient-of-variation-and-risk-pooling" class="section level3 hasAnchor" number="4.3.7">
<h3><span class="header-section-number">4.3.7</span> Coefficient of Variation and Risk Pooling<a href="chap3.html#coefficient-of-variation-and-risk-pooling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The coefficient of variation is defined as the ratio of the standard deviation to the mean, i.e.,
<span class="math display">\[
CV[X]=\frac{\sqrt{\mathbb{V}[X]}}{\mathbb{E}[X]}.
\]</span>
The coefficient of variation has the significant advantage of being a dimensionless number, which facilitates comparisons (excluding, for instance, the effects of different monetary units). It can be seen as a normalization of the standard deviation.</p>
<p>The coefficient of variation plays a particularly important role in actuarial science. It can be interpreted as the standard deviation of the “losses over pure premiums” ratio, traditionally denoted as L/P.</p>
</div>
</div>
<div id="insurance-and-bienaymé-chebyshev-inequality" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Insurance and Bienaymé-Chebyshev Inequality<a href="chap3.html#insurance-and-bienaymé-chebyshev-inequality" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="markovs-inequality" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Markov’s Inequality<a href="chap3.html#markovs-inequality" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Here we present one of the most famous inequalities in probability theory.</p>
<div class="proposition">
<p><span id="prp:MarkovIneq" class="proposition"><strong>Proposition 4.7  (Markov's Inequality) </strong></span>Given a random variable <span class="math inline">\(X\)</span>, any non-negative function <span class="math inline">\(g:{\mathbb{R}}\to{\mathbb{R}}^+\)</span>, and a constant <span class="math inline">\(a&gt;0\)</span>, we have
<span class="math display">\[
\Pr[g(X)&gt; a]&lt;\frac{\mathbb{E}[g(X)]}{a}.
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-26" class="proof"><em>Proof</em>. </span>The inequality
<span class="math display">\[
g(X)&gt; a\mathbb{I}[g(X)&gt; a],
\]</span>
yields, by taking the expectation,
<span class="math display">\[
\mathbb{E}[g(X)]&gt; a\Pr[g(X)&gt; a],
\]</span>
which gives the desired result.</p>
</div>
</div>
<div id="bienaymé-chebyshev-inequality" class="section level3 hasAnchor" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Bienaymé-Chebyshev Inequality<a href="chap3.html#bienaymé-chebyshev-inequality" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Bienaymé-Chebyshev inequality controls the deviation between a random variable and its mean. It is derived as a straightforward consequence of Markov’s inequality.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-27" class="proposition"><strong>Proposition 4.8  (Bienaymé-Chebyshev Inequality) </strong></span>Given a random variable <span class="math inline">\(X\)</span> with mean <span class="math inline">\(\mu\)</span> and finite variance <span class="math inline">\(\sigma^2\)</span>, we have
<span class="math display">\[
\Pr\big[|X-\mu|&gt;\epsilon\big]&lt;\frac{\sigma^2}{\epsilon^2}
\]</span>
for any <span class="math inline">\(\epsilon&gt;0\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-28" class="proof"><em>Proof</em>. </span>Just apply Markov’s inequality to <span class="math inline">\(g(x)=(x-\mu)^2\)</span> and <span class="math inline">\(a=\epsilon^2\)</span>.</p>
</div>
</div>
<div id="actuarial-interpretation-of-the-bienaymé-chebyshev-inequality" class="section level3 hasAnchor" number="4.4.3">
<h3><span class="header-section-number">4.4.3</span> Actuarial Interpretation of the Bienaymé-Chebyshev Inequality<a href="chap3.html#actuarial-interpretation-of-the-bienaymé-chebyshev-inequality" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As we discussed earlier, variance (and therefore standard deviation) measures the distance between the financial burden <span class="math inline">\(S\)</span> of the insurer and the corresponding pure premium <span class="math inline">\(\mu=\mathbb{E}[S]\)</span>. Therefore, we might wonder what we can say about the gap between <span class="math inline">\(S\)</span> and its mean using the knowledge of variance. The Bienaymé-Chebyshev inequality tells us that
<span class="math display" id="eq:BTcheby">\[\begin{equation}
\Pr\Big[|S-\mu|\leq t\sigma\Big]&gt;1-\frac{1}{t^2} \Leftrightarrow \Pr\Big[|S-\mu|&gt;t\sigma\Big]&lt;\frac{1}{t^2}
\tag{4.7}
\end{equation}\]</span>
for any <span class="math inline">\(t&gt;0\)</span>.</p>
<p>The inequalities <a href="chap3.html#eq:BTcheby">(4.7)</a> are of interest only if <span class="math inline">\(t&gt;1\)</span>. They imply that a random variable <span class="math inline">\(S\)</span> with finite variance cannot deviate “too much” from its mean <span class="math inline">\(\mu\)</span>, and they are of considerable importance to actuaries (interpreting <span class="math inline">\(S\)</span> as a loss amount and <span class="math inline">\(\mu\)</span> as the corresponding pure premium). Thus, the probability that the loss amount <span class="math inline">\(S\)</span> deviates from the pure premium <span class="math inline">\(\mu\)</span> by <span class="math inline">\(t=10\)</span> times the standard deviation <span class="math inline">\(\sigma\)</span> is always less than <span class="math inline">\(1/t^2=1\%\)</span>.</p>
</div>
<div id="conservative-nature-of-the-bienaymé-chebyshev-inequality" class="section level3 hasAnchor" number="4.4.4">
<h3><span class="header-section-number">4.4.4</span> Conservative Nature of the Bienaymé-Chebyshev Inequality<a href="chap3.html#conservative-nature-of-the-bienaymé-chebyshev-inequality" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Before moving forward, it’s important to note that the Bienaymé-Chebyshev inequality holds in a very general sense, so the upper bound it provides is often very (or overly) conservative. For illustration, in Figure <a href="chap3.html#fig:CompTchebyReal">4.1</a>, we have plotted the function
<span class="math display" id="eq:GammaRatio">\[\begin{equation}
t\mapsto\frac{1/t^2}{\Pr\big[|\mathcal{G}am(1/2,1/2)-1|&gt;t\sqrt{2}\big]},
\tag{4.8}
\end{equation}\]</span>
which is the ratio between the upper bound provided by the Bienaymé-Chebyshev inequality and the probability that a Gamma-distributed variable with mean 1 and variance 2 deviates from its mean by more than <span class="math inline">\(t\)</span> times the standard deviation. It’s evident that the upper bound <span class="math inline">\(1/t^2\)</span> is significantly above the exact value in this case. Figure <a href="chap3.html#fig:CompTchebyReal">4.1</a> also provides similar results for the log-normal distribution with the same mean and variance, given by the function
<span class="math display" id="eq:LNRatio">\[\begin{equation}
t\mapsto\frac{1/t^2}{\Pr\big[|\mathcal{LN}or(\mu,\sigma^2)-1|&gt;t\sqrt{2}\big]},
\tag{4.9}
\end{equation}\]</span>
where
<span class="math display">\[
\mu=-\frac{\ln 3}{2}\mbox{ and }\sigma^2=\ln 3,
\]</span>
and for the Pareto distribution with the same first two moments, i.e.,
<span class="math display" id="eq:ParRatio">\[\begin{equation}
t\mapsto\frac{1/t^2}{\Pr\big[|\mathcal{P}ar(\alpha,\theta)-1|&gt;t\sqrt{2}\big]},
\tag{4.10}
\end{equation}\]</span>
where
<span class="math display">\[
\alpha=4\mbox{ and }\theta=3.
\]</span></p>
<p>It’s clear that the upper bound provided by <a href="chap3.html#eq:BTcheby">(4.7)</a> is very cautious.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:CompTchebyReal"></span>
<img src="bookdown-demo_files/figure-html/CompTchebyReal-1.png" alt="Evoluation of ratios between Bienaymé-Tchebycheff upper bound and the true probability" width="768" />
<p class="caption">
Figure 4.1: Evoluation of ratios between Bienaymé-Tchebycheff upper bound and the true probability
</p>
</div>
</div>
</div>
<div id="insurance-and-law-of-large-numbers" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Insurance and Law of Large Numbers<a href="chap3.html#insurance-and-law-of-large-numbers" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="convergence-in-probability" class="section level3 hasAnchor" number="4.5.1">
<h3><span class="header-section-number">4.5.1</span> Convergence in Probability<a href="chap3.html#convergence-in-probability" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The law of large numbers provides a relevant justification for the calculation method of the pure premium associated with <span class="math inline">\(S\)</span>. To understand this, we need a concept of convergence for a sequence of random variables.</p>
<div class="definition">
<p><span id="def:unlabeled-div-29" class="definition"><strong>Definition 4.3  </strong></span>The sequence <span class="math inline">\(\{T_n,\hspace{2mm}n\in{\mathbb{N}}\}\)</span> converges in probability to the random variable <span class="math inline">\(T\)</span>, denoted as
<span class="math display">\[
T_n\to_{\text{proba}}T,
\]</span>
when
<span class="math display">\[
\Pr\big[|T_n-T|&gt;\epsilon\big]\to 0\mbox{ as }n\to +\infty
\]</span>
for any <span class="math inline">\(\epsilon&gt;0\)</span>.</p>
</div>
<p>This expresses the fact that as <span class="math inline">\(n\)</span> increases, the probability that <span class="math inline">\(T_n\)</span> deviates from its limit <span class="math inline">\(T\)</span> by more than <span class="math inline">\(\epsilon\)</span> tends towards 0; <span class="math inline">\(T_n\)</span> gets closer to its limit <span class="math inline">\(T\)</span> as <span class="math inline">\(n\)</span> gets larger.</p>
</div>
<div id="convergence-of-average-claim-amount-per-policy-to-the-pure-premium" class="section level3 hasAnchor" number="4.5.2">
<h3><span class="header-section-number">4.5.2</span> Convergence of Average Claim Amount per Policy to the Pure Premium<a href="chap3.html#convergence-of-average-claim-amount-per-policy-to-the-pure-premium" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="law-of-large-numbers" class="section level4 hasAnchor" number="4.5.2.1">
<h4><span class="header-section-number">4.5.2.1</span> Law of Large Numbers<a href="chap3.html#law-of-large-numbers" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let’s assume that the insurer issues a large number of identical policies, and let <span class="math inline">\(S_i\)</span>, <span class="math inline">\(i=1,2,\ldots,n\)</span>, represent the total payout by the insurer related to policy number <span class="math inline">\(i\)</span> during a reference period (usually a year).</p>
<div class="proposition">
<p><span id="prp:LLN" class="proposition"><strong>Proposition 4.9  </strong></span>Let <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> be the common mean and variance of the <span class="math inline">\(S_i\)</span>. Define <span class="math inline">\(\overline{S}^{(n)}\)</span> as the average claim amount per policy, i.e.
<span class="math display">\[
\overline{S}^{(n)}=\frac{1}{n}\sum_{i=1}^nS_i.
\]</span>
As long as the random variables <span class="math inline">\(S_i\)</span> are independent, identically distributed, and have finite variance, the law of large numbers assures that
<span class="math display">\[
\overline{S}^{(n)}\to_{\text{proba}}\mu\mbox{ as }n\to +\infty.
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-30" class="proof"><em>Proof</em>. </span>Indeed, the inequality <a href="chap3.html#eq:BTcheby">(4.7)</a> guarantees that
<span class="math display" id="eq:VarArg">\[\begin{equation}
\Pr\Big[\big|\overline{S}^{(n)}-\mu|&gt;\epsilon\Big]\leq\frac{\mathbb{V}\Big[\overline{S}^{(n)}\Big]}{\epsilon^2}=
\frac{\sigma^2}{n\epsilon^2}\to 0\mbox{ as }n\to +\infty.\tag{4.11}
\end{equation}\]</span></p>
</div>
<p>We have thus established that the average claim amount per policy converges to the pure premium. By charging each policyholder an amount of <span class="math inline">\(\mu\)</span>, the company should have sufficient funds to compensate for the losses incurred, with no profit and no deficit.</p>
</div>
<div id="underlying-assumptions" class="section level4 hasAnchor" number="4.5.2.2">
<h4><span class="header-section-number">4.5.2.2</span> Underlying Assumptions<a href="chap3.html#underlying-assumptions" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>It’s worth examining the assumptions underlying <a href="chap3.html#eq:VarArg">(4.11)</a> cautiously, in order to identify situations where using mathematical expectation to calculate the pure premium might not be appropriate:</p>
<ol style="list-style-type: decimal">
<li>Firstly, this result is asymptotic (as “<span class="math inline">\(n\)</span> <em>tends to infinity</em>”). In practice, the portfolio size must be considerable for the law of large numbers to be applicable.</li>
<li>Secondly, the random variables <span class="math inline">\(S_i\)</span> are assumed to be independent. Insurance covering natural catastrophes like floods or earthquakes, which likely affect all risks in a specific geographical area, falls outside the scope of the law of large numbers.</li>
<li>Lastly, the random variables <span class="math inline">\(S_i\)</span> are assumed to be identically distributed. Risks grouped for insurance must be homogeneous, meaning they are of similar nature. There are several aspects of homogeneity:</li>
</ol>
<ul>
<li>Homogeneity in nature: Each risk must be categorized based on its nature. Risks such as “fire” and “liability” cannot be grouped together for statistical analysis. Within each category, further sub-classifications should correspond to similar risk characteristics. For instance, fire risks may be divided into simple risks and industrial risks. Liability risks could be categorized into tenant liability, family liability, etc.</li>
<li>Homogeneity in object: Risks must involve similar individuals or objects. In life insurance, individuals must be categorized by age, gender, and health status. In accident insurance, the profession of the individual should be taken into account (an actuary is a better risk than a construction painter).</li>
<li>Homogeneity in value: Risks should be grouped by their value. All risks don’t need to have the same significance, but there shouldn’t be a significant disparity in value among them.</li>
</ul>
<p>If the risks are not sufficiently numerous, similar, and independent, the law of large numbers won’t be applicable, and risk pooling won’t be feasible. In such a situation, the insurer might consider reinsurance, which involves transferring a portion of the underwritten risks to another company.</p>
<div class="remark">
<p><span id="unlabeled-div-31" class="remark"><em>Remark</em>. </span>It’s possible that for a given coverage, the portfolio of policies allows for risk pooling (satisfying the assumptions of the law of large numbers), but this might not hold true for another coverage. For example, consider an insurer covering fire damage for a large number of identical buildings located in the same city but not adjacent to each other. The principle of risk pooling will likely work well, with all three assumptions of the law of large numbers satisfied. However, these same buildings may not be independent risks for earthquake or flood coverage, necessitating the insurer to seek reinsurance.</p>
</div>
</div>
<div id="unit-premiums-and-probabilities" class="section level4 hasAnchor" number="4.5.2.3">
<h4><span class="header-section-number">4.5.2.3</span> Unit Premiums and Probabilities<a href="chap3.html#unit-premiums-and-probabilities" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We are now in a position to justify the interpretation of the probability of an event as the pure premium associated with a policy that pays 1if the event occurs. In this case, the insurer’s payout can be represented by the random variable
<span class="math display">\[
S=\mathbb{I}[E]=\left\{
\begin{array}{l}
1,\text{ if }E\text{ occurs},\\
0,\text{ otherwise}.
\end{array}
\right.
\]</span>
Clearly, <span class="math inline">\(S\sim\mathcal{B}er(\Pr[E])\)</span>, and the associated pure premium is <span class="math inline">\(\mathbb{E}\big[\mathbb{I}[E]\big]=\Pr[E]\)</span>.</p>
</div>
</div>
<div id="case-of-flat-indemnity" class="section level3 hasAnchor" number="4.5.3">
<h3><span class="header-section-number">4.5.3</span> Case of Flat Indemnity<a href="chap3.html#case-of-flat-indemnity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="at-most-one-claim-per-period" class="section level4 hasAnchor" number="4.5.3.1">
<h4><span class="header-section-number">4.5.3.1</span> At Most One Claim per Period<a href="chap3.html#at-most-one-claim-per-period" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let’s assume the insurer covers <span class="math inline">\(n\)</span> individuals. In the event of a claim, the company is obligated to pay a flat amount <span class="math inline">\(s\)</span>. Each policy results in at most one claim. The random variable <span class="math inline">\(S_i\)</span> representing the company’s reimbursement to individual <span class="math inline">\(i\)</span> is given by
<span class="math display" id="eq:Siflat">\[\begin{equation}
S_i=\left\{
\begin{array}{l}
0,\text{ with probability }1-q,
\\
s,\text{ with probability }q.
\end{array}
\right.\tag{4.12}
\end{equation}\]</span>
If the <span class="math inline">\(S_i\)</span> are independent, then
<span class="math display">\[
\overline{S}^{(n)}\to_{\text{proba}}\mathbb{E}[S_1]=qs.
\]</span>
The difference between <span class="math inline">\(\overline{S}^{(n)}\)</span> and the pure premium <span class="math inline">\(qs\)</span> is bounded using the Bienaymé-Chebyshev inequality by
<span class="math display">\[
\Pr\Big[|\overline{S}^{(n)}-qs|&gt;\epsilon\Big]\leq\frac{1}{n\epsilon^2}s^2q(1-q).
\]</span></p>
</div>
<div id="random-number-of-claims-per-period" class="section level4 hasAnchor" number="4.5.3.2">
<h4><span class="header-section-number">4.5.3.2</span> Random Number of Claims per Period<a href="chap3.html#random-number-of-claims-per-period" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>If the policy can generate more than one claim per period, and the occurrence of any of these claims obligates the insurer to pay <span class="math inline">\(s\)</span>, the company’s expenditure is given by <span class="math inline">\(S_i=sN_i\)</span>, where <span class="math inline">\(N_i\)</span> is the number of claims reported by policy <span class="math inline">\(i\)</span>.</p>
<p>In this case,
<span class="math display">\[
\overline{S}^{(n)}=s\overline{N}^{(n)}\text{ where }\overline{N}^{(n)}=\frac{1}{n}\sum_{i=1}^nN_i
\text{ and }\overline{S}^{(n)}\to_{\text{proba}}
s\mathbb{E}[N_1].
\]</span>
The difference between <span class="math inline">\(\overline{S}^{(n)}\)</span> and the pure premium is controlled by
<span class="math display">\[
\Pr\Big[|\overline{S}^{(n)}-s\mathbb{E}[N_1]|&gt;\epsilon\Big]\leq\frac{1}{n\epsilon^2}s^2\mathbb{V}[N_1].
\]</span></p>
</div>
</div>
<div id="case-of-indemnity-compensation" class="section level3 hasAnchor" number="4.5.4">
<h3><span class="header-section-number">4.5.4</span> Case of Indemnity Compensation<a href="chap3.html#case-of-indemnity-compensation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="without-considering-the-number-of-claims" class="section level4 hasAnchor" number="4.5.4.1">
<h4><span class="header-section-number">4.5.4.1</span> Without Considering the Number of Claims<a href="chap3.html#without-considering-the-number-of-claims" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Now, suppose there’s a probability <span class="math inline">\(q\)</span> that <span class="math inline">\(S_i&gt;0\)</span>, and let <span class="math inline">\(Z_i\)</span> be the amount of the claims when <span class="math inline">\(S_i&gt;0\)</span>, i.e.
<span class="math display" id="eq:Siindemnity">\[\begin{equation}
S_i=\left\{
\begin{array}{l}
0,\text{ with probability }1-q,
\\
Z_i,\text{ with probability }q,
\end{array}
\right.\tag{4.13}
\end{equation}\]</span>
where <span class="math inline">\(Z_1,Z_2,\ldots\)</span> are positive, independent, and identically distributed random variables. In this case, the pure premium will be <span class="math inline">\(\mathbb{E}[S_i]=q\mathbb{E}[Z_i]=q\mu\)</span>.</p>
<p>We can represent <span class="math inline">\(S_i\)</span> as <span class="math inline">\(J_iZ_i\)</span> where <span class="math inline">\(J_i=\mathbb{I}[S_i&gt;0]\)</span>. This time, the difference between <span class="math inline">\(\overline{S}^{(n)}\)</span> and the pure premium <span class="math inline">\(q\mu\)</span> is bounded using the Bienaymé-Chebyshev inequality by
<span class="math display">\[\begin{eqnarray*}
\Pr\Big[|\overline{S}^{(n)}-q\mu|&gt;\epsilon\Big]&amp;\leq&amp;\frac{1}{n\epsilon^2}\mathbb{V}[S_1]\\
&amp;=&amp;\frac{1}{n\epsilon^2}\big(q\sigma^2+\mu^2q(1-q)\big),
\end{eqnarray*}\]</span>
where <span class="math inline">\(\sigma^2=\mathbb{V}[Z_1]\)</span>.</p>
<div class="remark">
<p><span id="unlabeled-div-32" class="remark"><em>Remark</em>. </span>In some cases, it might be useful for the actuary to explicitly include the number of claims made by the insured. In this case, the model could be represented as
<span class="math display">\[
S_i=\sum_{k=1}^{N_i}C_{ik}.
\]</span>
The pure premium would then be
<span class="math display">\[
\mathbb{E}[S_i]=\mathbb{E}[N_i]\mathbb{E}[C_{i1}].
\]</span></p>
</div>
</div>
</div>
</div>
<div id="characteristic-functions" class="section level2 hasAnchor" number="4.6">
<h2><span class="header-section-number">4.6</span> Characteristic Functions<a href="chap3.html#characteristic-functions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="probability-generating-function" class="section level3 hasAnchor" number="4.6.1">
<h3><span class="header-section-number">4.6.1</span> Probability Generating Function<a href="chap3.html#probability-generating-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="definition-6" class="section level4 hasAnchor" number="4.6.1.1">
<h4><span class="header-section-number">4.6.1.1</span> Definition<a href="chap3.html#definition-6" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The probability generating function is a convenient tool for obtaining a series of valuable results for actuaries, although it lacks an intuitive interpretation. It is defined as follows.</p>
<div class="definition">
<p><span id="def:unlabeled-div-33" class="definition"><strong>Definition 4.4  </strong></span>The probability generating function of a random variable <span class="math inline">\(N\)</span> taking values in <span class="math inline">\(\mathbb{N}\)</span>, denoted by <span class="math inline">\(\varphi_N\)</span>, is defined as
<span class="math display">\[
\varphi_N(z)=\mathbb{E}[z^N]=\sum_{j\in\mathbb{N}}\Pr[N=j]z^j,
\quad 0\leq z\leq 1.
\]</span></p>
</div>
<p>This function characterizes the probability distribution of <span class="math inline">\(N\)</span>. In fact, the successive derivatives of <span class="math inline">\(\varphi_N\)</span> evaluated at <span class="math inline">\(z=0\)</span> provide the probabilities <span class="math inline">\(\Pr[N=k]\)</span> with a factor, i.e.,
<span class="math display">\[\begin{eqnarray*}
\Pr[N=0]&amp;=&amp;\varphi_N(0),\\
k!\Pr[N=k]  &amp;=&amp;  \left.\frac{d^k}{dz^k}\varphi_N(z)\right|_{z=0}, \quad k\geq 1.
\end{eqnarray*}\]</span>
The successive derivatives of <span class="math inline">\(\varphi_N\)</span> evaluated at <span class="math inline">\(z=1\)</span> provide the factorial moments, namely
<span class="math display">\[\begin{eqnarray*}
\left.\frac{d}{dz}\varphi_N(z)\right|_{z=1} &amp; = &amp; \mathbb{E}[N],\\
\left.\frac{d^k}{dz^k}\varphi_N(z)\right|_{z=1} &amp;=&amp;  \mathbb{E}[N(N-1)\ldots(N-k+1)], \quad k\geq 1.
\end{eqnarray*}\]</span>
Note that, obviously, <span class="math inline">\(\varphi_N(1)=1\)</span>.</p>
<p>The probability generating functions associated with the common discrete probability distributions are listed in Table <a href="chap3.html#tab:FGPUs">4.3</a>.</p>
<table>
<caption><span id="tab:FGPUs">Table 4.3: </span>Probability Generating Function of Common Discrete Distributions</caption>
<colgroup>
<col width="38%" />
<col width="61%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Probability Law</th>
<th align="center">Probability Generating Function</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{DU}ni(n)\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{n+1}\frac{t^{n+1}-1}{t - 1}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{B}er(q)\)</span></td>
<td align="center"><span class="math inline">\((1-q + q t)\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{B}in(m,q)\)</span></td>
<td align="center"><span class="math inline">\((1-q +qt)^m\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{G}eo(q)\)</span></td>
<td align="center"><span class="math inline">\(\frac{q}{1-(1-q)t}\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{NB}in(\alpha,q)\)</span></td>
<td align="center"><span class="math inline">\(\left( \frac{q}{1-(1-q)t} \right) ^\alpha\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{P}oi(\lambda)\)</span></td>
<td align="center"><span class="math inline">\(\exp( \lambda (t -1))\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="FGPconv" class="section level4 hasAnchor" number="4.6.1.2">
<h4><span class="header-section-number">4.6.1.2</span> Probability Generating Function and Convolution<a href="chap3.html#FGPconv" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The main advantage of the probability generating function lies in its easy handling of convolutions. If we want to find the probability generating function of a sum of independent counting variables, we only need to multiply the probability generating functions of each term, as shown by the following result.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-34" class="proposition"><strong>Proposition 4.10  </strong></span>The probability generating function of <span class="math inline">\(N_\bullet=\sum_{i=1}^nN_i\)</span>, where the <span class="math inline">\(N_i\)</span> are independent, is given by the product of the generating functions <span class="math inline">\(\varphi_{N_i}\)</span> of each term.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-35" class="proof"><em>Proof</em>. </span>We just need to write
<span class="math display">\[\begin{eqnarray*}
\varphi_{N_\bullet}(z) &amp; = &amp; \mathbb{E}\left[z^{\sum_{i=1}^nN_i}\right]=\mathbb{E}\left[\prod_{i=1}^n
z^{N_i}\right] \\
&amp; = &amp; \prod_{i=1}^n\mathbb{E}[z^{N_i}]=\prod_{i=1}^n\varphi_{N_i}(z),\quad
z\in[0,1].
\end{eqnarray*}\]</span></p>
</div>
<p>In particular, if <span class="math inline">\(N_1,\ldots,N_n\)</span> are independent and identically distributed, we have
<span class="math display">\[
\varphi_{N_\bullet}(z)=\{\varphi_{N_1}(z)\}^n.
\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-36" class="example"><strong>Example 4.13  (Convolution of Binomial Distributions with Same Parameter) </strong></span>Let’s consider two independent random variables <span class="math inline">\(N_1\)</span> and <span class="math inline">\(N_2\)</span> with distributions <span class="math inline">\(\mathcal{B}in(m_1,q)\)</span> and <span class="math inline">\(\mathcal{B}in(m_2,q)\)</span> respectively. The probability generating function of the sum <span class="math inline">\(N_1+N_2\)</span> is given by
<span class="math display">\[
\varphi_{N_1+N_2}(z)=\varphi_{N_1}(z)\varphi_{N_2}(z)=\big(1+q(z-1)\big)^{m_1+m_2},
\]</span>
which shows that <span class="math inline">\(N_1+N_2\sim\mathcal{B}in(m_1+m_2,q)\)</span>. Therefore, the Bernoulli distribution provides the foundation for the binomial family, as any random variable <span class="math inline">\(N\)</span> with a <span class="math inline">\(\mathcal{B}in(m,q)\)</span> distribution can be represented as
<span class="math display">\[
N=\sum_{i=1}^mN_i,
\]</span>
where the <span class="math inline">\(N_i\)</span> are independent and follow a <span class="math inline">\(\mathcal{B}er(q)\)</span> distribution.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-37" class="example"><strong>Example 4.14  (Convolution of Poisson Distributions) </strong></span>Let <span class="math inline">\(N_1,N_2,\ldots,N_n\)</span> be independent random variables with Poisson distributions and respective parameters <span class="math inline">\(\lambda_1,\lambda_2,\ldots,\lambda_n\)</span>. Then <span class="math inline">\(N=\sum_{i=1}^nN_i\)</span> follows a Poisson distribution with parameter <span class="math inline">\(\sum_{i=1}^n\lambda_i\)</span>. The probability generating function of <span class="math inline">\(N\)</span> is the product of the probability generating functions of the <span class="math inline">\(N_i\)</span>:
<span class="math display">\[
\varphi_N(z)=\prod_{i=1}^n\exp(\lambda_i(z-1))
=\exp\left((z-1)\sum_{i=1}^n\lambda_i\right),
\]</span>
which makes <span class="math inline">\(N\)</span> a random variable with a Poisson distribution with parameter <span class="math inline">\(\sum_{i=1}^n\lambda_i\)</span>.</p>
</div>
</div>
</div>
<div id="laplace-transform" class="section level3 hasAnchor" number="4.6.2">
<h3><span class="header-section-number">4.6.2</span> Laplace Transform<a href="chap3.html#laplace-transform" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="definition-7" class="section level4 hasAnchor" number="4.6.2.1">
<h4><span class="header-section-number">4.6.2.1</span> Definition<a href="chap3.html#definition-7" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Similar to the probability generating function, the Laplace transform does not have an intuitive interpretation. Again, it is a useful tool for obtaining results in risk theory. This function characterizes the distribution of <span class="math inline">\(X\)</span> and is defined as follows.</p>
<div class="definition">
<p><span id="def:unlabeled-div-38" class="definition"><strong>Definition 4.5  </strong></span>The Laplace transform of a random variable <span class="math inline">\(X\)</span>, denoted by <span class="math inline">\(L_X\)</span>, is given by
<span class="math display">\[
L_X(t)=\mathbb{E}[\exp(-tX)],\quad t\geq 0.
\]</span></p>
</div>
<p>Laplace transform is often used for non-negative random variables. This ensures its existence and makes it a convenient tool for solving many problems in applied probability.</p>
<p>The moments of <span class="math inline">\(X\)</span> can be easily obtained by differentiating <span class="math inline">\(L_X\)</span> and evaluating the derivatives at 0. Specifically,
<span class="math display">\[
\mathbb{E}[X^k]=(-1)^k\left.\frac{d^k}{dt^k}L_{X}(t)\right|_{t=0},
\quad k\in \mathbb{N}.
\]</span></p>
<p>Table <a href="chap3.html#tab:TLFGMUs">4.4</a> presents the Laplace transforms associated with common continuous probability distributions.</p>
<table>
<caption><span id="tab:TLFGMUs">Table 4.4: </span>Laplace Transforms of Common Continuous Probability Distributions.</caption>
<colgroup>
<col width="42%" />
<col width="57%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Probability Law</th>
<th align="center">Laplace transform <span class="math inline">\(L_X(t)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{U}ni(a,b)\)</span></td>
<td align="center"><span class="math inline">\(\frac{\exp(-at)-\exp(-bt)}{(b-a)t}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{B}et(\alpha,\beta)\)</span></td>
<td align="center">No explicit form</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{N}or(\mu,\sigma^2)\)</span></td>
<td align="center"><span class="math inline">\(\exp(-\mu t+\frac{1}{2}\sigma^2t^2)\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{E}xp(\theta)\)</span></td>
<td align="center"><span class="math inline">\(\left(1+\frac{t}{\theta}\right)^{-1}\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{G}am(\alpha,\tau)\)</span></td>
<td align="center"><span class="math inline">\(\left(1+\frac{t}{\tau}\right)^{-\alpha}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{LN}or(\mu,\sigma^2)\)</span></td>
<td align="center">No explicit form</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{P}ar(\alpha,\theta)\)</span></td>
<td align="center">No explicit form</td>
</tr>
</tbody>
</table>
</div>
<div id="bernsteins-theorem" class="section level4 hasAnchor" number="4.6.2.2">
<h4><span class="header-section-number">4.6.2.2</span> Bernstein’s Theorem<a href="chap3.html#bernsteins-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Bernstein’s theorem provides a necessary and sufficient condition for a function to be the Laplace transform of a probability distribution. To do this, recall that a function <span class="math inline">\(g:{\mathbb{R}}^+\to{\mathbb{R}}\)</span> is completely monotone if its derivatives <span class="math inline">\(g^{(k)}\)</span> of all orders satisfy
<span class="math display">\[
(-1)^kg^{(k)}(t)\geq 0\mbox{ for all }t&gt;0.
\]</span></p>
<div class="proposition">
<p><span id="prp:TheoBer" class="proposition"><strong>Proposition 4.11  (Bernstein's Theorem) </strong></span>A function <span class="math inline">\(g\)</span> is the Laplace transform of a positive random variable if and only if it is completely monotone and satisfies <span class="math inline">\(g(0)=1\)</span>.</p>
</div>
</div>
<div id="TLconv" class="section level4 hasAnchor" number="4.6.2.3">
<h4><span class="header-section-number">4.6.2.3</span> Laplace Transform and Convolution<a href="chap3.html#TLconv" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The Laplace transform plays an important role in the analysis of convolutions, as shown by the following result.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-39" class="proposition"><strong>Proposition 4.12  </strong></span>Given non-negative and independent random variables <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span>, denoting their sum as <span class="math inline">\(S=\sum_{i=1}^nX_i\)</span>, the Laplace transform <span class="math inline">\(L_S\)</span> of <span class="math inline">\(S\)</span> is given by the product of the Laplace transforms <span class="math inline">\(L_{X_i}\)</span> of each term.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-40" class="proof"><em>Proof</em>. </span>We can write
<span class="math display">\[\begin{eqnarray*}
L_S(t)&amp;=&amp;\mathbb{E}\left[\exp\left(-t\sum_{i=1}^nX_i\right)\right]
\\
&amp;=&amp;\mathbb{E}\left[\prod_{i=1}^n\exp\left(-tX_i\right)\right]
\\
&amp;=&amp;\prod_{i=1}^n
L_{X_i}(t),\quad t\geq 0.
\end{eqnarray*}\]</span></p>
</div>
<p>Thus, under the assumption of independence, we can easily obtain the Laplace transform of the sum of the <span class="math inline">\(X_i\)</span>, while obtaining the corresponding cumulative distribution function is often very difficult.</p>
<div class="example">
<p><span id="exm:unlabeled-div-41" class="example"><strong>Example 4.15  (Convolution of Gamma Distributions) </strong></span>The Laplace transform expression of the <span class="math inline">\(\mathcal{G}am(\alpha,\tau)\)</span> distribution given in Table <a href="chap3.html#tab:TLFGMUs">4.4</a> reveals a fundamental property of the gamma distribution: its stability under convolution. Indeed, if <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are independent random variables with distributions <span class="math inline">\(\mathcal{G}am(\alpha_1,\tau)\)</span> and <span class="math inline">\(\mathcal{G}am(\alpha_2,\tau)\)</span> respectively, then <span class="math inline">\(X_1+X_2\)</span> follows a <span class="math inline">\(\mathcal{G}am(\alpha_1+\alpha_2,\tau)\)</span> distribution.
To see this, notice that the Laplace transform of <span class="math inline">\(X_1+X_2\)</span> is
<span class="math display">\[
\left(1+\frac{t}{\tau}\right)^{-\alpha_1}
\left(1+\frac{t}{\tau}\right)^{-\alpha_2}
=\left(1+\frac{t}{\tau}\right)^{-\alpha_1-\alpha_2}
\]</span>
which indeed corresponds to the <span class="math inline">\(\mathcal{G}am(\alpha_1+\alpha_2,\tau)\)</span> distribution.</p>
</div>
</div>
<div id="laplace-transform-of-compound-distributions" class="section level4 hasAnchor" number="4.6.2.4">
<h4><span class="header-section-number">4.6.2.4</span> Laplace Transform of Compound Distributions<a href="chap3.html#laplace-transform-of-compound-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The following property will be useful, especially in Chapter <a href="chap8.html#chap8">9</a>, to approximate compound distributions corresponding to mixed distribution variables <a href="#eq:LoiComp">(<strong>??</strong>)</a>.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-42" class="proposition"><strong>Proposition 4.13  </strong></span>The Laplace transform of <span class="math inline">\(S\)</span> defined in <a href="#eq:LoiComp">(<strong>??</strong>)</a>, i.e.
<span class="math inline">\(S=\sum_{i=1}^NX_i\)</span> with <span class="math inline">\(X_i\)</span>, <span class="math inline">\(i=1,2,\ldots\)</span>, independent and identically distributed, and independent of <span class="math inline">\(N\)</span>, is given for <span class="math inline">\(t&gt;0\)</span> by <span class="math inline">\(L_S(t)=\varphi_N(L_{X_1}(t))\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-43" class="proof"><em>Proof</em>. </span>We can write
<span class="math display">\[\begin{eqnarray*}
L_S(t) &amp; = &amp; \mathbb{E}\left[\exp\left(-t\sum_{i=1}^NX_i\right)\right] \\
&amp; = &amp; \sum_{k=0}^{+\infty}\Pr[N=k]\mathbb{E}\left[\exp\left(-t\sum_{i=1}^kX_i
\right)\right] \\
&amp; = &amp; \sum_{k=0}^{+\infty}\Pr[N=k]\{L_{X_1}(t)\}^k = \varphi_N(L_{X_1}(t)).
\end{eqnarray*}\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-44" class="example"><strong>Example 4.16  </strong></span>As <span class="math inline">\(\varphi_{N}(z)=\exp\{\lambda(z-1)\}\)</span> when <span class="math inline">\(N\sim\mathcal{P}oi(\lambda)\)</span>, the Laplace transform of <span class="math inline">\(S\sim\mathcal{CP}oi(\lambda,F_X)\)</span> is
<span class="math display">\[
L_S(t)=\exp\{\lambda(L_X(t)-1)\},\quad t\in {\mathbb{R}}^+.
\]</span></p>
</div>
</div>
<div id="stability-of-compound-poisson-distribution-through-convolution" class="section level4 hasAnchor" number="4.6.2.5">
<h4><span class="header-section-number">4.6.2.5</span> Stability of Compound Poisson Distribution through Convolution<a href="chap3.html#stability-of-compound-poisson-distribution-through-convolution" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Laplace transforms are quite useful for obtaining results involving convolutions, like the following property.</p>
<div class="proposition">
<p><span id="prp:StabConvPC" class="proposition"><strong>Proposition 4.14  </strong></span>Consider independent random variables
<span class="math inline">\(S_1\sim\mathcal{CP}oi(\lambda_1,F_1)\)</span>, , <span class="math inline">\(S_n\sim\mathcal{CP}oi(\lambda_n,F_n)\)</span>.
Then
<span class="math display">\[
S=\sum_{j=1}^nS_j\sim\mathcal{CP}oi(\lambda_\bullet,F_\bullet),
\]</span>
where
<span class="math display">\[
\lambda_\bullet=\sum_{j=1}^n\lambda_j\text{ and }F_\bullet(x)=\frac{1}{\lambda_\bullet}
\sum_{j=1}^n\lambda_jF_j(x),\quad x\in\mathbb{R}.
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-45" class="proof"><em>Proof</em>. </span>It is enough to write
<span class="math display">\[
L_S(t)=\prod_{j=1}^nL_{S_j}(t)=\prod_{j=1}^n\exp\{\lambda_j(L_j(t)-1)\},
\]</span>
where <span class="math inline">\(L_j\)</span> is the Laplace transform of the distribution corresponding to the cumulative distribution function <span class="math inline">\(F_j\)</span>. The result is then obtained by noticing that
<span class="math display">\[
L_s(t)=\exp\{\lambda_\bullet(L_\bullet(t)-1)\},
\]</span>
where the Laplace transform
<span class="math display">\[
L_\bullet(t)=\frac{1}{\lambda_\bullet}\sum_{j=1}^n\lambda_jL_j(t)
\]</span>
corresponds to the cumulative distribution function <span class="math inline">\(F_\bullet\)</span>.</p>
</div>
</div>
<div id="the-case-of-infinite-variance-risks" class="section level4 hasAnchor" number="4.6.2.6">
<h4><span class="header-section-number">4.6.2.6</span> The Case of Infinite Variance Risks<a href="chap3.html#the-case-of-infinite-variance-risks" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We saw in Property <a href="chap3.html#prp:LLN">4.9</a> that the law of large numbers guarantees (under certain assumptions) the convergence of the average claim amount to the pure premium. However, the reasoning based on <a href="#eq:ArguVar">(<strong>??</strong>)</a> assumes that the <span class="math inline">\(S_i\)</span> have finite variance. The result still holds if the <span class="math inline">\(S_i\)</span> have infinite variance (which is sometimes the case when the actuary deals with very large claim amounts, invoking the Pareto distribution).</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-46" class="proposition"><strong>Proposition 4.15  </strong></span>Let <span class="math inline">\(S_1,S_2,\ldots,S_n\)</span> be non-negative, independent, and identically distributed random variables with finite mean. Then <span class="math inline">\(\overline{S}^{(n)}\to_{\text{prob}}\mu\)</span> as <span class="math inline">\(n\to +\infty\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-47" class="proof"><em>Proof</em>. </span>Let <span class="math inline">\(L_S\)</span> be the common Laplace transform of the <span class="math inline">\(S_i\)</span>. The Laplace transform of the sum <span class="math inline">\(S_1+S_2+\ldots+S_n\)</span> is <span class="math inline">\(L_S^n\)</span>, and that of <span class="math inline">\(\overline{S}^{(n)}\)</span> is
<span class="math display">\[
L_{\overline{S}^{(n)}}(t)=\left\{L_S\left(\frac{t}{n}\right)\right\}^n.
\]</span>
Now, a limited Taylor expansion (to the first order) gives
<span class="math display">\[
L_S(t)=1-\mu t+o(t),
\]</span>
where <span class="math inline">\(o(t)\)</span> is such that
<span class="math display">\[
\lim_{t\to 0}\frac{o(t)}{t}=0,
\]</span>
i.e., a function that tends to 0 faster than the identity function (<span class="math inline">\(o(t)\)</span> is negligible for small values of <span class="math inline">\(t\)</span>). Therefore, as <span class="math inline">\(n\to +\infty\)</span>
<span class="math display">\[\begin{eqnarray*}
\lim_{n\to +\infty}L_{\overline{S}^{(n)}}(t)&amp;=&amp;\lim_{n\to +\infty}\left\{L_S\left(\frac{t}{n}\right)\right\}^n\\
&amp;=&amp;\lim_{n\to +\infty}\left\{1-\frac{\mu t}{n}\right\}^n=\exp(-t\mu).
\end{eqnarray*}\]</span>
Since <span class="math inline">\(\exp(-t\mu)\)</span> is the Laplace transform associated with the constant <span class="math inline">\(\mu\)</span>, we indeed recover the convergence of <span class="math inline">\(\overline{S}^{(n)}\)</span> to <span class="math inline">\(\mu\)</span>.</p>
</div>
<p>Thus, coverage of risks with infinite variance remains possible. However, intuitively, we can sense that it would be a risky endeavor—it deals with risks for which the spread around the pure premium is infinite!</p>
</div>
</div>
<div id="moment-generating-function" class="section level3 hasAnchor" number="4.6.3">
<h3><span class="header-section-number">4.6.3</span> Moment Generating Function<a href="chap3.html#moment-generating-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="definition-8" class="section level4 hasAnchor" number="4.6.3.1">
<h4><span class="header-section-number">4.6.3.1</span> Definition<a href="chap3.html#definition-8" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The moment generating function complements the actuary’s toolkit. It naturally appears in ruin theory and allows for classifying probability distributions according to their associated risks. Unlike the Laplace transform, it is not always defined for non-negative random variables.</p>
<div class="definition">
<p><span id="def:unlabeled-div-48" class="definition"><strong>Definition 4.6  </strong></span>Given a random variable <span class="math inline">\(X\)</span>, its moment generating function <span class="math inline">\(M_X\)</span> is defined as
<span class="math display">\[
M_X(t)=\mathbb{E}[\exp(tX)],\quad t\geq 0.
\]</span></p>
</div>
<p>We can see that the difference between the Laplace transform and the moment generating function is essentially formal (<span class="math inline">\(-t\)</span> is replaced by <span class="math inline">\(t\)</span>). In actuarial science, it is customary to distinguish between these two tools.</p>
</div>
<div id="log-normal-distribution" class="section level4 hasAnchor" number="4.6.3.2">
<h4><span class="header-section-number">4.6.3.2</span> Log-Normal Distribution<a href="chap3.html#log-normal-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The moments of the log-normal distribution can be easily obtained from the moment generating function of the normal distribution, as shown in the following example.</p>
<div class="example">
<p><span id="exm:2MomLN" class="example"><strong>Example 4.17  (Moments of the Log-Normal Distribution) </strong></span>When <span class="math inline">\(X\sim\mathcal{LN}or(\mu,\sigma^2)\)</span>, <span class="math inline">\(X\)</span> has the same distribution as <span class="math inline">\(\exp(Y)\)</span> where <span class="math inline">\(Y\sim\mathcal{N}or(\mu,\sigma^2)\)</span>.
Therefore,
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[X]=\mathbb{E}[\exp(Y)] &amp; = &amp; M_Y(1)=\exp(\mu+\sigma^2/2),
\end{eqnarray*}\]</span>
and
<span class="math display">\[
\mathbb{E}[X^2]=M_Y(2)=\mathbb{E}[\exp(2Y)]=\exp(2\mu+2\sigma^2),
\]</span>
from which we deduce
<span class="math display">\[\begin{eqnarray*}
\mathbb{V}[X]&amp;=&amp;\exp(2\mu+2\sigma^2)-\exp(2\mu+\sigma^2)\\
&amp;=&amp;\exp(2\mu)\exp(\sigma^2)(\exp(\sigma^2)-1).
\end{eqnarray*}\]</span>
Thus, the two parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> influence the variability of <span class="math inline">\(X\)</span>.</p>
</div>
<p>However, an exponential decay of the tail does not necessarily guarantee the finiteness of the moment generating function. The example of the log-normal distribution illustrates this point. All the moments associated with this distribution exist and are finite. Specifically, if <span class="math inline">\(X\sim\mathcal{LN}or(\mu,\sigma^2)\)</span>, then, generalizing Example <a href="chap3.html#exm:2MomLN">4.17</a>:
<span class="math display">\[
\mathbb{E}[X^k]=\exp(k\mu+\frac{1}{2}k^2\sigma^2),\quad k=1,2,\ldots
\]</span>
However, the moment generating function <span class="math inline">\(M_X(t)\)</span> is always infinite, regardless of the value of <span class="math inline">\(t\)</span>. As a result, the Pareto distribution <span class="math inline">\(\mathcal{P}ar(\alpha,\theta)\)</span> (for which moments of order <span class="math inline">\(k&gt;\alpha\)</span> are infinite) does not have a moment generating function.</p>
</div>
<div id="cramérs-distribution" class="section level4 hasAnchor" number="4.6.3.3">
<h4><span class="header-section-number">4.6.3.3</span> Cramér’s Distribution<a href="chap3.html#cramérs-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In addition to its use in certain mathematical developments, the moment generating function is a convenient tool for assessing the level of risk associated with a distribution used to model the cost of claims. Unlike the Laplace transform, the moment generating function is not necessarily finite. Distributions for which <span class="math inline">\(M_X\)</span> is constantly infinite indicate a high level of risk for the insurer. The Log-Normal and Pareto distributions fall into this category.</p>
<p>On the contrary, Cramér’s distributions are those for which the moment generating function is finite for at least one positive value of its argument. Such distributions reflect a low or moderate degree of risk for the insurer.</p>
<div class="definition">
<p><span id="def:unlabeled-div-49" class="definition"><strong>Definition 4.7  </strong></span>The random variable <span class="math inline">\(X\)</span> has a Cramér distribution if there exists <span class="math inline">\(h&gt;0\)</span> such that <span class="math inline">\(M_X(t)\)</span> exists and is finite for <span class="math inline">\(t&lt;h\)</span>.</p>
</div>
<p>We obtain by expanding the exponential in a Taylor series:
<span class="math display">\[
M_X(t)=1+\sum_{k=1}^{+\infty}\frac{t^k}{k!}\mathbb{E}[X^k]\text{ for }t&lt;h.
\]</span></p>
<p>Table <a href="chap3.html#tab:TLFGMUs2">4.5</a> summarizes the moment generating functions of common continuous probability distributions.</p>
<table>
<caption><span id="tab:TLFGMUs2">Table 4.5: </span>Moment generating functions of common continuous probability distributions.</caption>
<colgroup>
<col width="38%" />
<col width="61%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Probability Law</th>
<th align="center">Moment Generating Function <span class="math inline">\(M_X(t)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{U}ni(a,b)\)</span></td>
<td align="center"><span class="math inline">\(\frac{\exp(bt)-\exp(at)}{(b-a)t}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{B}et(\alpha,\beta)\)</span></td>
<td align="center">no explicit form</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{N}or(\mu,\sigma^2)\)</span></td>
<td align="center"><span class="math inline">\(\exp(\mu t + \frac{1}{2}\sigma^2t^2)\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{E}xp(\theta)\)</span></td>
<td align="center"><span class="math inline">\(\left(1-\frac{t}{\theta}\right)^{-1}\)</span> if <span class="math inline">\(t&lt;\theta\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{G}am(\lambda, \alpha)\)</span></td>
<td align="center"><span class="math inline">\(\left(1-\frac{t}{\tau}\right)^{-\alpha}\)</span> if <span class="math inline">\(t&lt;\tau\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="FGMconv" class="section level4 hasAnchor" number="4.6.3.4">
<h4><span class="header-section-number">4.6.3.4</span> Moment Generating Function and Convolution<a href="chap3.html#FGMconv" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Similar to the Laplace transform, the primary interest of the moment generating function lies in the study of sums of random variables. Indeed, the sum of independent random variables amounts to taking the product of the moment generating functions.</p>
<div class="{.proposition">
<p>Given non-negative independent random variables <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span>, and denoting their sum as <span class="math inline">\(S=\sum_{i=1}^nX_i\)</span>, the moment generating function <span class="math inline">\(M_S\)</span> of <span class="math inline">\(S\)</span> is given by the product of the moment generating functions <span class="math inline">\(M_{X_i}\)</span> of each term.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-50" class="proof"><em>Proof</em>. </span>It suffices to write
<span class="math display">\[\begin{eqnarray*}
M_S(t)&amp;=&amp;\mathbb{E}\left[\exp\left(t\sum_{i=1}^nX_i\right)\right]\\
&amp;=&amp;\mathbb{E}\left[\prod_{i=1}^n\exp(tX_i)\right]\\
&amp;=&amp;\prod_{i=1}^nM_{X_i}(t).
\end{eqnarray*}\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-51" class="example"><strong>Example 4.18  (Convolution of Normal Distributions) </strong></span>If <span class="math inline">\(X\sim\mathcal{N}or(\mu,\sigma^2)\)</span>,
<span class="math display">\[
M_X(t)=\exp(\mu t+\frac{1}{2}t^2\sigma^2).
\]</span>
This allows us to assert that given independent random variables <span class="math inline">\(X_i\sim\mathcal{N}or(\mu_i,\sigma_i^2)\)</span>, any linear combination <span class="math inline">\(T=\sum_{i=1}^n\alpha_iX_i\)</span> is also normally distributed. Indeed, the moment generating function of <span class="math inline">\(T\)</span> is given by
<span class="math display">\[
\prod_{i=1}^n\mathbb{E}[\exp(\alpha_itX_i)]=\exp\left(\sum_{i=1}^n\alpha_i\mu_i+\frac{t^2}{2}\sum_{i=1}^n\alpha_i^2\sigma_i^2\right),
\]</span>
which implies that
<span class="math display">\[
\sum_{i=1}^n\alpha_iX_i\sim\mathcal{N}or\left(\sum_{i=1}^n\alpha_i\mu_i,\sum_{i=1}^n\alpha_i^2\sigma_i^2\right).
\]</span></p>
</div>
</div>
<div id="chernoff-bound" class="section level4 hasAnchor" number="4.6.3.5">
<h4><span class="header-section-number">4.6.3.5</span> Chernoff Bound<a href="chap3.html#chernoff-bound" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>This very useful bound holds for Cramér’s distributions.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-52" class="proposition"><strong>Proposition 4.16  </strong></span>Let <span class="math inline">\(X\)</span> be a random variable with a finite moment generating function, and denote
<span class="math display">\[
\Psi(t)=\ln M_X(t).
\]</span>
We have
<span class="math display">\[
\overline{F}_X(x)\leq\exp(-h(x))\text{ where }h(x)=\sup_{t\geq 0}\{tx-\Psi(t)\}.
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-53" class="proof"><em>Proof</em>. </span>The Markov inequality stated in Property <a href="#prp:IneqMarkov"><strong>??</strong></a> gives
<span class="math display">\[\begin{eqnarray*}
\overline{F}_X(x)&amp;=&amp;\Pr[\exp(tX)&gt;\exp(tx)]\\
&amp;\leq&amp;\frac{M_X(t)}{\exp(tx)}=\exp(-(tx-\Psi(t))).
\end{eqnarray*}\]</span>
Since the above reasoning applies for any <span class="math inline">\(t&gt;0\)</span>, we deduce the announced result from the existence of a moment generating function.</p>
</div>
<p>A random variable with a moment generating function must therefore necessarily have a tail function that exponentially decreases to 0.</p>
</div>
</div>
<div id="hazard-rate" class="section level3 hasAnchor" number="4.6.4">
<h3><span class="header-section-number">4.6.4</span> Hazard Rate<a href="chap3.html#hazard-rate" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="definition-9" class="section level4 hasAnchor" number="4.6.4.1">
<h4><span class="header-section-number">4.6.4.1</span> Definition<a href="chap3.html#definition-9" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>An interesting quantity is the hazard rate (also known as the instantaneous death rate in life insurance), defined as follows.</p>
<div class="definition">
<p><span id="def:unlabeled-div-54" class="definition"><strong>Definition 4.8  </strong></span>Let <span class="math inline">\(X\)</span> be a positive random variable with a probability density function <span class="math inline">\(f_X\)</span>. The hazard rate associated with <span class="math inline">\(X\)</span>, denoted as <span class="math inline">\(r_X\)</span>, is given by
<span class="math display" id="eq:DefTaux">\[\begin{equation}
r_X(x)=-\frac{d}{dx}\ln\overline{F}(x)=\frac{f_X(x)}{\overline{F}_X(x)},\hspace{2mm}
x\in {\mathbb{R}}^+.\tag{4.14}
\end{equation}\]</span></p>
</div>
</div>
<div id="interpretation" class="section level4 hasAnchor" number="4.6.4.2">
<h4><span class="header-section-number">4.6.4.2</span> Interpretation<a href="chap3.html#interpretation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To better understand the meaning of the hazard rate, it is useful to refer to the following representation of <span class="math inline">\(r_X\)</span>.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-55" class="proposition"><strong>Proposition 4.17  </strong></span>The hazard rate can be obtained through the following limit:
<span class="math display">\[
r_X(x)=\lim_{\Delta x\to 0}\frac{\Pr[x&lt;X\leq x+\Delta x|X&gt;x]}
{\Delta x}.
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-56" class="proof"><em>Proof</em>. </span>Indeed,
<span class="math display">\[\begin{eqnarray*}
\Pr[x&lt;X\leq x+\Delta x|X&gt;x] &amp; = &amp; \frac{\Pr[x&lt;X\leq x+\Delta x]}{\Pr[X&gt;x]} \\
&amp; = &amp; \frac{\Pr[X&gt;x]-\Pr[X&gt;x+\Delta x]}{\Pr[X&gt;x]},
\end{eqnarray*}\]</span>
thus
<span class="math display">\[\begin{eqnarray*}
&amp; &amp; \lim_{\Delta x\to 0}\frac{\Pr[x&lt;X\leq x+\Delta x|X&gt;x]}
{\Delta x} \\
&amp; = &amp; \frac{1}{\Pr[X&gt;x]}\lim_{\Delta x\to 0}\frac{\Pr[X&gt;x]-\Pr[X&gt;x+\Delta x]}
{\Delta x} \\
&amp; = &amp; -\frac{1}{\Pr[X&gt;x]}\frac{d}{dx}\Pr[X&gt;x] =r_X(x).
\end{eqnarray*}\]</span></p>
</div>
<p>In other words, <span class="math inline">\(r_X(x)\Delta x\)</span> can be interpreted as the probability that the claim amount is approximately equal to <span class="math inline">\(x\)</span> given that it is at least <span class="math inline">\(x\)</span>. Formally, the hazard rate of a risk <span class="math inline">\(X\)</span> allows us to approximate the “probability” that <span class="math inline">\(X\)</span> is equal to <span class="math inline">\(x\)</span>, given that <span class="math inline">\(X\)</span> exceeds <span class="math inline">\(x\)</span>, i.e.
<span class="math display">\[
r_X(x)\Delta x\approx \Pr[x&lt;X\leq x+\Delta x|X&gt;x].
\]</span></p>
<div class="remark">
<p><span id="unlabeled-div-57" class="remark"><em>Remark</em>. </span>It is interesting to compare this interpretation with the one held by the density function. We have seen in the previous chapter that the density function <span class="math inline">\(f_X\)</span> of a risk <span class="math inline">\(X\)</span> evaluated at <span class="math inline">\(x\)</span> can be interpreted as the “probability” that <span class="math inline">\(X\)</span> is “equal” to <span class="math inline">\(x\)</span>, since
<span class="math display">\[
f_X(x)=\lim_{\Delta x\to 0}\frac{\Pr[x&lt;X\leq x+\Delta x]}{\Delta x},
\]</span>
so that the approximation
<span class="math display">\[
f_X(x)\Delta x\approx \Pr[x&lt;X\leq x+\Delta x]
\]</span>
is valid for sufficiently small <span class="math inline">\(\Delta x\)</span>.</p>
</div>
</div>
<div id="connection-with-the-tail-function" class="section level4 hasAnchor" number="4.6.4.3">
<h4><span class="header-section-number">4.6.4.3</span> Connection with the Tail Function<a href="chap3.html#connection-with-the-tail-function" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The following result shows that it is possible to express the tail function of <span class="math inline">\(x\)</span> in terms of the hazard rate <span class="math inline">\(r_X\)</span>.</p>
<div class="proposition">
<p><span id="prp:TauxQueue" class="proposition"><strong>Proposition 4.18  </strong></span>The tail function of a positive random variable <span class="math inline">\(X\)</span> is expressed as follows in terms of the associated hazard rate <span class="math inline">\(r_X\)</span>:
<span class="math display" id="eq:SurvFunct">\[\begin{equation}
\overline{F}(x)=\exp\left(-\int_{\xi=0}^xr_X(\xi)d\xi\right),
\hspace{2mm}x\geq 0.\tag{4.15}
\end{equation}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-58" class="proof"><em>Proof</em>. </span>It is sufficient to solve the differential equation <a href="chap3.html#eq:DefTaux">(4.14)</a> with the initial condition <span class="math inline">\(\overline{F}(0)=1\)</span>.</p>
</div>
<p>Property <a href="chap3.html#prp:TauxQueue">4.18</a> shows that the hazard rate <span class="math inline">\(r_X\)</span> characterizes the probability distribution of <span class="math inline">\(X\)</span>.</p>
</div>
</div>
<div id="stop-loss-premiums" class="section level3 hasAnchor" number="4.6.5">
<h3><span class="header-section-number">4.6.5</span> Stop-Loss Premiums<a href="chap3.html#stop-loss-premiums" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="definition-10" class="section level4 hasAnchor" number="4.6.5.1">
<h4><span class="header-section-number">4.6.5.1</span> Definition<a href="chap3.html#definition-10" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A stop-loss reinsurance treaty involves having the reinsurer take over the part of the total claim amount <span class="math inline">\(S\)</span> that exceeds a certain amount <span class="math inline">\(d\)</span>. The reinsured portion, denoted as <span class="math inline">\(S^R\)</span>, is thus defined by
<span class="math display">\[
S^R=(S-d)_+=\left\{ \begin{array} {l}
0, \mbox{ if } S\leq d,\\
S-d, \mbox{ if } S&gt;d.
\end{array}
\right.
\]</span>
Note that this risk transfer between the insurer and the reinsurer is similar to the mandatory deductible clause imposed on insured parties by an insurance company, a clause that we examined in detail in Section <a href="chap2.html#DecOblig">3.15.2</a>.</p>
<p>The pure premium that the cedent must pay to the reinsurer for such a contract, called the stop-loss premium, is given by
<span class="math display">\[
\mathbb{E}[S^R]=\mathbb{E}[(S-d)_+].
\]</span>
This leads to the following definition.</p>
<div class="definition">
<p><span id="def:unlabeled-div-59" class="definition"><strong>Definition 4.9  </strong></span>Given a risk <span class="math inline">\(X\)</span>, the stop-loss premium for a retention <span class="math inline">\(t\geq 0\)</span> is defined as
<span class="math display">\[
\pi_X(t)  =  \mathbb{E}[(X-t)_+] .
\]</span>
The function <span class="math inline">\(\pi_X\)</span> is also called the stop-loss transform of the random variable <span class="math inline">\(X\)</span>.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-60" class="remark"><em>Remark</em>. </span>Even though formally there is no distinction between the stop-loss premium <span class="math inline">\(\mathbb{E}[(X-t)_+]\)</span> and the price of a call option on an asset whose value at the exercise time is <span class="math inline">\(X\)</span> and <span class="math inline">\(t\)</span> denotes the exercise price, they are two quite different mathematical entities.</p>
<p>Indeed, the stop-loss premium is calculated using the physical or historical probability distribution, while in the case of the call option, a change of measure is applied beforehand to switch to the risk-neutral probability distribution (which avoids arbitrage opportunities).</p>
<p>Apart from the fact that insurance markets are incomplete, invalidating many results from classical financial theory, the actuary works with the historical probability measure, while the financier switches to the risk-neutral measure.</p>
</div>
</div>
<div id="properties-1" class="section level4 hasAnchor" number="4.6.5.2">
<h4><span class="header-section-number">4.6.5.2</span> Properties<a href="chap3.html#properties-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Integration by parts yields the following result quite easily.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-61" class="proposition"><strong>Proposition 4.19  </strong></span>The stop-loss transform can be expressed as follows using the tail function:
<span class="math display" id="eq:RepPSL">\[\begin{equation}
\pi_X(t)=\int_{x=t}^{+\infty}\overline{F}_X(x)dx.\tag{4.16}
\end{equation}\]</span></p>
</div>
<p>Representation <a href="chap3.html#eq:RepPSL">(4.16)</a> also allows us to derive the following characteristics of the stop-loss transform <span class="math inline">\(\pi_X\)</span>.</p>
<div class="proposition">
<p><span id="prp:MS1510" class="proposition"><strong>Proposition 4.20  </strong></span>Assuming <span class="math inline">\(\mathbb{E}[X]&lt;+\infty\)</span>. The stop-loss transform <span class="math inline">\(\pi_X\)</span> has the following properties:</p>
<ol style="list-style-type: decimal">
<li>It is decreasing and convex.</li>
<li><span class="math inline">\(\lim_{t\to +\infty}\pi_X(t)=0\)</span> and <span class="math inline">\(\lim_{t\to -\infty}\{\pi_X(t)+t\}=\mathbb{E}[X]\)</span>.</li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-62" class="proof"><em>Proof</em>. </span></p>
<ol style="list-style-type: decimal">
<li>is immediately deduced from the representation <a href="chap3.html#eq:RepPSL">(4.16)</a>. As for (2), the first limit is obtained from <a href="chap3.html#eq:RepPSL">(4.16)</a>, while the second comes from
<span class="math display">\[
\lim_{t\to -\infty}\{\pi_X(t)+t\}=\lim_{t\to -\infty}\mathbb{E}[\max\{X,t\}]=\mathbb{E}[X].
\]</span></li>
</ol>
</div>
<p>The following property is also quite interesting. It states that a function satisfying conditions (1)-(2) in Property <a href="chap3.html#prp:MS1510">4.20</a> is the stop-loss transform associated with a risk <span class="math inline">\(X\)</span>.</p>
<div class="proposition">
<p><span id="prp:MS1510b" class="proposition"><strong>Proposition 4.21  </strong></span>If the function <span class="math inline">\(g\)</span> satisfies (1)-(2) in Property <a href="chap3.html#prp:MS1510">4.20</a>, there exists a risk <span class="math inline">\(X\)</span> such that <span class="math inline">\(g=\pi_X\)</span>. The cumulative distribution function of <span class="math inline">\(X\)</span> is given by
<span class="math display">\[
F_X(t)=1+g_+&#39;(t),
\]</span>
where <span class="math inline">\(g_+&#39;\)</span> is the right derivative of <span class="math inline">\(g\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-63" class="proof"><em>Proof</em>. </span>If <span class="math inline">\(g\)</span> is convex, then the right derivative <span class="math inline">\(g_+&#39;\)</span> exists and is non-decreasing and continuous from the right. Additionally,
<span class="math display">\[
\lim_{t\to +\infty}g(t)=0\Rightarrow \lim_{t\to+\infty}g_+&#39;(t)=0
\]</span>
and <span class="math inline">\(\lim_{t\to -\infty}\{g(t)+t\}\)</span> can only exist if <span class="math inline">\(\lim_{t\to -\infty}g_+&#39;(t)=-1\)</span>. Thus, <span class="math inline">\(1+g_+&#39;\)</span> is a distribution function, denoted as <span class="math inline">\(F_X\)</span>. Taking <span class="math inline">\(X=F_X^{-1}(U)\)</span> concludes the proof.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-64" class="remark"><em>Remark</em>. </span>Property <a href="chap3.html#prp:MS1510b">4.21</a> also teaches us that the stop-loss transform <span class="math inline">\(\pi_X\)</span> characterizes the probability distribution of <span class="math inline">\(X\)</span>.</p>
</div>
</div>
<div id="average-excess-of-loss" class="section level4 hasAnchor" number="4.6.5.3">
<h4><span class="header-section-number">4.6.5.3</span> Average Excess of Loss<a href="chap3.html#average-excess-of-loss" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Another interesting quantity in the analysis of claim distributions, quite similar to the stop-loss premium, is the average excess of loss (also known as remaining lifetime in life insurance), defined as follows.</p>
<div class="definition">
<p><span id="def:unlabeled-div-65" class="definition"><strong>Definition 4.10  </strong></span>Given a risk <span class="math inline">\(X\)</span>, the average excess of loss <span class="math inline">\(e_X\)</span> is defined as
<span class="math display">\[\begin{eqnarray*}
e_X(x) &amp; = &amp; \mathbb{E}[X-x|X&gt;x] \\
&amp; = &amp; \frac{\int_{\xi=x}^{+\infty}(\xi-x)dF_X(\xi)}{\overline{F}_X(x)},
\hspace{2mm}x\geq 0.
\end{eqnarray*}\]</span></p>
</div>
<p>It represents the average claim amount when a mandatory deductible of amount <span class="math inline">\(x\)</span> is applied by the company. A distribution for which <span class="math inline">\(e_X\)</span> only slowly tends to 0 is less favorable for the insurer compared to another distribution where the convergence to 0 is rapid.</p>
<p>The average excess of loss for common continuous distributions is presented in Table <a href="chap3.html#tab:Tab441Partrat">4.6</a> (including their asymptotic behavior as <span class="math inline">\(x\to +\infty\)</span>). Starting from <a href="chap3.html#eq:RepPSL">(4.16)</a>, it is straightforward to observe that
<span class="math display">\[
\pi_X(t)=e_X(t)\overline{F}_X(t),
\]</span>
so that the stop-loss premiums associated with common probability distributions can be derived easily from Table <a href="chap3.html#tab:Tab441Partrat">4.6</a>.</p>
<table>
<caption><span id="tab:Tab441Partrat">Table 4.6: </span>Average Excess of Loss for common continuous probability distributions.</caption>
<colgroup>
<col width="19%" />
<col width="64%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Probability law</th>
<th align="center">Average Excess of Loss</th>
<th align="center">Asymptotic Equivalent <span class="math inline">\((x\to +\infty)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{E}xp(\theta)\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{\theta}\)</span></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{G}am(\alpha,\tau)\)</span></td>
<td align="center"><span class="math inline">\(\frac{\alpha}{\tau}\frac{1-\Gamma(\alpha+1,\tau x)}{1-\Gamma(\alpha,\tau x)}-x\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{\tau}\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{LN}or(\mu,\sigma^2)\)</span></td>
<td align="center"><span class="math inline">\(\exp(\mu+\frac{\sigma^2}{2})\frac{\overline{\Phi}\left(\frac{\ln(x)-\mu-\sigma^2}{\sigma}\right)}{\overline{\Phi}\left(\frac{\ln(x)-\mu}{\sigma}\right)}-x\)</span></td>
<td align="center"><span class="math inline">\(\sigma^2\frac{x}{\ln x}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{P}ar(\alpha,\theta)\)</span> with <span class="math inline">\(\alpha&gt;1\)</span></td>
<td align="center"><span class="math inline">\(\frac{\theta+x}{\alpha-1}\)</span></td>
<td align="center"></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="Hetero" class="section level2 hasAnchor" number="4.7">
<h2><span class="header-section-number">4.7</span> Heterogeneity and Mixtures<a href="chap3.html#Hetero" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="context" class="section level2 hasAnchor" number="4.8">
<h2><span class="header-section-number">4.8</span> Context<a href="chap3.html#context" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>So far, we have assumed that the risks in the portfolio are independent and identically distributed. In most insurances sold to the general public, the dependence between insured risks is not a major issue. In automobile liability insurance, family liability insurance, or theft insurance, it is usually negligible. In fire insurance, it can be easily managed through proper underwriting practices or an appropriate reinsurance program. However, in some cases, the actuary must carefully examine the consequences of dependence; examples include the “earthquake” or “flood” component of fire insurance. The assumption of identical distribution, however, is much less clear. It is clear that certain characteristics of risks influence the probability of a claim occurring or the extent of its consequences.</p>
<p>One of the key features of insurance is that not all individuals are equal in the face of risk: some have a propensity to cause much higher or more frequent claims than others. When these insured parties are mixed in the insurer’s portfolio, it results in some heterogeneity: individuals with a low level of risk coexist with others whose risk level is higher. The insurer can partially address this problem by partitioning the portfolio into more homogeneous risk classes. As we will see later, this is achieved by using observable characteristics of insured parties that significantly influence risk. Even if the portfolio is divided into sub-classes, they often remain very heterogeneous. This heterogeneity of risks covered by the insurer is captured by the mixture models we study in this section.</p>
<div id="a-simple-example" class="section level3 hasAnchor" number="4.8.1">
<h3><span class="header-section-number">4.8.1</span> A Simple Example…<a href="chap3.html#a-simple-example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="a-portfolio-with-two-types-of-risks" class="section level4 hasAnchor" number="4.8.1.1">
<h4><span class="header-section-number">4.8.1.1</span> A Portfolio with Two Types of Risks<a href="chap3.html#a-portfolio-with-two-types-of-risks" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let’s revisit Example <a href="#exm:Voyage"><strong>??</strong></a> and assume that the risk of loss or theft of luggage varies depending on the traveler’s destination. For countries in group A, let’s say the insurer has to pay the fixed indemnity of 250in 10% of cases, on average, while for countries in group B, the fixed indemnity will be paid in 20% of cases. Thus, for travelers to countries in group A, the insurer’s expense is represented by the random variable
<span class="math display">\[
S_A=\left\{
\begin{array}{l}
0,\text{ with probability }0.9,\\
250\text{Euros},\text{ with probability }0.1
\end{array}
\right.
\]</span>
while for a traveler to countries in group B, the expense becomes
<span class="math display">\[
S_B=\left\{
\begin{array}{l}
0,\text{ with probability }0.8,\\
250\text{Euros},\text{ with probability }0.2.
\end{array}
\right.
\]</span></p>
</div>
<div id="pure-premiums" class="section level4 hasAnchor" number="4.8.1.2">
<h4><span class="header-section-number">4.8.1.2</span> Pure Premiums<a href="chap3.html#pure-premiums" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The insurer should therefore charge a pure premium of <span class="math inline">\(\mathbb{E}[S_A]=25\text{Euros}\)</span> for a traveler departing to a country in group A, compared to <span class="math inline">\(\mathbb{E}[S_B]=50\text{Euros}\)</span> for another traveler heading to a country in group B. Suppose that 50% of trips are to countries in group A, and 50% to countries in group B. In the portfolio, 50% of insured parties who incur expenses according to the distribution of <span class="math inline">\(S_A\)</span> coexist with the other half who incur expenses according to the distribution of <span class="math inline">\(S_B\)</span>. This portfolio is therefore heterogeneous, mixing two types of risks.</p>
</div>
<div id="total-pure-premium-income" class="section level4 hasAnchor" number="4.8.1.3">
<h4><span class="header-section-number">4.8.1.3</span> Total Pure Premium Income<a href="chap3.html#total-pure-premium-income" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The total premium income of the company for this portfolio is
<span class="math display">\[
n_A\mathbb{E}[S_A]+n_B\mathbb{E}[S_B]=75 n_A,
\]</span>
where <span class="math inline">\(n_A\)</span> represents the number of policies covering travelers to countries in group A, and <span class="math inline">\(n_B=n_A\)</span> represents the number of policies covering travelers to countries in group B.</p>
</div>
<div id="associated-homogeneous-portfolio" class="section level4 hasAnchor" number="4.8.1.4">
<h4><span class="header-section-number">4.8.1.4</span> Associated Homogeneous Portfolio<a href="chap3.html#associated-homogeneous-portfolio" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In terms of pure premiums, there is no difference between this portfolio and a homogeneous portfolio in which the claim amounts for each policy would follow the distribution
<span class="math display">\[
S_{AB}=\left\{
\begin{array}{l}
0,\text{ with probability }0.85,\\
250\text{Euros},\text{ with probability }0.15.
\end{array}
\right.
\]</span>
Indeed, the total pure premium income for this homogeneous portfolio is
<span class="math display">\[
(n_A+n_B)37.5=75n_A.
\]</span>
Considering the homogeneous portfolio is equivalent to neglecting to differentiate insured parties based on their destination, and thus on the risk they represent(We emphasize that there is no single correct practice. The actuary decides on the model based on the level of solidarity they want to induce in the portfolio. Their goal is not to automatically choose the model that best fits reality. Assuming that the <span class="math inline">\(S_i\)</span> are independent and identically distributed when they are not amounts to inducing the maximum level of solidarity in the portfolio, which is not necessarily a bad thing). If we acknowledge the heterogeneity of the portfolio, we charge 25or 50based on the destination, while erasing this difference implies applying a uniform premium of 37.5to all insured parties in the portfolio.</p>
</div>
<div id="consequences-of-portfolio-heterogeneity" class="section level4 hasAnchor" number="4.8.1.5">
<h4><span class="header-section-number">4.8.1.5</span> Consequences of Portfolio Heterogeneity<a href="chap3.html#consequences-of-portfolio-heterogeneity" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>This simple example introduces several fundamental concepts:</p>
<ol style="list-style-type: decimal">
<li><p>When a uniform premium is charged to insured parties in a heterogeneous portfolio, a certain level of solidarity emerges. Indeed, the 37.5premium paid by an insured traveler to a country in group A can be broken down into a sum of 25, which is the price of their risk, and an additional 12.5, which will artificially lower the premium for travelers to countries in group B. The 25is paid due to risk pooling: it will be used to compensate claims affecting insured parties with the same profile (i.e., traveling to a country in group A). On the other hand, the 12.5reflects the solidarity that the insurer has introduced at the portfolio level by standardizing the premium amount.</p></li>
<li><p>When a uniform premium is charged to insured parties in a heterogeneous portfolio, the induced solidarity makes the insurer’s results depend on the portfolio’s structure. For instance, imagine that insured parties traveling to countries in group A are well aware of their risk, realize they are overcharged, and decide not to purchase coverage anymore, deeming the product too expensive. The insurer would then only have insured parties whose destination is a country in group B in the portfolio. Its total pure premium income would amount to <span class="math inline">\(n_B37.5\text{Euros}\)</span> and would not be sufficient to cover an expected loss of <span class="math inline">\(n_B50\text{Euros}\)</span>. Therefore, the collective premium of 37.5depends on the composition of the portfolio (here, the fact that 50% of trips are to countries in group A). Thus, the pricing is accurate only if the portfolio composition remains the same.</p></li>
<li><p>The insurer can hardly maintain a uniform premium in a market where competitors differentiate risks and apply a balanced premium within each defined risk class. In our example, let’s assume that Company <span class="math inline">\(C_1\)</span>, the sole company on the market, charges 37.5to each insured party. A new company <span class="math inline">\(C_2\)</span> enters the market and differentiates the premium amounts based on the destination country. The insured parties traveling to countries in group A should all switch from <span class="math inline">\(C_1\)</span> to <span class="math inline">\(C_2\)</span>. The results of <span class="math inline">\(C_2\)</span> will be balanced, but those of <span class="math inline">\(C_1\)</span> will deteriorate rapidly, as the insured parties traveling to countries in group A will no longer be there to subsidize the discount granted to insured parties traveling to countries in group B. Company <span class="math inline">\(C_1\)</span> will have no choice but to raise its uniform premium to 50(if it manages to overcome the loss of <span class="math inline">\(n_B 12.5\text{Euros}\)</span> it will suffer in the first year when insured parties departing to countries in group A leave). Thus, the market, i.e., Companies <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span>, will acknowledge the risk difference based on the destination either explicitly (like <span class="math inline">\(C_2\)</span>, which offers a differentiated premium) or implicitly (like <span class="math inline">\(C_1\)</span>, whose pricing structure is such that it only targets a segment of the market).</p></li>
</ol>
<p>However, it’s worth mentioning that reality is more subtle. Market players differentiate themselves not only by the premiums they charge but also by the services and extent of coverage they offer, by the target audience they address, and so on. Moreover, insured parties will only decide to switch their insurer if the premium reduction they obtain is substantial enough to justify the effort. The choice of the insurer can also be guided by ideological considerations, as is the case with mutuals.</p>
</div>
<div id="connection-with-mixture-models" class="section level4 hasAnchor" number="4.8.1.6">
<h4><span class="header-section-number">4.8.1.6</span> Connection with Mixture Models<a href="chap3.html#connection-with-mixture-models" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The random variable <span class="math inline">\(S\)</span> representing the claim costs generated by a policy in the portfolio that mixes two types of risks can also be modeled as a mixture of two Bernoulli distributions (scaled by 250). That is, conditional on <span class="math inline">\(Q=q\)</span>, <span class="math inline">\(S\sim 250\mathcal{B}er(q)\)</span> and
<span class="math display">\[
Q=\left\{
\begin{array}{l}
0.1,\text{ with probability }\frac{1}{2},\\
0.2,\text{ with probability }\frac{1}{2}.
\end{array}
\right.
\]</span>
Hence, mixture models provide an appropriate tool to handle the heterogeneity of insurance portfolios.</p>
<p>In general, we account for heterogeneity by introducing a random effect <span class="math inline">\(\Theta\)</span> representing the unknown risk level of the insured party. This results in a mixture model, defined as follows.</p>
<div class="definition">
<p><span id="def:unlabeled-div-66" class="definition"><strong>Definition 4.11  </strong></span>Suppose that conditional on <span class="math inline">\(\{\Theta=\theta\}\)</span>, the distribution of the random variable <span class="math inline">\(X\)</span> is described by the cumulative distribution function <span class="math inline">\(F(\cdot|\theta)\)</span>, i.e.
<span class="math display">\[
\Pr[X\leq x|\Theta=\theta]=F(x|\theta),\hspace{2mm}x\in{\mathbb{R}}.
\]</span>
If <span class="math inline">\(\Theta\)</span> is unknown, then the cumulative distribution function of <span class="math inline">\(X\)</span> is
<span class="math display">\[
\mathbb{E}\Big[\Pr[X\leq x|\Theta]\Big]=\int_{\theta\in{\mathbb{R}}}F(x|\theta)dF_\Theta(\theta),
\]</span>
which is a weighted average of the conditional cumulative distribution functions <span class="math inline">\(F(\cdot|\theta)\)</span> with weights determined by the cumulative distribution function <span class="math inline">\(F_\Theta\)</span> of <span class="math inline">\(\Theta\)</span>.</p>
</div>
</div>
</div>
<div id="poisson-mixtures" class="section level3 hasAnchor" number="4.8.2">
<h3><span class="header-section-number">4.8.2</span> Poisson Mixtures<a href="chap3.html#poisson-mixtures" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="context-1" class="section level4 hasAnchor" number="4.8.2.1">
<h4><span class="header-section-number">4.8.2.1</span> Context<a href="chap3.html#context-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Empirically, actuaries have observed that while the Poisson distribution theoretically accounts well for the number of claims caused by each insured party, it poorly models the number of claims affecting a policy in the portfolio. This is primarily due to the heterogeneity of insurance portfolios. If we take the example of auto liability insurance, each insured party has their own driving habits, travel patterns, and operates in an environment dependent on their social and professional activities. As a result, the numbers of claims caused by insured parties in the portfolio will vary more than the Poisson model can capture: indeed, the natural variability of the number of claims associated with the Poisson model is compounded by the variability stemming from portfolio heterogeneity.</p>
<p>Assuming that the number <span class="math inline">\(N\)</span> of claims caused by an insured party in the portfolio follows the <span class="math inline">\(\mathcal{P}oi(\lambda)\)</span> distribution implicitly posits that the portfolio is homogeneous: all insured parties have a similar risk profile (captured by the annual claim frequency <span class="math inline">\(\lambda\)</span>). In practice, this scenario is clearly unlikely: insured parties are not all equal in terms of risk, as explained earlier. The idea is to reflect this portfolio heterogeneity by considering that the average number of claims can vary from one insured party to another: it thus becomes a random variable <span class="math inline">\(\lambda\Theta\)</span>, where <span class="math inline">\(\Theta\)</span> characterizes deviations around the average number of claims <span class="math inline">\(\lambda\)</span> (with <span class="math inline">\(\mathbb{E}[\Theta]=1\)</span>).</p>
</div>
<div id="definition-11" class="section level4 hasAnchor" number="4.8.2.2">
<h4><span class="header-section-number">4.8.2.2</span> Definition<a href="chap3.html#definition-11" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>This brings us to consider mixtures of Poisson distributions. A mixture distribution reflects the fact that the population of interest results from the mixture of different individuals.</p>
<div class="definition">
<p><span id="def:unlabeled-div-67" class="definition"><strong>Definition 4.12  </strong></span>The random counting variable <span class="math inline">\(N\)</span> has a Poisson mixture distribution with mean <span class="math inline">\(\lambda\)</span> and relative risk level <span class="math inline">\(\Theta\)</span> when
<span class="math display" id="eq:MixPoisson">\[\begin{eqnarray}
\Pr[N=k]&amp;=&amp;\mathbb{E}\left[\exp(-\lambda\Theta)\frac{(\lambda\Theta)^k}{k!}\right]\nonumber\\
&amp;=&amp;\int_{\theta=0}^{+\infty}\exp(-\lambda\theta)\frac{(\lambda\theta)^k}{k!}
dF_\Theta(\theta),\hspace{2mm}k\in {\mathbb{N}},\tag{4.17}
\end{eqnarray}\]</span>
where <span class="math inline">\(F_\Theta\)</span> is the cumulative distribution function of <span class="math inline">\(\Theta\)</span>, assumed to satisfy the constraint <span class="math inline">\(\mathbb{E}[\Theta]=1\)</span>. From now on, we will denote <span class="math inline">\(\mathcal{MP}oi(\lambda,F_\Theta)\)</span> or simply <span class="math inline">\(\mathcal{MP}oi(\lambda,\Theta)\)</span> as an abuse of notation, the Poisson mixture distribution with mean <span class="math inline">\(\lambda\)</span> and relative risk level described by <span class="math inline">\(F_\Theta\)</span>; by extension, we will use the same notation for any random variable with distribution (as in <a href="chap3.html#eq:MixPoisson">(4.17)</a>).</p>
</div>
<p>Technically, we want to work with the random pair <span class="math inline">\((N,\Theta)\)</span>; to achieve this, we define its joint probability distribution based on
<span class="math display">\[
\Pr[\Theta\leq t,N=n]=\int_{\theta=0}^t\exp(-\lambda\theta)\frac{(\lambda\theta)^n}{n!}dF_\Theta(\theta),
\]</span>
for <span class="math inline">\(t\in{\mathbb{R}}^+\)</span> and <span class="math inline">\(n\in{\mathbb{N}}\)</span>.</p>
<div class="example">
<p><span id="exm:GoodBad" class="example"><strong>Example 4.19  </strong></span>The simplest model that meets these characteristics is known as the “good risks – bad risks” model. It involves considering that the portfolio consists of two types of risks: good ones, for which the number of claims follows the <span class="math inline">\(\mathcal{P}oi(\lambda\theta_1)\)</span> distribution, and bad ones, for which the number of claims follows the <span class="math inline">\(\mathcal{P}oi(\lambda\theta_2)\)</span> distribution, with <span class="math inline">\(\theta_2&gt;1&gt;\theta_1\)</span>. If the proportion of good risks is <span class="math inline">\(\varrho\)</span>, the hypothesis above amounts to
<span class="math display">\[
\Theta=\left\{
\begin{array}{l}
\theta_1,\mbox{ with probability }\varrho,
\\
\theta_2,\mbox{ with probability }1-\varrho,
\end{array}
\right.
\]</span>
where the parameters <span class="math inline">\(\theta_1\)</span>, <span class="math inline">\(\theta_2\)</span>, and <span class="math inline">\(\varrho\)</span> are constrained by
<span class="math display">\[
\mathbb{E}[\Theta]=\varrho\theta_1+(1-\varrho)\theta_2=1.
\]</span>
The probability that a policy (whose status as a good or bad risk is unknown) results in <span class="math inline">\(k\)</span> claims during the reference period is then
<span class="math display">\[
\Pr[N=k]=\varrho\exp(-\lambda\theta_1)\frac{(\lambda\theta_1)^k}{k!}+
(1-\varrho)\exp(-\lambda\theta_2)\frac{(\lambda\theta_2)^k}{k!},
\]</span>
by virtue of <a href="chap3.html#eq:MixPoisson">(4.17)</a>.</p>
</div>
<p>The above example illustrates the connection between mixing and portfolio heterogeneity. Of course, dividing insured parties into only two categories as in the example above can be simplistic, and multiplying categories inevitably leads to over-parameterization of the model, which goes against the principle of parsimony. Therefore, it is often considered that the risk profile varies continuously in the portfolio (i.e., if insured parties are ranked from worst to best, a continuum is obtained); <span class="math inline">\(\Theta\)</span> then becomes a continuous random variable with probability density <span class="math inline">\(f_\Theta\)</span>, and
<span class="math display" id="eq:MixPoissonbis">\[\begin{equation}
\Pr[N=k]=\int_{\theta=0}^{+\infty}\exp(-\lambda\theta)\frac{(\lambda\theta)^k}{k!}
f_\Theta(\theta)d\theta,\hspace{2mm}k\in {\mathbb{N}}.\tag{4.18}
\end{equation}\]</span></p>
<div class="remark">
<p><span id="unlabeled-div-68" class="remark"><em>Remark</em>. </span>On a theoretical level, the insurer facing a number of claims following the <span class="math inline">\(\mathcal{MP}oi(\lambda,\Theta)\)</span> distribution rather than <span class="math inline">\(\mathcal{P}oi(\lambda)\)</span> is actually covering a double randomness. It insures not only the uncertainty about the quality of the risk (represented by the unknown claim frequency <span class="math inline">\(\lambda\Theta\)</span>) but also the uncertainty around the number of claims itself (Poisson randomness).</p>
</div>
</div>
<div id="moments" class="section level4 hasAnchor" number="4.8.2.3">
<h4><span class="header-section-number">4.8.2.3</span> Moments<a href="chap3.html#moments" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let <span class="math inline">\(N\)</span> be a random variable with <span class="math inline">\(\mathcal{MP}oi(\lambda,\Theta)\)</span> distribution. The mean of <span class="math inline">\(N\)</span> is given by
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[N] &amp; =&amp;  \int_{\theta=0}^{+\infty}\left(\sum_{k=0}^{+\infty}k\exp(-\lambda\theta)\frac{(\lambda\theta)^k}{k!}\right)
dF_\Theta(\theta)\\
&amp;=&amp;\lambda\int_{\theta=0}^{+\infty}\theta dF_\Theta(\theta)=\lambda.
\end{eqnarray*}\]</span>
Regarding the variance, it follows that
<span class="math display">\[\begin{eqnarray*}
\mathbb{V}[N]&amp;=&amp;  \int_{\theta=0}^{+\infty}\left(\sum_{k=0}^{+\infty}k^2\exp(-\lambda\theta)\frac{(\lambda\theta)^k}{k!}\right)
dF_\Theta(\theta)-\lambda^2\\
&amp;=&amp;\int_{\theta=0}^{+\infty}(\lambda\theta+\lambda^2\theta^2) dF_\Theta(\theta)-\lambda^2\\
&amp;=&amp;\lambda+\lambda^2\mathbb{V}[\Theta].
\end{eqnarray*}\]</span>
Since
<span class="math display">\[
\mathbb{V}[N]=\mathbb{E}[N]+\lambda^2\mathbb{V}[\Theta]&gt;\mathbb{E}[N]
\]</span>
as long as <span class="math inline">\(\Theta\)</span> is not constant. Thus, any Poisson mixture implies overdispersion of the data.</p>
</div>
<div id="tail-function" class="section level4 hasAnchor" number="4.8.2.4">
<h4><span class="header-section-number">4.8.2.4</span> Tail Function<a href="chap3.html#tail-function" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The tail function of <span class="math inline">\(N\sim\mathcal{MP}oi(\lambda,\Theta)\)</span> can also be expressed as
<span class="math display">\[\begin{eqnarray*}
&amp;&amp;\Pr[N&gt;n]\\
&amp;=&amp;\int_{\theta\in{\mathbb{R}}^+}\sum_{k=n+1}^{+\infty}\exp(-\lambda\theta)\frac{(\lambda\theta)^k}{k!}dF_\Theta(\theta)\\
&amp;=&amp;\int_{\theta\in{\mathbb{R}}^+}\sum_{k=n+1}^{+\infty}\left\{\exp(-\lambda\theta)\frac{\lambda(\lambda\theta)^{k-1}}{(k-1)!}
-\exp(-\lambda\theta)\frac{\lambda(\lambda\theta)k}{k!}\right\}\overline{F}_\Theta(\theta)d\theta\\
&amp;=&amp;\lambda\int_{\theta\in{\mathbb{R}}^+}\exp(-\lambda\theta)\frac{(\lambda\theta)^n}{n!}\overline{F}_\Theta(\theta)d\theta.
\end{eqnarray*}\]</span></p>
</div>
<div id="probability-generating-function-1" class="section level4 hasAnchor" number="4.8.2.5">
<h4><span class="header-section-number">4.8.2.5</span> Probability Generating Function<a href="chap3.html#probability-generating-function-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The probability generating function of <span class="math inline">\(N\sim\mathcal{MP}oi(\lambda,\Theta)\)</span> and the Laplace transform of <span class="math inline">\(\Theta\)</span> are related by the formula
<span class="math display" id="eq:MixPoissonTransf">\[\begin{equation}
\varphi_N(z)=\int_{\theta=0}^{+\infty}\exp(\lambda\theta(z-1))
f_\Theta(\theta)d\theta=L_\Theta(\lambda(1-z)).\tag{4.19}
\end{equation}\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-69" class="example"><strong>Example 4.20  (Negative Binomial Distribution) </strong></span>If we consider <span class="math inline">\(\Theta\sim\mathcal{G}am(a,a)\)</span>, then from <a href="chap3.html#eq:MixPoissonTransf">(4.19)</a> and Table <a href="chap3.html#tab:TLFGMUs">4.4</a>, we obtain
<span class="math display">\[
\varphi_{N}(z)=\left(1+\frac{\lambda(1-z)}{\alpha}\right)^{-\alpha},
\]</span>
which, according to Table <a href="chap3.html#tab:FGPUs">4.3</a>, is the probability generating function associated with the <span class="math inline">\(\mathcal{NB}in(\alpha,\alpha/(\alpha+\lambda))\)</span> distribution.</p>
</div>
</div>
<div id="identifiability" class="section level4 hasAnchor" number="4.8.2.6">
<h4><span class="header-section-number">4.8.2.6</span> Identifiability<a href="chap3.html#identifiability" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Poisson mixtures are identifiable, i.e. if <span class="math inline">\(N_1\sim\mathcal{MP}oi(\lambda,\Theta_1)\)</span> and <span class="math inline">\(N_2\sim\mathcal{MP}oi(\lambda,\Theta_2)\)</span> then
<span class="math display">\[
N_1\stackrel{\text{d}}{=}N_2\Rightarrow \Theta_1\stackrel{\text{d}}{=}\Theta_2.
\]</span>
Thus, in the context of studying Poisson mixtures, one can reduce it to studying the mixing distributions. This follows from the following reasoning, to which we provide a general scope.</p>
<p>Often when <span class="math inline">\(N\sim\mathcal{MP}oi(\lambda,\Theta)\)</span>, an expectation involving <span class="math inline">\(N\)</span> can be transformed into an expectation involving <span class="math inline">\(\Theta\)</span>, and vice versa. That is, given a function <span class="math inline">\(g\)</span>, it’s possible to find a function <span class="math inline">\(g^*\)</span> such that the identity
<span class="math display">\[
\mathbb{E}[g(\Theta)]=\mathbb{E}[g^*(N)]
\]</span>
holds. This is the case, for example, when all derivatives <span class="math inline">\(g^{(1)},g^{(2)},g^{(3)},\ldots\)</span> of <span class="math inline">\(g\)</span> exist and are positive. In this case,
<span class="math display">\[
\mathbb{E}[g(\Theta)]=  \int_{\theta\in {\mathbb{R}}^+}g(\theta)dF_\Theta(\theta)
= \sum_{k=0}^{+\infty}\frac{g^{(k)}(0)}{k!}\int_{\theta\in {\mathbb{R}}^+}\theta^kdF_\Theta(\theta).
\]</span>
The identity
<span class="math display">\[
(\lambda\theta)^k=\sum_{\ell=k}^{+\infty}\frac{\exp(-\lambda\theta)(\lambda\theta)^\ell}{(\ell-k)!}
\]</span>
allows us to write
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[g(\Theta)] &amp; = &amp; \sum_{k=0}^{+\infty}\frac{g^{(k)}(0)}{\lambda^kk!}\sum_{\ell=k}^{+\infty}
\frac{\ell !\Pr[N=\ell]}{(\ell-k)!} \\
&amp; = &amp; \sum_{\ell =0}^{+\infty}\left\{\sum_{k=0}^\ell\binom{\ell}{k}\frac{g^{(k)}(0)}{\lambda^k}\right\}
\Pr[N=\ell]\\
&amp;=&amp;\mathbb{E}[g^*(N)]
\end{eqnarray*}\]</span>
where the function <span class="math inline">\(g^*\)</span> is defined as
<span class="math display">\[
g^*(\ell)=\sum_{k=0}^\ell\binom{\ell}{k}\frac{g^{(k)}(0)}{\lambda^k},\hspace{2mm}\ell\in{\mathbb{N}}.
\]</span></p>
<p>Taking <span class="math inline">\(g(\theta)=\exp(t\theta)\)</span>, the associated function <span class="math inline">\(g^*\)</span> is
<span class="math display">\[
g^*(\ell)=\sum_{k=0}^\ell\binom{\ell}{k}\frac{t^k}{\lambda^k}=\left(1+\frac{t}{\lambda}\right)^\ell.
\]</span>
Thus, coming back to the identifiability issue mentioned at the beginning of this section, we have
<span class="math display">\[\begin{eqnarray*}
N_1\stackrel{\text{d}}{=}N_2&amp;\Rightarrow&amp;\mathbb{E}[g^*(N_1)]=\varphi_{N_1}\left(1+\frac{t}{\lambda}\right)\\
&amp;&amp;=\varphi_{N_2}\left(1+\frac{t}{\lambda}\right)=\mathbb{E}[g^*(N_2)]\\
&amp;\Rightarrow&amp;M_{\Theta_1}(t)=\mathbb{E}[g(\Theta_1)]=\mathbb{E}[g(\Theta_2)]=M_{\Theta_2}(t)\\
&amp;\Rightarrow&amp;\Theta_1\stackrel{\text{d}}{=}\Theta_2.
\end{eqnarray*}\]</span></p>
</div>
</div>
<div id="shakeds-theorem" class="section level3 hasAnchor" number="4.8.3">
<h3><span class="header-section-number">4.8.3</span> Shaked’s Theorem<a href="chap3.html#shakeds-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Poisson mixtures have a very important property established by <span class="citation">(<a href="#ref-shaked1980mixtures" role="doc-biblioref">Shaked 1980</a>)</span> known as the “Shaked’s Two Crossings Theorem.”</p>
<div class="proposition">
<p><span id="prp:Shaked2C" class="proposition"><strong>Proposition 4.22  </strong></span>If <span class="math inline">\(N\sim\mathcal{MP}oi(\lambda,\Theta)\)</span>, then there exist two integer values <span class="math inline">\(0\leq k_0&lt;k_1\)</span> such that
<span class="math display">\[\begin{eqnarray*}
\Pr[N=k]&amp;\geq&amp; \exp(-\lambda)\frac{\lambda^k}{k!}\text{ for }k=0,1,\ldots,k_0,\\
\Pr[N=k]&amp;\leq&amp; \exp(-\lambda)\frac{\lambda^k}{k!}\text{ for }k=k_0+1,\ldots,k_1,\\
\Pr[N=k]&amp;\geq&amp; \exp(-\lambda)\frac{\lambda^k}{k!}\text{ for }k\geq k_1+1.
\end{eqnarray*}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-70" class="proof"><em>Proof</em>. </span>Let’s begin by noting that the number of sign changes in the sequence
<span class="math display">\[
\Pr[N=k]-\exp(-\lambda)\frac{\lambda^k}{k!},\hspace{2mm}k\in{\mathbb{N}},
\]</span>
is the same as the number of sign changes in the sequence <span class="math inline">\(c(k)\)</span>, <span class="math inline">\(k\in{\mathbb{N}}\)</span>, where
<span class="math display">\[\begin{eqnarray*}
c(k)&amp;=&amp;\frac{\Pr[N=k]}{\exp(-\lambda)\frac{\lambda^k}{k!}}-1\\
&amp;=&amp;\int_{\xi\in{\mathbb{R}}^+}\exp(\lambda-\xi)\left(\frac{\xi}{\lambda}\right)^kd\xi-1.
\end{eqnarray*}\]</span>
Since the function <span class="math inline">\(c(\cdot)\)</span> is convex, it cannot have more than two sign changes on <span class="math inline">\({\mathbb{N}}\)</span>. Clearly, <span class="math inline">\(c(\cdot)\)</span> must have at least one sign change. Now, let’s prove that <span class="math inline">\(c(\cdot)\)</span> cannot have only one sign change. Indeed, in that case, we would have <span class="math inline">\(\mathbb{E}[N]&lt;\lambda\)</span> or <span class="math inline">\(\lambda&lt;\mathbb{E}[N]\)</span>, which contradicts <span class="math inline">\(\mathbb{E}[N]=\lambda\)</span>.</p>
</div>
<p>This result indicates that adding an error <span class="math inline">\(\Theta\)</span> to the mean <span class="math inline">\(\lambda\)</span> increases the probability mass assigned to 0: therefore, there will be more policies with no claims in the mixed Poisson model compared to the Poisson model with the same mean. Furthermore, we observe that the probability mass assigned to large values (those exceeding <span class="math inline">\(k_1+1\)</span>) will be higher in the mixed Poisson model than in the Poisson model with the same mean.</p>
</div>
<div id="composite-mixed-poisson-distributions" class="section level3 hasAnchor" number="4.8.4">
<h3><span class="header-section-number">4.8.4</span> Composite Mixed Poisson Distributions<a href="chap3.html#composite-mixed-poisson-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="definition-12" class="section level4 hasAnchor" number="4.8.4.1">
<h4><span class="header-section-number">4.8.4.1</span> Definition<a href="chap3.html#definition-12" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>If <span class="math inline">\(N\sim\mathcal{MP}oi(\lambda,\Theta)\)</span>, then for <span class="math inline">\(S\)</span> in the form <a href="#eq:CompDist">(<strong>??</strong>)</a>, we refer to it as a composite mixed Poisson distribution, denoted as <span class="math inline">\(S\sim\mathcal{CMP}oi(\lambda,F_\Theta,F)\)</span> or simply <span class="math inline">\(S\sim\mathcal{CMP}oi(\lambda,\Theta,F)\)</span>.</p>
</div>
<div id="variance-1" class="section level4 hasAnchor" number="4.8.4.2">
<h4><span class="header-section-number">4.8.4.2</span> Variance<a href="chap3.html#variance-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let’s define the risk index <span class="math inline">\(r_2\)</span> as
<span class="math display">\[
r_2=\frac{\mathbb{E}[X_1^2]}{\{\mathbb{E}[X_1]\}^2}.
\]</span>
Clearly, <span class="math inline">\(r_2\geq 1\)</span> since
<span class="math display">\[
r_2-1=\frac{\mathbb{V}[X_1]}{\{\mathbb{E}[X_1]\}^2}
\]</span>
and <span class="math inline">\(r_2=1\Leftrightarrow X_1=\)</span> constant. The variance of <span class="math inline">\(S\sim\mathcal{CMP}oi(\lambda,\Theta,F)\)</span> is then given by
<span class="math display">\[\begin{eqnarray*}
\mathbb{V}[S]&amp;=&amp;\lambda\mathbb{E}[X_1^2]+\lambda^2\{\mathbb{E}[X_1]\}^2\mathbb{V}[\Theta]
\\
&amp;=&amp;\{\lambda\mathbb{E}[X_1]\}^2\left({\frac{r_2}{\lambda}+\mathbb{V}[\Theta]}\right).
\end{eqnarray*}\]</span>
Furthermore, the coefficient of variation of <span class="math inline">\(S\)</span> is given by
<span class="math display">\[
CV[S]=\frac{\sqrt{\mathbb{V}[S]}}{\mathbb{E}[S]}=\sqrt{\frac{r_2}{\lambda}+\mathbb{V}[\Theta]}.
\]</span>
As
<span class="math display">\[
CV[\mathcal{P}oi(\lambda)]=\sqrt{\frac{r_2}{\lambda}},
\]</span>
we observe that when <span class="math inline">\(\lambda\)</span> is high, <span class="math inline">\(CV[S]\)</span> is dominated by the behavior of the mixing distribution (expressed by <span class="math inline">\(\mathbb{V}[\Theta]\)</span>).</p>
<p>The variance of <span class="math inline">\(S\)</span> can be further decomposed as follows to identify the sources of variability in the insurer’s financial burden:
<span class="math display">\[\begin{eqnarray*}
\mathbb{V}[S]&amp;=&amp;\{\mathbb{E}[X_1]\}^2\mathbb{V}[\mathcal{P}oi(\lambda)]+\lambda\mathbb{V}[X_1]+\lambda^2\{\mathbb{E}[X_1]\}^2\mathbb{V}[\Theta]\\
&amp;\equiv &amp;V_1+V_2+V_3.
\end{eqnarray*}\]</span>
Let’s give a meaning to each of the three terms in this decomposition:</p>
<ul>
<li>the first term <span class="math inline">\(V_1\)</span> can be seen as <span class="math inline">\(\mathbb{V}[\mathcal{P}oi(\lambda)\mathbb{E}[X_1]]\)</span>, that is, the variance of the insurer’s expense if the claims were constantly equal to their mean and if their number followed a Poisson distribution.</li>
<li>the second term <span class="math inline">\(V_2\)</span> can be seen as the contribution of the claim amounts <span class="math inline">\(X_1,X_2,\ldots\)</span> to the total variability <span class="math inline">\(\mathbb{V}[S]\)</span>, since it is actually
<span class="math display">\[
\mathbb{V}\left[\sum_{i=1}^\lambda X_i\right],
\]</span>
ignoring the fact that <span class="math inline">\(\lambda\)</span> might not be an integer.</li>
<li>the third and final term <span class="math inline">\(V_3\)</span> can be considered as the additional variability induced by the mixing distribution.</li>
</ul>
<p>For small values of <span class="math inline">\(\lambda\)</span>, the variability of the claims predominates, while for large values of <span class="math inline">\(\lambda\)</span>, the effect of the mixing dominates.</p>
</div>
<div id="asymptotic-behavior-of-the-claimspremium-ratio-in-a-compound-mixed-poisson-model" class="section level4 hasAnchor" number="4.8.4.3">
<h4><span class="header-section-number">4.8.4.3</span> Asymptotic Behavior of the Claims/Premium Ratio in a Compound Mixed Poisson Model<a href="chap3.html#asymptotic-behavior-of-the-claimspremium-ratio-in-a-compound-mixed-poisson-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let’s assume a heterogeneous portfolio with the number of claims <span class="math inline">\(N\sim\mathcal{MP}oi(\lambda,\Theta)\)</span>. The total claims amount <span class="math inline">\(S\)</span> generated by this portfolio follows a <span class="math inline">\(\mathcal{CMP}oi (\lambda,\Theta,F)\)</span> distribution. The variance of the pure premium ratio (denoted S/P) in this case is given by
<span class="math display" id="eq:LimVarSP">\[\begin{eqnarray}
\mathbb{V}\left[\frac{S}{\mathbb{E}[S]}\right]&amp;=&amp;\frac{1}{\lambda^2(\mathbb{E}[X_1])^2}\mathbb{V}[S]\nonumber\\
&amp;=&amp;\frac{\lambda\mathbb{E}[X_1^2]+\lambda^2(\mathbb{E}[X_1])^2\mathbb{V}[\Theta]}{\lambda^2(\mathbb{E}[X_1])^2}\nonumber\\
&amp;\to&amp;\mathbb{V}[\Theta]\text{ as }\lambda\to +\infty.\tag{4.20}
\end{eqnarray}\]</span>
Thus, the concern for large portfolios mainly arises from the mixing distribution, that is, the portfolio heterogeneity.</p>
<p>When there is no heterogeneity (i.e., <span class="math inline">\(\mathbb{V}[\Theta]=0\)</span> and <span class="math inline">\(\Theta=1\)</span>), i.e.,
<span class="math inline">\(S\sim\mathcal{CP}oi(\lambda,F)\)</span>, we have
<span class="math display">\[
\mathbb{V}\left[\frac{S}{\mathbb{E}[S]}\right]\to 0\text{ as }\lambda\to +\infty,
\]</span>
so the variance of the S/P ratio tends to 0 for large homogeneous portfolios. Therefore, the Bienaymé-Chebyshev inequality allows us to assert that
<span class="math display">\[
\frac{S}{\mathbb{E}[S]}\to_{\text{prob}}1,\text{ as }\lambda\to +\infty.
\]</span>
This reflects the risk reduction through aggregation, as the insurer’s outcome becomes more stable as the portfolio size (i.e., <span class="math inline">\(\lambda\)</span>) increases.</p>
<p>Examining the limit <a href="chap3.html#eq:LimVarSP">(4.20)</a>, we see that <span class="math inline">\(S/\mathbb{E}[S]\)</span> remains random even in a large portfolio when <span class="math inline">\(S\sim\mathcal{CMP}oi(\lambda,\Theta,F)\)</span>: the above-mentioned limit suggests that <span class="math inline">\(S/\mathbb{E}[S]\)</span> behaves like <span class="math inline">\(\Theta\)</span> when <span class="math inline">\(\lambda\to+\infty\)</span>. This is precisely what we will highlight in this section.</p>
<p>To do this, we will need the concept of convergence in distribution, which is different from the convergence in probability used in the law of large numbers (Property <a href="chap3.html#prp:LLN">4.9</a>).</p>
<div class="definition">
<p><span id="def:unlabeled-div-71" class="definition"><strong>Definition 4.13  </strong></span>A sequence of random variables <span class="math inline">\(\{T_n,\hspace{2mm}n=1,2,\ldots\}\)</span> converges in distribution to the random variable <span class="math inline">\(T\)</span>, denoted as <span class="math inline">\(T_n\to_{\text{dist}}T\)</span>, when
<span class="math display">\[
\Pr[T_n\leq t]\to F_T(t),\text{ as }n\to +\infty,
\]</span>
at every point <span class="math inline">\(t\)</span> where <span class="math inline">\(F_T\)</span> is continuous.</p>
</div>
<p>The two concepts of convergence used so far, namely <span class="math inline">\(\to_{\text{prob}}\)</span> and <span class="math inline">\(\to_{\text{dist}}\)</span>, are not equivalent. In fact, convergence in probability is stronger than convergence in distribution: for any sequence <span class="math inline">\(\{T_n,\hspace{2mm}n=1,2,\ldots\}\)</span>,
<span class="math display">\[
T_n\to_{\text{prob}}T\Rightarrow T_n\to_{\text{dist}}T.
\]</span></p>
<p>We are now able to demonstrate the following result.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-72" class="proposition"><strong>Proposition 4.23  </strong></span>If <span class="math inline">\(S\sim\mathcal{CMP}oi(\lambda,\Theta,F)\)</span>, then
<span class="math display">\[
\frac{S}{\mathbb{E}[S]}\to_{\text{dist}}\Theta,\text{ as }\lambda\to +\infty.
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-73" class="proof"><em>Proof</em>. </span>To see this, let’s write
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}\left[\left(\frac{S}{\mathbb{E}[S]}-\Theta\right)^2\right]&amp;=&amp;
\mathbb{E}\left[\mathbb{E}\left[\left(\frac{S}{\mathbb{E}[S]}-\Theta\right)^2\Big|\Theta\right]\right]\\
&amp;=&amp;
\mathbb{E}\left[
\mathbb{E}\left[
\left(\frac{S}{\mathbb{E}[S]}-\mathbb{E}\left[\frac{S}{\mathbb{E}[S]}\Big|\Theta\right]\right)^2
\Big|\Theta\right]\right]\\
&amp;=&amp;
\mathbb{E}\left[\mathbb{V}\left[\frac{S}{\mathbb{E}[S]}\Big|\Theta\right]\right].
\end{eqnarray*}\]</span>
Now,
<span class="math display">\[\begin{eqnarray*}
\mathbb{V}\left[\frac{S}{\mathbb{E}[S]}\Big|\Theta=\theta\right]&amp;=&amp;\frac{1}{\mathbb{E}^2[S]}\mathbb{V}[S|\Theta=\theta]\\
&amp;=&amp;
\frac{1}{\{\lambda\mathbb{E}[X_1]\}^2}\lambda\theta\mathbb{E}[X_1^2],
\end{eqnarray*}\]</span>
so that
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}\left[\mathbb{V}\left[\frac{S}{\mathbb{E}[S]}\Big|\Theta\right]\right]&amp;=&amp;\mathbb{E}\left[
\frac{\mathbb{E}[X_1^2]}{\lambda\{\mathbb{E}[X_1]\}^2}\Theta\right]\\
&amp;=&amp;\frac{\mathbb{E}[X_1^2]}{\lambda\{\mathbb{E}[X_1]\}^2}
\to 0,\text{ as }\lambda\to+\infty.
\end{eqnarray*}\]</span>
Finally, we deduce that
<span class="math display">\[
\mathbb{E}\left[\left(\frac{S}{\mathbb{E}[S]}-\Theta\right)^2\right]\to 0,\text{ as }\lambda\to +\infty.
\]</span>
The Markov inequality guarantees that
<span class="math display">\[\begin{eqnarray*}
\Pr\left[\left|\frac{S}{\mathbb{E}[S]}-\Theta\right|&gt;\epsilon\right]&amp;\leq&amp;
\frac{\mathbb{E}\left|\frac{S}{\mathbb{E}[S]}-\Theta\right|}{\epsilon}\\
&amp;\leq&amp;\frac{1}{\epsilon}\sqrt{\mathbb{E}\left[\left(\frac{S}{\mathbb{E}[S]}-\Theta\right)^2\right]}\\
&amp;\to &amp; 0,\text{ as }\lambda\to+\infty.
\end{eqnarray*}\]</span>
Thus,
<span class="math display">\[
\frac{S}{\mathbb{E}[S]}\to_{\text{prob}}\Theta,\text{ as }\lambda\to +\infty
\]</span>
<span class="math display">\[
\Rightarrow\frac{S}{\mathbb{E}[S]}\to_{\text{dist}}\Theta,\text{ as }\lambda\to +\infty.
\]</span></p>
</div>
<p>Therefore, the limiting distribution of the loss ratio (<span class="math inline">\(S/\mathbb{E}[S]\)</span>) is not the normal distribution, but the mixing distribution that describes the frequency risk heterogeneity: even for very large portfolios, <span class="math inline">\(S/\mathbb{E}[S]\)</span> remains random and becomes more dispersed as the portfolio heterogeneity, measured by <span class="math inline">\(\mathbb{V}[\Theta]\)</span>, increases.</p>
</div>
</div>
<div id="exponential-mixtures" class="section level3 hasAnchor" number="4.8.5">
<h3><span class="header-section-number">4.8.5</span> Exponential Mixtures<a href="chap3.html#exponential-mixtures" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="definition-13" class="section level4 hasAnchor" number="4.8.5.1">
<h4><span class="header-section-number">4.8.5.1</span> Definition<a href="chap3.html#definition-13" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Exponential mixtures constitute a very flexible class of probability distributions. Using an exponential mixture to describe the claim amounts implies considering that the claims follow a negative exponential distribution, but their mean is variable.</p>
<div class="definition">
<p><span id="def:unlabeled-div-74" class="definition"><strong>Definition 4.14  </strong></span>The continuous random variable <span class="math inline">\(X\)</span> is said to have an exponential mixture distribution when it has the cumulative distribution function
<span class="math display" id="eq:MelExpcdf">\[\begin{eqnarray}
\Pr[X\leq x]
&amp; = &amp; \int_{\theta\in {\mathbb{R}}^+}
\left\{1-\exp(-\theta x)\right\}dF_\Theta(\theta),\tag{4.21}
\end{eqnarray}\]</span>
<span class="math inline">\(x\in {\mathbb{R}}^+\)</span>. Hereafter, we will denote by <span class="math inline">\(\mathcal{ME}xp(F_\Theta)\)</span> or simply <span class="math inline">\(\mathcal{ME}xp(\Theta)\)</span> the distribution with the cumulative distribution function given by <a href="chap3.html#eq:MelExpcdf">(4.21)</a>.</p>
</div>
<p>The family of exponential mixtures reflects varying levels of risk for the insurer. If <span class="math inline">\(\Theta=\theta\)</span>, we simply obtain the negative exponential distribution <span class="math inline">\(\mathcal{E}xp(\theta)\)</span>. However, if <span class="math inline">\(\Theta\)</span> follows a Gamma distribution, we transition to the Pareto distribution, as shown in the following example.</p>
<div class="example">
<p><span id="exm:unlabeled-div-75" class="example"><strong>Example 4.21  (Pareto Distribution as an Exponential Mixture) </strong></span>When <span class="math inline">\(X\sim\mathcal{ME}xp(\Theta)\)</span> and <span class="math inline">\(\Theta\sim\mathcal{G}am(\alpha,\tau)\)</span>, the exponential mixture corresponds to the Pareto distribution. Indeed, the survival function of the exponential mixture is then given by
<span class="math display">\[\begin{eqnarray*}
\Pr[X&gt;x]&amp;=&amp;
\frac{\tau^\alpha}{\Gamma(\alpha)}\int_{\theta\in {\mathbb{R}}^+}
\exp\left(-\theta(x+\tau)\right)\theta^{\alpha-1}
d\theta\\
&amp; = &amp; \frac{1}{\Gamma(\alpha)}
\left(\frac{\tau}{x+\tau}\right)^\alpha\int_{\xi\in {\mathbb{R}}^+}
\exp(-\xi)\xi^{\alpha-1}d\xi\\
&amp;=&amp;\left(\frac{\tau}{x+\tau}\right)^\alpha,
\end{eqnarray*}\]</span>
which is indeed the survival function associated with the <span class="math inline">\(\mathcal{P}ar(\alpha,\tau)\)</span> model.</p>
</div>
</div>
<div id="tail-function-1" class="section level4 hasAnchor" number="4.8.5.2">
<h4><span class="header-section-number">4.8.5.2</span> Tail Function<a href="chap3.html#tail-function-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let’s now examine the tail function associated with an exponential mixture: it’s easy to see that if <span class="math inline">\(X\sim\mathcal{ME}xp(\Theta)\)</span> then
<span class="math display" id="eq:FoncQueueMelExp">\[\begin{equation}
\Pr[X&gt;x]=\int_{\theta\in {\mathbb{R}}^+}\exp(-\theta x)dF_\Theta(\theta)
=L_\Theta(x),\hspace{2mm}x\in {\mathbb{R}}^+.\tag{4.22}
\end{equation}\]</span>
Thus, the tail function of an exponential mixture appears as the Laplace transform of <span class="math inline">\(\Theta\)</span>. This leads us to the following result.</p>
<div class="proposition">
<p><span id="prp:Bernstein" class="proposition"><strong>Proposition 4.24  </strong></span>A probability distribution is an exponential mixture if, and only if, its associated tail function is completely monotone.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-76" class="proof"><em>Proof</em>. </span>As seen earlier, if <span class="math inline">\(X\sim\mathcal{ME}xp(\Theta)\)</span>, the derivatives of the tail function <a href="chap3.html#eq:FoncQueueMelExp">(4.22)</a> can be written as
<span class="math display">\[\begin{eqnarray*}
\frac{d^k}{dx^k}\Pr[X&gt;x] &amp; = &amp;
\int_{\theta\in {\mathbb{R}}^+}\left\{\frac{d^k}{dx^k}\exp(-\theta x)\right\}
dF_\Theta(\theta)\\
&amp; = &amp; (-1)^k\int_{\theta\in {\mathbb{R}}^+}\theta^{k}\exp(-\theta x)dF_\Theta(\theta),
\end{eqnarray*}\]</span>
which indeed appears as a completely monotone function. To prove the converse, one just needs to invoke Proposition <a href="chap3.html#prp:TheoBer">4.11</a>.</p>
</div>
<p>The Proposition <a href="chap3.html#prp:Bernstein">4.24</a> notably leads to the fact that the probability density function associated with an exponential model is decreasing and therefore has a unique mode at 0. This might seem restrictive and explains why the model is often used to describe claim amounts exceeding a fixed threshold.</p>
</div>
</div>
<div id="identifiability-of-exponential-mixtures" class="section level3 hasAnchor" number="4.8.6">
<h3><span class="header-section-number">4.8.6</span> Identifiability of Exponential Mixtures<a href="chap3.html#identifiability-of-exponential-mixtures" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Note that the uniqueness of the Laplace transform ensures that if <span class="math inline">\(X\sim\mathcal{ME}xp(\Theta_1)\)</span> and <span class="math inline">\(Y\sim\mathcal{ME}xp(\Theta_2)\)</span>
<span class="math display">\[
X=_{\text{law}}Y\Rightarrow\Theta_1=_{\text{law}}\Theta_2,
\]</span>
making the model identifiable; this allows us to study exponential mixtures through their mixing distribution.</p>
<div id="properties-2" class="section level4 hasAnchor" number="4.8.6.1">
<h4><span class="header-section-number">4.8.6.1</span> Properties<a href="chap3.html#properties-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Exponential mixtures enjoy many interesting properties. To establish these, let’s recall the following results about completely monotone functions (see <span class="citation">(<a href="#ref-feller1950introduction" role="doc-biblioref">Feller 1950</a>)</span> for more details).</p>
<div class="lemma">
<p><span id="lem:TechnicalRes" class="lemma"><strong>Lemma 4.1  </strong></span>Let <span class="math inline">\(g_1\)</span> and <span class="math inline">\(g_2\)</span> be functions from <span class="math inline">\((0,+\infty)\)</span> to <span class="math inline">\([0,+\infty)\)</span>.</p>
<ol style="list-style-type: decimal">
<li>If <span class="math inline">\(g_1\)</span> and <span class="math inline">\(g_2\)</span> are completely monotone, their product <span class="math inline">\(g_1g_2\)</span> is also completely monotone.</li>
<li>If <span class="math inline">\(g_1\)</span> is completely monotone and <span class="math inline">\(g_2\)</span> has a completely monotone first derivative, then <span class="math inline">\(g_1\circ g_2\)</span> is completely monotone. In particular, <span class="math inline">\(\exp(-g_2)\)</span> is completely monotone.
\end{description}</li>
</ol>
</div>
<div class="proposition">
<p><span id="prp:MinMelExp" class="proposition"><strong>Proposition 4.25  </strong></span>Let <span class="math inline">\(X_1\sim\mathcal{ME}xp(\Theta_1)\)</span> and <span class="math inline">\(X_2\sim\mathcal{ME}xp(\Theta_2)\)</span>, independently. Then,
<span class="math display">\[
Z=\min\{X_1,X_2\}\sim\mathcal{ME}xp(\Theta_3)\text{ where }\Theta_3=_{\text{law}}\Theta_1+\Theta_2.
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-77" class="proof"><em>Proof</em>. </span>Clearly,
<span class="math display">\[
\Pr[Z&gt;t]=\Pr[X_1&gt;t]\Pr[X_2&gt;t];
\]</span>
thus, the tail function of <span class="math inline">\(Z\)</span> appears as the product of two completely monotone functions and, by virtue of Lemma <a href="chap3.html#lem:TechnicalRes">4.1</a> (1), it is also completely monotone. Proposition <a href="chap3.html#prp:Bernstein">4.24</a> then allows us to affirm that the distribution of <span class="math inline">\(Z\)</span> is indeed an exponential mixture. Moreover,
<span class="math display">\[\begin{eqnarray*}
\Pr[Z&gt;t] &amp; = &amp; L_{\Theta_3}(t) \\
&amp; = &amp; \Pr[X_1&gt;t]\Pr[X_2&gt;t] = L_{\Theta_1}(t)L_{\Theta_2}(t),
\end{eqnarray*}\]</span>
which concludes the proof.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-78" class="example"><strong>Example 4.22  </strong></span>Consider the family of probability distributions with hazard rate of the form
<span class="math display">\[
r_X(x)={\theta}+\frac{\alpha}{\lambda+x},
\hspace{2mm}x\in {\mathbb{R}}^+.
\]</span>
This can be seen as the sum of the hazard rate associated with the negative exponential distribution <span class="math inline">\(\mathcal{E}xp(\theta)\)</span> and that of the Pareto distribution <span class="math inline">\(\mathcal{P}ar(\alpha, \lambda)\)</span>. As the hazard rate of the random variable <span class="math inline">\(Z=\min\{X_1,X_2\}\)</span> is the sum of the hazard rates associated with the random variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>, this family of distributions can be seen as those of the minimum between <span class="math inline">\(X_1\sim \mathcal{E}xp(\theta)\)</span> and
<span class="math inline">\(X_2\sim\mathcal{P}ar(\alpha, \lambda)\)</span>. According to Property <a href="chap3.html#prp:MinMelExp">4.25</a> (1), this
family is an exponential mixture with the mixing distribution being the translated Gamma distribution. This model can be used when the estimation of the parameters of the Pareto model yields <span class="math inline">\(\alpha&lt;2\)</span> (rendering the variance infinite); the Pareto model might be too severe, and this model can be preferred over it.</p>
</div>
</div>
</div>
</div>
<div id="pure-premium-in-segmented-universe" class="section level2 hasAnchor" number="4.9">
<h2><span class="header-section-number">4.9</span> Pure Premium in Segmented Universe<a href="chap3.html#pure-premium-in-segmented-universe" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="segmentation-techniques" class="section level3 hasAnchor" number="4.9.1">
<h3><span class="header-section-number">4.9.1</span> Segmentation Techniques<a href="chap3.html#segmentation-techniques" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="definition-of-segmentation" class="section level4 hasAnchor" number="4.9.1.1">
<h4><span class="header-section-number">4.9.1.1</span> Definition of Segmentation<a href="chap3.html#definition-of-segmentation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Insurance portfolios are often heterogeneous. This is why for a long time, the premium charged to policyholders has varied based on characteristics specific to them and their observed claims experience. This is referred to as segmentation. This term is currently considered part of professional jargon and can be defined as follows.</p>
<div class="definition">
<p><span id="def:unlabeled-div-79" class="definition"><strong>Definition 4.15  </strong></span>Segmentation is any technique that an insurer uses to differentiate the premium, and possibly also the coverage, based on a number of specific characteristics of the risk to be insured. This is done in order to achieve a better alignment between the costs incurred by a specific individual and the premium that this individual must pay for the offered coverage. In some cases, this may involve the insurer declining to cover the risk.</p>
</div>
<p>This definition of segmentation relates to private insurance. Indeed, there are other forms of segmentation that, as in social insurance, are not directly related to the insured benefits but rather aim to distribute the burden of premiums among policyholders using factors that are fundamentally unrelated to the risk being insured (such as income level, for example).</p>
</div>
<div id="segmentation-techniques-1" class="section level4 hasAnchor" number="4.9.1.2">
<h4><span class="header-section-number">4.9.1.2</span> Segmentation Techniques<a href="chap3.html#segmentation-techniques-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Segmentation is not limited to the well-known premium differentiation, but also includes risk selection that the insurer undertakes at the time of contract conclusion (acceptance) or during the contract term (subsequent selection). The various stages of segmentation can thus be represented as follows:</p>
<p><span class="math display">\[
\begin{array}{c}
\text{Risk Acceptance}\\
\downarrow\\
\text{A priori Rating}\\
\text{Imposition of Deductibles}\\
\text{or Mandatory Retentions}\\
\text{Transformation of the Risk to be Insured}\\
\downarrow\\
\text{A posteriori Rating}\\
\text{Termination}
\end{array}
\]</span></p>
<p>In automobile insurance, there is typically an acceptance policy set by the company, either focusing on specific market segments (e.g., civil servants) or aiming to avoid certain profiles. The company may attach certain conditions to the acceptance of a risk (such as requiring the policyholder to attend defensive driving courses), or even impose coverage limitations, such as deductibles or mandatory retentions. The company then sets a premium amount {}, depending on the policyholder’s characteristics. It may also impose certain {} customization mechanisms, sometimes specific to certain categories of policyholders (e.g., subjecting young drivers to stricter {} adjustments).</p>
</div>
<div id="residual-heterogeneity" class="section level4 hasAnchor" number="4.9.1.3">
<h4><span class="header-section-number">4.9.1.3</span> Residual Heterogeneity<a href="chap3.html#residual-heterogeneity" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Given the multitude of existing risk factors, only a limited number of these factors can be utilized. Based on these factors, a first form of segmentation is applied. The initial heterogeneous set of risks is divided into more or less homogeneous groups. This is the purpose of {} rating techniques, which will be presented subsequently. Since only a limited number of risk factors are used in this division, individual differences will still remain within each risk group.</p>
<p>Considering the remaining heterogeneity within a risk group, differences in the claims statistics of policyholders within a tariff class should not only be attributed to chance but should also be considered to some extent as a reflection of the influence of risk factors that were not taken into account {}.</p>
</div>
<div id="experience-rating" class="section level4 hasAnchor" number="4.9.1.4">
<h4><span class="header-section-number">4.9.1.4</span> Experience Rating<a href="chap3.html#experience-rating" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Taking into account claims history gives rise to a second form of segmentation, which can be expressed in various ways:</p>
<p>1.by applying {} rating through a system like bonus-malus or “experience rating”;
2. by granting premium discounts based on observed claims experience;
3. by imposing a variable deductible that increases with the number of claims;
4. by using claims statistics as a criterion for subsequent selection.</p>
<p>We will delve more deeply into these matters later.</p>
<p>Finally, we note that {} customization is a correction of the shortcomings of {} customization, and therefore, the extent to which claims statistics come into play should depend on the degree of tariff precision applied {}.</p>
</div>
<div id="solidarity-and-segmentation" class="section level4 hasAnchor" number="4.9.1.5">
<h4><span class="header-section-number">4.9.1.5</span> Solidarity and Segmentation<a href="chap3.html#solidarity-and-segmentation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We have seen that the method of calculating the pure premium using mathematical expectation is based on three assumptions: similar, numerous, and sufficiently dispersed risks. In practice, the risks covered by an insurance company are far from being similar. Consider, for example, the motor liability risk. It is evident that a young driver with a red convertible Porsche living in a densely populated urban area is a very different risk from a retired civil servant living in a rural area. The insurer must decide whether to differentiate the premiums these two individuals will pay. If affirmative, the insurer will personalize the amount and thus prevent policyholders with the lowest risk level from subsidizing their peers with higher risk levels.</p>
<p>The insurer may wish to limit solidarity among different categories of policyholders and require each of them to pay the price for their coverage. In doing so, the insurer will group similar risks into risk classes where policyholders are indistinguishable from the point of view of the information held by the company. By doing this, it will, of course, reduce the size of the classes. Thus, in seeking to better satisfy one of the assumptions of the law of large numbers, we deviate from another.</p>
<p>Technically, the actuary will work conditionally on the characteristics of the policyholders. They will inquire about the frequency of claims for a policyholder knowing that they are 26 years old and live in a densely populated urban area. When the number of policyholders in certain risk classes (i.e., the set of policyholders with the same characteristics) is too small, the actuary will resort to regression models to establish tariffs. Conditional laws and their moments will therefore be very important in this context.</p>
</div>
</div>
<div id="conditional-expectation" class="section level3 hasAnchor" number="4.9.2">
<h3><span class="header-section-number">4.9.2</span> Conditional Expectation<a href="chap3.html#conditional-expectation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="definition-for-counting-variables" class="section level4 hasAnchor" number="4.9.2.1">
<h4><span class="header-section-number">4.9.2.1</span> Definition for Counting Variables<a href="chap3.html#definition-for-counting-variables" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The discrete case poses no problems. Given a pair <span class="math inline">\((N_1, N_2)\)</span> of counting random variables, the conditional expectation of <span class="math inline">\(N_2\)</span> given <span class="math inline">\(N_1 = n_1\)</span> is given by
<span class="math display">\[
\mathbb{E}[N_2|N_1=n_1] = \sum_{n_2 \in \mathbb{N}} n_2 \Pr[N_2=n_2|N_1=n_1].
\]</span></p>
<p>::: {.example name = “Continuation of Example <a href="#exm:PoissonCommonShock"><strong>??</strong></a>”]
Let’s calculate the conditional expectation of <span class="math inline">\(N_2\)</span> given <span class="math inline">\(N_1=n_1\)</span>:
<span class="math display">\[\begin{eqnarray*}
&amp; &amp; \mathbb{E}[N_2|N_1=n_1]
\\
&amp;=&amp; \sum_{k \in \mathbb{N}} \mathbb{E}[N_2|N_1=n_1,M=k]\Pr[M=k|N_1=n_1]\\
&amp;=&amp; \sum_{k=0}^{n_1} \mathbb{E}[N_2|M=k]\frac{\Pr[N_1=n_1|M=k]\Pr[M=k]}{\Pr[N_1=n_1]}\\
&amp;=&amp; \sum_{k=0}^{n_1} \binom{n_1}{k}(k+\lambda_2)\frac{\lambda_1^{n_1-k}\mu^k}{(\lambda_1+\mu)^{n_1}}\\
&amp;=&amp; n_1\frac{\mu}{\lambda_1+\mu}+\lambda_2.
\end{eqnarray*}\]</span>
This last expression evolves linearly with <span class="math inline">\(n_1\)</span>.
:::</p>
</div>
<div id="definition-for-continuous-random-variables" class="section level4 hasAnchor" number="4.9.2.2">
<h4><span class="header-section-number">4.9.2.2</span> Definition for Continuous Random Variables<a href="chap3.html#definition-for-continuous-random-variables" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Now, consider a pair <span class="math inline">\((X_1, X_2)\)</span> of continuous random variables with density <span class="math inline">\(f_{\boldsymbol{X}}\)</span>. If we want to define <span class="math inline">\(\mathbb{E}[X_1|X_2=x_2]\)</span>, we will use the conditional density obtained in <a href="#eq:CondDens">(<strong>??</strong>)</a> and define
<span class="math display">\[
\mathbb{E}[X_1|X_2=x_2] = \int_{x_1 \in \mathbb{R}} x_1 f_{X_1}(x_1|x_2)dx_1.
\]</span></p>
</div>
<div id="definition-in-the-mixed-case" class="section level4 hasAnchor" number="4.9.2.3">
<h4><span class="header-section-number">4.9.2.3</span> Definition in the Mixed Case<a href="chap3.html#definition-in-the-mixed-case" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For a mixed pair <span class="math inline">\((X, N)\)</span> where <span class="math inline">\(X\)</span> takes values in <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(N\)</span> in <span class="math inline">\(\mathbb{N}\)</span>, we have
<span class="math display">\[
\mathbb{E}[X|N=n] = \int_{x \in \mathbb{R}^+} x f_{1|2}(x|n)dx
\]</span>
and
<span class="math display">\[
\mathbb{E}[N|X=x] = \sum_{n \in \mathbb{N}} n f_{2|1}(n|x).
\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-80" class="example"><strong>Example 4.23  </strong></span>If <span class="math inline">\(N\sim\mathcal{MP}oi(\lambda,\Theta)\)</span>, the cumulative distribution function of <span class="math inline">\(\Theta\)</span> given <span class="math inline">\(N=n\)</span>, denoted as <span class="math inline">\(F_\Theta(\cdot|n)\)</span>,
<span class="math display">\[\begin{eqnarray*}
F_\Theta(t|n) &amp;=&amp; \frac{\Pr[\Theta\leq t,N=n]}{\Pr[N=n]}\\
&amp;=&amp; \frac{\int_{\theta=0}^t \exp(-\lambda\theta)\frac{(\lambda\theta)^n}{n!}dF_\Theta(\theta)}
{\int_{\theta \in \mathbb{R}^+} \exp(-\lambda\theta)\frac{(\lambda\theta)^n}{n!}dF_\Theta(\theta)}\\
&amp;=&amp; \frac{\int_{\theta=0}^t \exp(-\lambda\theta)\theta^n dF_\Theta(\theta)}
{\int_{\theta \in \mathbb{R}^+} \exp(-\lambda\theta)\theta^n dF_\Theta(\theta)}.
\end{eqnarray*}\]</span>
This allows us to calculate the conditional expectation:
<span class="math display">\[
\mathbb{E}[\Theta|N=n] = \int_{\theta \in \mathbb{R}^+} \theta dF_\Theta(\theta|n)
\]</span>
which eventually gives
<span class="math display">\[
\mathbb{E}[\Theta|N=n] = \frac{\int_{\theta=0}^t \exp(-\lambda\theta)\theta^{n+1}dF_\Theta(\theta)}
{\int_{\theta \in \mathbb{R}^+} \exp(-\lambda\theta)\theta^n dF_\Theta(\theta)}.
\]</span></p>
</div>
<div class="remark">
<p><span id="unlabeled-div-81" class="remark"><em>Remark</em>. </span>Sometimes, the conditional expectation of the random variable <span class="math inline">\(X\)</span> given that an event <span class="math inline">\(E\)</span> has occurred is denoted as <span class="math inline">\(\mathbb{E}[X|E]\)</span>. This is actually the mean associated with the cumulative distribution function
<span class="math display">\[
F_X(x|E) = \Pr[X\leq x|E],\hspace{2mm}x \in \mathbb{R}.
\]</span></p>
</div>
</div>
<div id="properties-of-conditional-expectation" class="section level4 hasAnchor" number="4.9.2.4">
<h4><span class="header-section-number">4.9.2.4</span> Properties of Conditional Expectation<a href="chap3.html#properties-of-conditional-expectation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>It is easily verified that conditional expectation has the following properties for any random variables <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, and <span class="math inline">\(X_3\)</span>, and any real constant <span class="math inline">\(c\)</span>:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\mathbb{E}[c|X_1=x_1]=c\)</span> for any <span class="math inline">\(x_1\in\mathbb{R}\)</span>.</li>
<li><span class="math inline">\(\mathbb{E}[X_1+X_2|X_3=x_3]=\mathbb{E}[X_1|X_3=x_3]+\mathbb{E}[X_2|X_3=x_3]\)</span> for any <span class="math inline">\(x_3\in\mathbb{R}\)</span>.</li>
<li><span class="math inline">\(\mathbb{E}[cX_1|X_2=x_2]=c\mathbb{E}[X_1|X_2=x_2]\)</span>, for any <span class="math inline">\(x_2\in\mathbb{R}\)</span>.</li>
<li>for any function <span class="math inline">\(g\)</span>, <span class="math inline">\(\mathbb{E}[g(X_1,X_2)|X_2=x_2]=\mathbb{E}[g(X_1,x_2)|X_2=x_2]\)</span> for any <span class="math inline">\(x_2\in\mathbb{R}\)</span>.</li>
<li>if <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are independent, then <span class="math inline">\(\mathbb{E}[X_1|X_2=x_2]=\mathbb{E}[X_1]\)</span>.</li>
</ol>
</div>
<div id="conditional-expectation-as-a-random-variable" class="section level4 hasAnchor" number="4.9.2.5">
<h4><span class="header-section-number">4.9.2.5</span> Conditional Expectation as a Random Variable<a href="chap3.html#conditional-expectation-as-a-random-variable" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Unless <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are independent, the conditional distribution of <span class="math inline">\(X_1\)</span> given <span class="math inline">\(X_2=x_2\)</span> depends on <span class="math inline">\(x_2\)</span>. In particular, <span class="math inline">\(\mathbb{E}[X_1|X_2=x_2]\)</span> is a function of <span class="math inline">\(x_2\)</span>, i.e.,
<span class="math display">\[
\mathbb{E}[X_1|X_2=x_2]=h^*(x_2).
\]</span>
Thus, one could be interested in the random variable
<span class="math display">\[
h^*(X_2)=\mathbb{E}[X_1|X_2].
\]</span></p>
<div class="proposition">
<p><span id="prp:Property3.8.5" class="proposition"><strong>(#prp:Property3.8.5) </strong></span>The random variable <span class="math inline">\(\mathbb{E}[X_1|X_2]\)</span> has the same mean as <span class="math inline">\(X_1\)</span>:
<span class="math display">\[
\mathbb{E}\Big[\mathbb{E}[X_1|X_2]\Big]=\mathbb{E}[X_1].
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-82" class="proof"><em>Proof</em>. </span>When <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are continuous, this equality is established as follows:
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}\Big[\mathbb{E}[X_1|X_2]\Big]&amp;=&amp;\int_{x_2\in\mathbb{R}}\mathbb{E}[X_1|X_2=x_2]f_2(x_2)dx_2\\
&amp;=&amp;\int_{x_2\in\mathbb{R}}\left\{\int_{x_1\in\mathbb{R}}x_1f_{1|2}(x_1|x_2)dx_1\right\}f_2(x_2)dx_2\\
&amp;=&amp;\int_{x_2\in\mathbb{R}}\int_{x_1\in\mathbb{R}}x_1f_{\boldsymbol{X}}(x_1,x_2)dx_1dx_2\\
&amp;=&amp;\int_{x_1\in\mathbb{R}}x_1f_1(x_1)dx_1=\mathbb{E}[X_1].
\end{eqnarray*}\]</span>
The reasoning is similar for discrete and mixed cases.</p>
</div>
</div>
<div id="characteristic-of-conditional-expectation" class="section level4 hasAnchor" number="4.9.2.6">
<h4><span class="header-section-number">4.9.2.6</span> Characteristic of Conditional Expectation<a href="chap3.html#characteristic-of-conditional-expectation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let’s now highlight a remarkable characteristic of conditional expectation, which can be taken as a general definition of this concept.</p>
<div class="proposition">
<p><span id="prp:Property3.8.6" class="proposition"><strong>(#prp:Property3.8.6) </strong></span>For any function <span class="math inline">\(h:\mathbb{R}\to\mathbb{R}\)</span>, we have
<span class="math display">\[
\mathbb{E}\Big[h(X_2)\big\{X_1-\mathbb{E}[X_1|X_2]\big\}\Big]=0.
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-83" class="proof"><em>Proof</em>. </span>Property @ref(prp:Property3.8.5) allows us to write
<span class="math display">\[\begin{eqnarray*}
&amp; &amp; \mathbb{E}\Big[h(X_2)\big\{X_1-\mathbb{E}[X_1|X_2]\big\}\Big]\\
&amp;= &amp; \mathbb{E}\left[\mathbb{E}\Big[h(X_2)\big\{X_1-\mathbb{E}[X_1|X_2]\big\}\Big|X_2\Big]\right]\\
  &amp;= &amp; \mathbb{E}\left[h(X_2)\mathbb{E}\Big[\big\{X_1-\mathbb{E}[X_1|X_2]\big\}\Big|X_2\Big]\right]=0,
  \end{eqnarray*}\]</span>
which completes the verification of the announced result.</p>
</div>
<p>One can see <span class="math inline">\(X_1-\mathbb{E}[X_1|X_2]\)</span> as a residue (i.e., as the part of <span class="math inline">\(X_1\)</span> that <span class="math inline">\(X_2\)</span> fails to explain). Property @ref(prp:Property3.8.6) then expresses the orthogonality between any predictor <span class="math inline">\(h(X_2)\)</span> and the residue <span class="math inline">\(X-\mathbb{E}[X_1|X_2]\)</span>, an orthogonality relationship meaning that <span class="math inline">\(X_2\)</span> can no longer explain anything about this residue. This ensures that <span class="math inline">\(\mathbb{E}[X_1|X_2]\)</span> is the best predictor of <span class="math inline">\(X_1\)</span> in terms of least squares, as indicated by the following result.</p>
<div class="proposition">
<p><span id="prp:Propertyhstar1" class="proposition"><strong>Proposition 4.26  </strong></span>The random variable <span class="math inline">\(h^*(X_2)=\mathbb{E}[X_1|X_2]\)</span> minimizes <span class="math inline">\(\mathbb{E}[(X_1-h(X_2))^2]\)</span> over all functions <span class="math inline">\(h\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-84" class="proof"><em>Proof</em>. </span>Let’s write
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[(X_1-h(X_2))^2]&amp;=&amp;\mathbb{E}[(X_1-\mathbb{E}[X_1|X_2]+\mathbb{E}[X_1|X_2]-h(X_2))^2]\\
&amp;=&amp;\underbrace{\mathbb{E}[(X_1-\mathbb{E}[X_1|X_2])^2]}_{\text{independent of $h$}}
+\mathbb{E}[(\mathbb{E}[X_1|X_2]-h(X_2))^2]\\
&amp; &amp; +2\underbrace{\mathbb{E}[(X_1-\mathbb{E}[X_1|X_2])(\mathbb{E}[X_1|X_2]-h(X_2))]}_{\text{=0 by definition of conditional expectation}}
\end{eqnarray*}\]</span>
which will be minimized when <span class="math inline">\(h(X_2)=\mathbb{E}[X_1|X_2]\)</span>.</p>
</div>
<p>Of course, there is no reason to limit ourselves to a single conditioning variable, and we can consider a vector <span class="math inline">\(\boldsymbol{X}\)</span> of dimension <span class="math inline">\(n\)</span> and define <span class="math inline">\(\mathbb{E}[X_1|X_2,\ldots,X_n]\)</span>.</p>
<div class="definition">
<p><span id="def:unlabeled-div-85" class="definition"><strong>Definition 4.16  </strong></span>Consider a random vector <span class="math inline">\(\boldsymbol{X}\)</span> of dimension <span class="math inline">\(n\)</span>. The conditional expectation <span class="math inline">\(\mathbb{E}[X_1|X_2,\ldots,X_n]\)</span> of <span class="math inline">\(X_1\)</span> given <span class="math inline">\(X_2,\ldots,X_n\)</span> is the random variable <span class="math inline">\(h^*(X_2,\ldots,X_n)\)</span> such that the equation
<span class="math display" id="eq:GeneralDefCondExp">\[\begin{equation}
\mathbb{E}\big[h(X_2,\ldots,X_n)\{X_1-h^*(X_2,\ldots,X_n)\}\big]=0,\tag{4.23}
\end{equation}\]</span>
holds for all functions <span class="math inline">\(h:\mathbb{R}^{n-1}\to\mathbb{R}\)</span>.</p>
</div>
<p>The variables (or vectors) behind the conditioning bar <span class="math inline">\(|\)</span> are assumed to be grouped into a single vector. We can then easily generalize Property <a href="chap3.html#prp:Propertyhstar1">4.26</a> as follows.
::: {.proposition #Propertyhstar}
The random variable <span class="math inline">\(h^*(X_2,\ldots,X_n)=\mathbb{E}[X_1|X_2,\ldots,X_n]\)</span> is the function of <span class="math inline">\(X_2,\ldots,X_n\)</span> that minimizes <span class="math inline">\(\mathbb{E}[(X_1-h(X_2,\ldots,X_n))^2]\)</span> over all functions <span class="math inline">\(h:\mathbb{R}^{n-1}\to\mathbb{R}\)</span>.
:::</p>
</div>
<div id="conditional-variance" class="section level4 hasAnchor" number="4.9.2.7">
<h4><span class="header-section-number">4.9.2.7</span> Conditional Variance<a href="chap3.html#conditional-variance" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Given a pair <span class="math inline">\((X_1,X_2)\)</span>, we define the conditional variance of <span class="math inline">\(X_1\)</span> given that the event <span class="math inline">\(\{X_2=x_2\}\)</span> has occurred as
<span class="math display">\[
\mathbb{V}[X_1|X_2=x_2]=\mathbb{E}\Big[\big(X_1-\mathbb{E}[X_1|X_2=x_2]\big)^2\big)\Big|X_2=x_2\Big].
\]</span>
Thus, we can define the function <span class="math inline">\(v(x_2)=\mathbb{V}[X_1|X_2=x_2]\)</span> and take interest in the random variable
<span class="math display">\[
v(X_2)=\mathbb{V}[X_1|X_2].
\]</span></p>
<div class="proposition">
<p><span id="prp:PropertyVarH" class="proposition"><strong>Proposition 4.27  (Variance Decomposition) </strong></span>For any random variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>,
<span class="math display">\[
\mathbb{V}[X_1]=\mathbb{E}\Big[\mathbb{V}[X_1|X_2]\Big]+\mathbb{V}\Big[\mathbb{E}[X_1|X_2]\Big].
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-86" class="proof"><em>Proof</em>. </span>Following the reasoning that led to the optimality of conditional expectation in terms of least squares in Property <a href="chap3.html#prp:Propertyhstar1">4.26</a>, we obtain
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[(X_1-\mathbb{E}[X_2])^2]&amp;=&amp;\mathbb{E}[(X_1-\mathbb{E}[X_1|X_2])^2]+\mathbb{E}[(\mathbb{E}[X_1|X_2]-\mathbb{E}[X_2])^2]\\
&amp;= &amp; \mathbb{E}\big[\mathbb{V}[X_1|X_2]\big]+\mathbb{E}\big[(\mathbb{E}[X_1|X_2]-\mathbb{E}[X_2])^2\big],
\end{eqnarray*}\]</span>
which completes the verification.</p>
</div>
<p>Just like with conditional expectation, we can condition with respect to multiple random variables (thus with respect to a random vector) and define
<span class="math display">\[
\mathbb{V}[X_1|X_2,\ldots,X_n]=\mathbb{E}\Big[\big(X_1-\mathbb{E}[X_1|X_2,\ldots,X_n]\big)^2\big)\Big|X_2,\ldots,X_n\Big].
\]</span>
An obvious adaptation of the reasoning used in the proof of Property <a href="chap3.html#prp:PropertyVarH">4.27</a> shows that the decomposition
<span class="math display">\[
\mathbb{V}[X_1]=\mathbb{E}\Big[\mathbb{V}[X_1|X_2,\ldots,X_n]\Big]+\mathbb{V}\Big[\mathbb{E}[X_1|X_2,\ldots,X_n]\Big]
\]</span>
holds.</p>
</div>
</div>
<div id="customization-of-premiums" class="section level3 hasAnchor" number="4.9.3">
<h3><span class="header-section-number">4.9.3</span> Customization of Premiums<a href="chap3.html#customization-of-premiums" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="principle" class="section level4 hasAnchor" number="4.9.3.1">
<h4><span class="header-section-number">4.9.3.1</span> Principle<a href="chap3.html#principle" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The actuary may decide to personalize the amount of premiums. To do this, they will use the characteristics of the insured individuals that they are aware of, summarized in a vector <span class="math inline">\(\boldsymbol{X}\)</span>, for instance. These characteristics might include age, gender, address, marital status, occupation, etc., of the insured, as well as characteristics of the insured property (value, etc.), the type of policy (deductible, duration, etc.), or even the claims history. The premium will then be a function
<span class="math inline">\(g(\boldsymbol{X})\)</span> of these characteristics.</p>
<p>At the beginning of a period, the insurer will determine the premium amount using the relevant risk characteristics (which they have incorporated into their pricing). It’s also possible that, for business reasons, the insurer deliberately decides not to consider certain critical factors. This creates cross-subsidies between different categories of insured individuals, which the actuary must be able to measure. In such cases, it’s also useful to keep track of the “exact” premium that the insured individual should have paid if there hadn’t been any commercial simplifications (this is the purpose of the technical rate, which can be quite different from the commercial rate).</p>
<p>From a theoretical standpoint, it’s interesting to note that when the insurer takes into account the characteristics <span class="math inline">\(\boldsymbol{X}\)</span> to determine the pure premium, the future premiums that insured individuals will have to pay become random. If an insured individual moves, becomes a parent, or changes their car, the premium they pay to an insurer that factors in the address, number of children, or type of vehicle into their rate will be modified. This is a fundamentally different situation from the classic case where the premium is constant.</p>
</div>
<div id="determination-of-the-pure-premium-in-a-segmented-universe" class="section level4 hasAnchor" number="4.9.3.2">
<h4><span class="header-section-number">4.9.3.2</span> Determination of the Pure Premium in a Segmented Universe<a href="chap3.html#determination-of-the-pure-premium-in-a-segmented-universe" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In order to determine the appropriate function <span class="math inline">\(g\)</span>, we’ll choose the one that provides the best approximation of the financial burden <span class="math inline">\(S\)</span> of the insurer with respect to a particular insured individual, i.e., <span class="math inline">\(g\)</span> should minimize
<span class="math display">\[
d_2(S,g(\boldsymbol{X}))=\mathbb{E}[(S-g(\boldsymbol{X}))^2].
\]</span>
Property <a href="#prp:Propertyhstar"><strong>??</strong></a> teaches us that this function is precisely the conditional expectation of <span class="math inline">\(S\)</span> given <span class="math inline">\(\boldsymbol{X}\)</span>. Thus, when the actuary decides to customize the premium amount, the pure premium is no longer the expectation <span class="math inline">\(\mathbb{E}[S]\)</span> but rather the conditional expectation <span class="math inline">\(\mathbb{E}[S|\boldsymbol{X}]\)</span>.</p>
<p>Intuitively, this means that each insured individual is no longer required to pay the average claims cost per policy, but instead, these averages are calculated within each risk class (where insured individuals are identical based on the segmentation criteria chosen by the company) and passed on to the insured individuals in that class. In practice, however, things are not that simple because some classes might have very few policies. Estimating the average claims cost of the insurer relative to a class with only a few policies cannot be done accurately enough. In the extreme case, if a class contains only one insured individual who had no claims during the year, it’s difficult to imagine that the insurer would exempt them from paying their premium the following year. Therefore, it’s necessary to build regression models in practice, which compensate for the low sample size in certain risk classes. The frequencies and costs of claims for different categories of insured individuals in the portfolio are connected by common parameters, which will be estimated based on observations related to the portfolio.</p>
</div>
<div id="interaction-between-rating-variables" class="section level4 hasAnchor" number="4.9.3.3">
<h4><span class="header-section-number">4.9.3.3</span> Interaction between Rating Variables<a href="chap3.html#interaction-between-rating-variables" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>There is often talk of the marginal impact of a rating variable, despite the interactions it may have with other risk factors. If an insurance company notices that the claims experience is particularly bad in a certain region, should it conclude that the region is risky and increase the premium for drivers who live there? Not necessarily, in fact: the increased claims experience could be due to a completely different factor (e.g., less experienced drivers living there). It’s even possible that this region is actually less risky than others, all else being equal. This demonstrates that the effect of each variable must be assessed independently, meaning corrected for the impact of all other variables.</p>
</div>
<div id="interaction-between-tariff-variables" class="section level4 hasAnchor" number="4.9.3.4">
<h4><span class="header-section-number">4.9.3.4</span> Interaction between tariff variables<a href="chap3.html#interaction-between-tariff-variables" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We often hear about the marginal impact of a rate variable, despite the interactions it may have with other risk factors. If a company notices that claims experience is particularly bad in a certain region, should it conclude that this region is dangerous and raise the rate for motorists living there? Not necessarily, in fact: the extra loss may be due to a completely different factor (for example, the inexperience of the drivers who live there). It’s even possible that this region is actually less risky than others, all other things being equal. This clearly shows that the effect of each variable must be assessed independently, i.e. after adjusting for the impact of all the others.</p>
</div>
<div id="true-and-apparent-dependencies" class="section level4 hasAnchor" number="4.9.3.5">
<h4><span class="header-section-number">4.9.3.5</span> True and apparent dependencies<a href="chap3.html#true-and-apparent-dependencies" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let’s consider the random variable <span class="math inline">\(I\)</span>, which takes the value 1 when the insured has declared at least one claim during the period under consideration, and 0 otherwise. We speak of apparent dependence between <span class="math inline">\(I\)</span> and a rate variable when the probability of having at least one claim depends on a variable correlated with this rate variable (whether hidden, such as aggressiveness at the wheel, or observable, such as the age of the insured, if the age structure differs according to this 3rd variable). In the latter case, the dependence between the rate variable and the fact of having or not having claims would disappear if the third variable were taken into account. To illustrate this point, let’s consider the following small example.</p>
</div>
</div>
<div id="segmentation-pooling-and-solidarity" class="section level3 hasAnchor" number="4.9.4">
<h3><span class="header-section-number">4.9.4</span> Segmentation, Pooling, and Solidarity<a href="chap3.html#segmentation-pooling-and-solidarity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Most often, segmentation pits proponents of pooling against advocates of solidarity. Fine tariff differentiation, made possible by technological advancements, can lead to an increase in inequalities and destabilization of the social fabric. However, segmentation and pooling are by no means mutually exclusive. Pooling consists of sharing risks collectively. In the absence of segmentation, these risks will be borne by individuals with different profiles, whereas after segmentation, the pooling will occur among individuals equally exposed to the risk.</p>
<div id="risk-pooling" class="section level4 hasAnchor" number="4.9.4.1">
<h4><span class="header-section-number">4.9.4.1</span> Risk Pooling<a href="chap3.html#risk-pooling" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let us consider the theoretical situation in which the insurer possesses complete information regarding all risk factors and, based on this information, charges each insured a premium that perfectly aligns with the estimated average cost of the claims they impose on the collective. This is the most advanced form of tariff differentiation.</p>
<p>The premiums paid by all insureds will be used to indemnify those who experience a claim. Since, by assumption, all risk factors are considered in the premium calculation, no one will be systematically favored. This is referred to as risk pooling: as insureds are rigorously identical, the transfer of premiums between insureds aims to mitigate the consequences of randomness.</p>
</div>
<div id="solidarity" class="section level4 hasAnchor" number="4.9.4.2">
<h4><span class="header-section-number">4.9.4.2</span> Solidarity<a href="chap3.html#solidarity" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The insurer is, of course, unable to incorporate the effect of all factors influencing risk into the premium calculation. In practice, individual differences will persist between the premium an insured must pay and the estimated cost of the claims they will cause.</p>
<p>This gives rise to transfers between insureds who overpay premiums and others who contribute too little. A portion of the premium paid by insureds with low risk levels will be used to compensate for claims caused by insureds with higher risk levels. The premium paid by these insureds no longer solely serves to compensate for claims affecting similar insureds, but also artificially reduces the amount of premium paid by other insureds with higher risk levels. This is referred to as solidarity: an undifferentiated or inadequately differentiated tariff induces premium transfers within portfolios and makes the insurer’s outcome dependent on the portfolio structure.</p>
</div>
<div id="limitations-of-segmentation" class="section level4 hasAnchor" number="4.9.4.3">
<h4><span class="header-section-number">4.9.4.3</span> Limitations of Segmentation<a href="chap3.html#limitations-of-segmentation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The question raised by segmentation primarily concerns how premiums should be distributed among the insured. Should a uniform effort be imposed, independent of the risk each individual represents? Or, on the contrary, should the contribution be based on this risk? Should other distinguishing factors (income, personal wealth, etc.) be taken into account? It is clear that we are touching upon the social aspect of the insurance market here: insurers sell security and thus cannot be equated with any other producer of goods. The answer to these questions will depend on the type of coverage and societal choices.</p>
<p>It seems evident that government intervention is desirable in certain cases. When it comes to imposing limitations on segmentation, a double distinction is often made based on the type of insurance and the nature of the risk factor.</p>
<p>Regarding the type of coverage, a distinction can be made between mandatory and non-mandatory insurances. If the law mandates a specific insurance (such as automobile liability insurance), it is logical for the political power to examine to what extent this obligation can be met in practice. This means that every potential insurance policyholder must have the guarantee of being able to obtain insurance at an affordable price.</p>
<p>The question of whether it is opportune to impose limitations on segmentation in the realm of non-mandatory insurances is much more delicate and must be answered with nuance. Some of these insurances (such as personal liability, fire insurance, outstanding balance insurance, …) cover significant risks for the insured, their family, or third parties. They are considered necessary by most consumers and are therefore widely spread. Easy access to these insurances is certainly desirable. To ensure this accessibility, a certain level of control by authorities is necessary. However, it is generally agreed that few or no limitations should be imposed when these voluntary insurances serve purely as conveniences (theft insurance, travel insurance, vehicle damage, …).</p>
<p>Regarding the nature of the risk factor, a distinction is made between risk factors that the consumer can influence through their free choice or behavior (smoking, alcohol or drug consumption, engaging in risky sports, …) and those that do not correlate, or do so to a lesser extent, with the insured’s free choice (gender, age, genetic profile, hereditary fitness, regional differences in jurisprudence, …).</p>
<p>For risk factors falling into the first category, there is consensus that they can be fully used as segmentation criteria. In these cases, there is no justification for a policyholder to pay for another person who, voluntarily, adopts a risky behavior. However, differentiating premiums based on factors over which the insured has no control does not enjoy unanimous support.</p>
</div>
</div>
<div id="DeWit" class="section level3 hasAnchor" number="4.9.5">
<h3><span class="header-section-number">4.9.5</span> Formalization of the Segmentation Concept<a href="chap3.html#DeWit" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="risk-transfer-in-an-unsegmented-universe" class="section level4 hasAnchor" number="4.9.5.1">
<h4><span class="header-section-number">4.9.5.1</span> Risk Transfer in an Unsegmented Universe<a href="chap3.html#risk-transfer-in-an-unsegmented-universe" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let us now attempt to formalize the problem of segmentation. Consider an insured individual subject to a risk <span class="math inline">\(S\)</span>, randomly drawn from an insurance portfolio. Suppose that all characteristics of the insured influencing the risk are encompassed in a random vector <span class="math inline">\(\boldsymbol{\Omega} = (\Omega_1, \Omega_2, \ldots)\)</span>. The notation “omega” recalls that the vector of the same name contains all information about the insured, whether observable by the insurer or not.</p>
<p>We can imagine that the insurer does not take the characteristics <span class="math inline">\(\boldsymbol{\Omega}\)</span> of the insured into account in any way and therefore demands a pure premium of <span class="math inline">\(\mathbb{E}[S]\)</span>, the same as that demanded from all insureds in the portfolio. In this case, the situation is as presented in Table <a href="chap3.html#tab:PasSegm">4.7</a>.</p>
<table>
<caption><span id="tab:PasSegm">Table 4.7: </span>Situation of insureds and insurer in the absence of segmentation</caption>
<thead>
<tr class="header">
<th align="center">X.</th>
<th align="center">Policyholders</th>
<th align="center">Insurer</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Expense</td>
<td align="center"><span class="math inline">\(\mathbb{E}[S]\)</span></td>
<td align="center"><span class="math inline">\(S - \mathbb{E}[S]\)</span></td>
</tr>
<tr class="even">
<td align="center">Average Expense</td>
<td align="center"><span class="math inline">\(\mathbb{E}[S]\)</span></td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">Variance</td>
<td align="center">0</td>
<td align="center"><span class="math inline">\(\mathbb{V}[S]\)</span></td>
</tr>
</tbody>
</table>
<p>The insurer thus assumes the entire variance of claims <span class="math inline">\(\mathbb{V}[S]\)</span>, whether it is due to the heterogeneity of the portfolio or the intrinsic variability of claim amounts.</p>
</div>
<div id="risk-transfer-with-complete-information" class="section level4 hasAnchor" number="4.9.5.2">
<h4><span class="header-section-number">4.9.5.2</span> Risk Transfer with Complete Information<a href="chap3.html#risk-transfer-with-complete-information" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>At the other extreme, let’s suppose that the insurer incorporates all the information <span class="math inline">\(\boldsymbol{\Omega}\)</span> into the pricing. We would then be in the situation described in Table <a href="chap3.html#tab:MondeParfait">4.8</a>.</p>
<table>
<caption><span id="tab:MondeParfait">Table 4.8: </span>Situation of insureds and insurer when segmentation is based on complete information</caption>
<colgroup>
<col width="12%" />
<col width="41%" />
<col width="45%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">X.</th>
<th align="center">Policyholders</th>
<th align="center">Insurer</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Expense</td>
<td align="center"><span class="math inline">\(\mathbb{E}[S\vert\boldsymbol{\Omega}]\)</span></td>
<td align="center"><span class="math inline">\(S - \mathbb{E}[S\vert\boldsymbol{\Omega}]\)</span></td>
</tr>
<tr class="even">
<td align="center">Average Expense</td>
<td align="center"><span class="math inline">\(\mathbb{E}[S]\)</span></td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">Variance</td>
<td align="center"><span class="math inline">\(\mathbb{V}\Big[\mathbb{E}[S\vert\boldsymbol{\Omega}]\Big]\)</span></td>
<td align="center"><span class="math inline">\(\mathbb{V}\Big[S - \mathbb{E}[S\vert\boldsymbol{\Omega}]\Big]\)</span></td>
</tr>
</tbody>
</table>
<p>Unlike the previous case, the premium paid by a randomly selected insured from the portfolio is now a random variable: <span class="math inline">\(\mathbb{E}[S|\boldsymbol{\Omega}]\)</span> depends on the characteristics <span class="math inline">\(\boldsymbol{\Omega}\)</span> of that insured. As the random variable <span class="math inline">\(S - \mathbb{E}[S|\boldsymbol{\Omega}]\)</span> is centered, the risk assumed by the insurer is the variance of the financial outcome of the insurance operation, i.e.,
<span class="math display">\[\begin{eqnarray*}
\mathbb{V}\Big[S - \mathbb{E}[S|\boldsymbol{\Omega}]\Big] &amp; = &amp; \mathbb{E}\Big[\Big(S - \mathbb{E}[S|\boldsymbol{\Omega}]\Big)^2\Big]\\
&amp; = &amp; \mathbb{E}\Big[\mathbb{E}\Big[\Big(S - \mathbb{E}[S|\boldsymbol{\Omega}]\Big)^2\Big|\boldsymbol{\Omega}\Big]\Big]\\
&amp; = &amp; \mathbb{E}\Big[\mathbb{V}[S|\boldsymbol{\Omega}]\Big].
\end{eqnarray*}\]</span>
In this case, we observe a sharing of the total variance of <span class="math inline">\(S\)</span> (i.e., the risk) between the insureds and the insurer, manifested by the formula
<span class="math display">\[
\mathbb{V}[S] = \underbrace{\mathbb{E}\Big[\mathbb{V}[S|\boldsymbol{\Omega}]\Big]}_{\to \text{insurer}}
+\underbrace{\mathbb{V}\Big[\mathbb{E}[S|\boldsymbol{\Omega}]\Big]}_{\to \text{insureds}}.
\]</span>
Thus, when all relevant variables <span class="math inline">\(\boldsymbol{\Omega}\)</span> have been accounted for, the insurer’s intervention is limited to the portion of claims exclusively due to chance; indeed, <span class="math inline">\(\mathbb{V}[S|\boldsymbol{\Omega}]\)</span> represents the fluctuations of <span class="math inline">\(S\)</span> due solely to randomness. In this ideal situation, the insurer pools the risk, and therefore, there is no induced solidarity among the insureds in the portfolio: each individual pays based on their own risk.</p>
</div>
<div id="risk-transfer-with-partial-information" class="section level4 hasAnchor" number="4.9.5.3">
<h4><span class="header-section-number">4.9.5.3</span> Risk Transfer with Partial Information<a href="chap3.html#risk-transfer-with-partial-information" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Of course, the situation described in the previous paragraph is purely theoretical, as among the explanatory variables <span class="math inline">\(\boldsymbol{\Omega}\)</span>, many cannot be observed by the insurer. In automobile insurance, for example, the insurer cannot observe the insured’s driving speed, their aggressiveness on the road, or the number of kilometers they travel each year (This last variable, measuring exposure to risk, is indirectly accounted for by factors like vehicle use—private/professional, for instance. We will delve into these questions in detail later). Therefore, the insurer can only utilize a subset <span class="math inline">\(\boldsymbol{X}\)</span> of the explanatory variables contained in <span class="math inline">\(\boldsymbol{\Omega}\)</span>, i.e., <span class="math inline">\(\boldsymbol{X}\subset \boldsymbol{\Omega}\)</span>. The situation is then similar to that described in Table <a href="chap3.html#tab:MondeReel">4.9</a>.</p>
<table>
<caption><span id="tab:MondeReel">Table 4.9: </span>Situation of insured and insurer when segmentation is based on partial information</caption>
<colgroup>
<col width="17%" />
<col width="41%" />
<col width="41%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">X.</th>
<th align="center">Policyholders</th>
<th align="center">Insurer</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Expense</td>
<td align="center"><span class="math inline">\(\mathbb{E}[S\vert\boldsymbol{X}]\)</span></td>
<td align="center"><span class="math inline">\(S - \mathbb{E}[S\vert\boldsymbol{X}]\)</span></td>
</tr>
<tr class="even">
<td align="center">Average Expense</td>
<td align="center"><span class="math inline">\(\mathbb{E}[S]\)</span></td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">Variance</td>
<td align="center"><span class="math inline">\(\mathbb{V}\Big[\mathbb{E}[S\vert\boldsymbol{X}]\Big]\)</span></td>
<td align="center"><span class="math inline">\(\mathbb{E}\Big[\mathbb{V}[S\vert\boldsymbol{X}]\Big]\)</span></td>
</tr>
</tbody>
</table>
<p>It is interesting to note that
<span class="math display" id="eq:FormOmegaX">\[\begin{eqnarray}
\mathbb{E}\Big[\mathbb{V}[S|\boldsymbol{X}]\Big]&amp;=&amp;
\mathbb{E}\Big[\mathbb{E}\Big[\mathbb{V}[S|\boldsymbol{\Omega}]\Big|\boldsymbol{X}\Big]\Big]
+\mathbb{E}\Big[\mathbb{V}\Big[\mathbb{E}[S|\boldsymbol{\Omega}]\Big|\boldsymbol{X}\Big]\Big]\nonumber
\\
&amp;=&amp;\underbrace{\mathbb{E}\Big[\mathbb{V}[S|\boldsymbol{\Omega}]\Big]}_{\text{mutualisation}}
+\underbrace{\mathbb{E}\Big\{\mathbb{V}\Big[\mathbb{E}[S|\boldsymbol{\Omega}]\Big|\boldsymbol{X}\Big]\Big\}}_{\text{solidarité}}.
\tag{4.24}
\end{eqnarray}\]</span>
This decomposition of the risk borne by the company can be interpreted as follows: the insurer, when not accounting for all risk factors, intervenes to mitigate the unfavorable consequences of randomness (first term of <a href="chap3.html#eq:FormOmegaX">(4.24)</a> representing risk pooling), but must also handle the variations in the exact pure premium <span class="math inline">\(\mathbb{E}[S|\boldsymbol{\Omega}]\)</span> that are not explained by the risk factors <span class="math inline">\(\boldsymbol{X}\)</span> included in the premium calculation (second term of <a href="chap3.html#eq:FormOmegaX">(4.24)</a>, representing solidarity induced by imperfect customization of the premium amount). In other words, besides countering unforeseen events, the insurer also needs to bear the variability of claims due to policyholders’ characteristics not considered in the premium.</p>
<p>In a segmentation based on <span class="math inline">\(\boldsymbol{X}\subset\boldsymbol{\Omega}\)</span>, the sharing of the variance of <span class="math inline">\(S\)</span> is as follows:
<span class="math display">\[\begin{eqnarray*}
\mathbb{V}[S]&amp;=&amp;\mathbb{E}\Big[\mathbb{V}[S|\boldsymbol{X}]\Big]+\mathbb{V}\Big[\mathbb{E}[S|\boldsymbol{X}]\Big]\\
&amp;=&amp;\underbrace{\underbrace{\mathbb{E}\Big[\mathbb{V}[S|\boldsymbol{\Omega}]\Big]}_{\text{mutualisation}}
+\underbrace{\mathbb{E}\Big[\mathbb{V}\Big[\mathbb{E}[S|\boldsymbol{\Omega}]\Big|\boldsymbol{X}\Big]\Big]}_{\text{solidarité}}}_{\to\text{insurer}}\\
&amp;&amp;+\underbrace{\mathbb{V}\Big[\mathbb{E}[S|\boldsymbol{X}]\Big]}_{\to\text{policyholders}}.
\end{eqnarray*}\]</span></p>
</div>
<div id="complementarity-between-and-rating" class="section level4 hasAnchor" number="4.9.5.4">
<h4><span class="header-section-number">4.9.5.4</span> Complementarity between {} and {} rating<a href="chap3.html#complementarity-between-and-rating" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The entire concept underlying experience rating (which will be discussed in detail in a dedicated chapter) is that of history. More precisely, if we denote <span class="math inline">\(\boldsymbol{S}^\leftarrow\)</span> as information about policyholders’ past claims available to the insurer, the information contained in <span class="math inline">\((\boldsymbol{X},\boldsymbol{S}^\leftarrow)\)</span> becomes comparable to <span class="math inline">\(\boldsymbol{\Omega}\)</span>, such that <span class="math inline">\(\mathbb{E}[S|\boldsymbol{X},\boldsymbol{S}^\leftarrow]\)</span> should converge to <span class="math inline">\(\mathbb{E}[S|\boldsymbol{\Omega}]\)</span> (in a sense to be specified).</p>
</div>
</div>
<div id="drawbacks-resulting-from-extensive-segmentation" class="section level3 hasAnchor" number="4.9.6">
<h3><span class="header-section-number">4.9.6</span> Drawbacks Resulting from Extensive Segmentation<a href="chap3.html#drawbacks-resulting-from-extensive-segmentation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="a-spiraling-process-of-increasing-segmentation" class="section level4 hasAnchor" number="4.9.6.1">
<h4><span class="header-section-number">4.9.6.1</span> A Spiraling Process of Increasing Segmentation<a href="chap3.html#a-spiraling-process-of-increasing-segmentation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>If, unlike the competition, an insurance company neglects a significant segmentation criterion, it will (assuming market efficiency) only attract risks deemed unfavorable with respect to that criterion, while the good risks (according to that criterion) will go to competitors. This process of adverse selection against the less segmenting insurer will be further amplified by the opinions of intermediaries and consumer associations.</p>
<p>As a result, insurers must more or less align their segmentation policies with each other. Since there will always be an insurer who, for business reasons, wants to segment more than its competitors, the risk of falling into an ever-increasing segmentation spiral is very real.</p>
</div>
<div id="uninsurability" class="section level4 hasAnchor" number="4.9.6.2">
<h4><span class="header-section-number">4.9.6.2</span> Uninsurability<a href="chap3.html#uninsurability" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Certain policyholders might find themselves unable to obtain insurance coverage if the offered premiums are too high. Thus, it does not seem socially desirable to charge certain categories of young drivers premiums that are too high for their motor liability insurance, even if it can be justified technically. The implementation of an extensive segmentation policy would inevitably increase the number of uninsured drivers. A similar problem could also arise for other risk classes, such as older drivers.</p>
<p>The problem of excluding certain risks can only be resolved by imposing a certain level of solidarity among different categories of policyholders. To address this issue, the state often introduces a requirement for collective acceptance within the community of insurers: bad risks that cannot be placed in the regular market could be insured through a pool involving all insurers operating in that line of business.</p>
</div>
<div id="higher-operating-costs" class="section level4 hasAnchor" number="4.9.6.3">
<h4><span class="header-section-number">4.9.6.3</span> Higher Operating Costs<a href="chap3.html#higher-operating-costs" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To differentiate premiums using a technically sound method, it is necessary for the insurer to maintain files containing a large amount of data, while respecting the limits imposed by privacy laws. Processing all this information requires extra work and can lead to increased administrative costs.</p>
<p>Indirectly, segmentation results in policyholders switching insurers more frequently, contributing to cost escalation.</p>
</div>
</div>
<div id="segmentation-and-information-asymmetry" class="section level3 hasAnchor" number="4.9.7">
<h3><span class="header-section-number">4.9.7</span> Segmentation and Information Asymmetry<a href="chap3.html#segmentation-and-information-asymmetry" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="concepts" class="section level4 hasAnchor" number="4.9.7.1">
<h4><span class="header-section-number">4.9.7.1</span> Concepts<a href="chap3.html#concepts" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The theory of contracts, especially in the context of insurance contracts, has reached a high level of sophistication. In particular, the literature includes detailed studies on adverse selection and moral hazard, as well as mechanisms to mitigate these undesirable effects.</p>
<p>The literature on markets with incomplete information, of which insurance is a prime example, usually distinguishes two categories of phenomena:</p>
<ol style="list-style-type: decimal">
<li>those related to the unobservable nature of an immutable characteristic of the exchanged good or service, which is referred to as adverse selection;</li>
<li>those arising from the unobservability of an action undertaken by one of the two exchange partners, which falls under the category of moral hazard.</li>
</ol>
<p>For a comprehensive study, readers can refer to <span class="citation">(<a href="#ref-salanie1996theorie" role="doc-biblioref">Salanié 1996</a>)</span>.</p>
<p>These phenomena justify many common practices of insurers. For instance, {} classification procedures are often seen as a way to mitigate adverse selection effects, while updating premium amounts (through mechanisms like bonus-malus systems) should eliminate a portion of moral hazard.</p>
</div>
<div id="definition-of-adverse-selection" class="section level4 hasAnchor" number="4.9.7.2">
<h4><span class="header-section-number">4.9.7.2</span> Definition of Adverse Selection<a href="chap3.html#definition-of-adverse-selection" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A characteristic of private insurance lies in the freedom of both parties involved, the policyholder and the insurer, to contract. The potential policyholder is free to determine whether, when, where, and how to insure. Thus, they will choose the insurance contract they find most appealing. Moreover, the potential policyholder has a significant advantage in terms of information compared to an insurer that segments less. The potential policyholder knows their own situation very precisely, while the concerned insurer has no knowledge of certain risk-aggravating factors that may be present. This asymmetric information leads to adverse selection from policyholders.</p>
</div>
<div id="blissful-ignorance" class="section level4 hasAnchor" number="4.9.7.3">
<h4><span class="header-section-number">4.9.7.3</span> Blissful Ignorance<a href="chap3.html#blissful-ignorance" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>It is important to grasp the fact that the problem lies in the insured’s knowledge of their risk profile. Conversely, if ignorance is symmetric—meaning neither the insured nor the insurer have knowledge of factors influencing the risk level—the insurer will cover the peril based on the collective average risk.</p>
<p>Let’s push the reasoning further and show that when the contracting parties lack knowledge of information that can influence the risk level, they are actually entering into a multi-guarantee insurance contract.</p>
<div class="example">
<p><span id="exm:unlabeled-div-87" class="example"><strong>Example 4.24  </strong></span>Suppose that 5% of the population is predisposed to a disease M. More precisely, in the case of predisposition, the probability of developing disease M is 95%, whereas it is only 10% in the absence of predisposition. This predisposition can be detected using a genetic test, but its use is prohibited for insurers and too costly for policyholders. The cost of treating disease M is 100,000. The pure premium for coverage against this disease is
<span class="math display">\[
(0.5\times 0.95+0.95\times 0.1)\times 100\hspace{1mm}000\text{Euros}.
\]</span></p>
<p>Upon closer examination of this example, it becomes evident that uniform pricing actually covers two distinct risks: first, the risk of being predisposed to disease M, and second, the risk of developing the disease. It’s also noticeable that this is the only way to provide acceptable coverage conditions for predisposed individuals (who, if identifiable, would pay a pure premium of $95%$100,000,000, nearly the cost of treatment).</p>
</div>
<p>Symmetric ignorance, therefore, has a particularly advantageous aspect in broadening the scope of insurance. This is in fact the essence of the Hirschleifer paradox, according to which broader information is not always desirable. Uncertainty has a significant advantage in allowing insurance. Thus, the widespread use of genetic tests would render coverage for certain risk populations impossible, whereas ignorance of the predisposition of the insured to certain diseases makes insurance possible.</p>
</div>
<div id="adverse-selection" class="section level4 hasAnchor" number="4.9.7.4">
<h4><span class="header-section-number">4.9.7.4</span> Adverse-selection<a href="chap3.html#adverse-selection" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>While the threat posed by adverse selection to insurance business is indeed real, solutions do exist. For instance, for a death coverage, it might be sufficient to exclude engaging in dangerous sports and impose strict coverage and acceptance conditions to curb adverse selection.</p>
<p>Another common solution is to encourage aggravated risks to identify themselves. For instance, for physical damage insurance on vehicles, offering different deductible levels is often enough for risky policyholders to prefer lower deductibles, while good drivers will readily opt for higher deductibles.</p>
</div>
<div id="moral-hazard" class="section level4 hasAnchor" number="4.9.7.5">
<h4><span class="header-section-number">4.9.7.5</span> Moral Hazard<a href="chap3.html#moral-hazard" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Being insured influences risk-related behavior. The assumption of risks by the insurer can indeed dilute individual responsibilities and discourage prevention, leading to an increase in total risk. For instance, someone who has purchased theft insurance may be inclined to take fewer precautions. Someone who is covered for healthcare expenses is more likely to be hospitalized for treatments that are not strictly necessary or more expensive. Alongside the insured normal risk, an additional risk emerges, called “moral hazard.”</p>
<p>Segmentation can mitigate this phenomenon:</p>
<ol style="list-style-type: decimal">
<li>Partial risk coverage through mandatory deductibles, excess payments, or capped payments has an impact on the insured, who will then attempt to limit the frequency and/or cost of claims.</li>
<li>Subsequent selection and {} pricing can encourage the insured to behave more cautiously.</li>
</ol>
<p>There are numerous contexts in which the self-protective activities of the insured significantly impact the claim costs borne by the insurer. Ideally, the insurer would include provisions in the general conditions of policies that encourage policyholders to take all measures to prevent claims. For example, an insured individual who falls victim to a burglary at home must provide evidence of a break-in (thus proving they were not negligent in leaving the door open), under penalty of losing the right to coverage. However, often these self-protective activities are not observable by the insurer.</p>
</div>
<div id="distinguishing-moral-hazard-and-adverse-selection" class="section level4 hasAnchor" number="4.9.7.6">
<h4><span class="header-section-number">4.9.7.6</span> Distinguishing Moral Hazard and Adverse Selection<a href="chap3.html#distinguishing-moral-hazard-and-adverse-selection" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The distinction between moral hazard and adverse selection can be reduced to a causality problem. With moral hazard, the unobservable actions of individuals that affect claim occurrence are consequences of the contract forms (these unobservable actions are induced by the degree of coverage offered by the policy, increasing when protection decreases). For example, an insurance policy may cause an increase in claims occurrence because it reduces incentives for caution. Thus, following an exogenous change in an insurance contract (such as a modification of coverage conditions), its effect can be tested by limiting it to insured individuals already present in the portfolio and isolating a moral hazard effect.</p>
<p>With pure adverse selection, the nature of different risks precedes the subscription of policies; the choices of coverage levels are the consequences of the different risks present. There is thus a form of inverse causality between the two information problems.</p>
<p>The distinction between the two phenomena can be summarized in the following formula:
<span class="math display">\[
\begin{array}{c}
\text{People buying more insurance become more risky}\\
\text{versus}\\
\text{Risky people buy more insurance.}
\end{array}
\]</span></p>
</div>
</div>
</div>
<div id="exercises-1" class="section level2 hasAnchor" number="4.10">
<h2><span class="header-section-number">4.10</span> Exercises<a href="chap3.html#exercises-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="exercise">
<p><span id="exr:ExoSL" class="exercise"><strong>Exercise 4.1  </strong></span>Establish the following identities:
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}[X]
=\mathbb{E}[F_X^{-1}(U)]
&amp;=&amp;\int_{p=0}^1F_X^{-1}(p)dp\\
\mathbb{E}[(X-t)_+]&amp;=&amp;\int_{p=F_X(t)}^1F_X^{-1}(p)dp-t\overline{F}_X(t).
\end{eqnarray*}\]</span></p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-88" class="exercise"><strong>Exercise 4.2  </strong></span>To determine the pure premium, we could consider a penalty distance that differentially penalizes underpricing and overpricing, of the form
<span class="math display">\[
d_*(S,c)=\alpha \mathbb{E}[(S-c)_+]+\beta\mathbb{E}[(c-S)_+].
\]</span>
For <span class="math inline">\(\alpha=\beta\)</span>, the average absolute deviation <span class="math inline">\(d_1\)</span> is obtained up to a factor, and minimizing <span class="math inline">\(d_*(S,c)\)</span> thus provides the median. If <span class="math inline">\(\alpha\neq\beta\)</span>, show that minimizing <span class="math inline">\(d_*(S,c)\)</span> leads to the <span class="math inline">\(\alpha/(\alpha+\beta)\)</span> quantile.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-89" class="exercise"><strong>Exercise 4.3  </strong></span>Show that
<span class="math display">\[
\mathbb{E}[X]=\mathbb{E}[1/r_X(X)].
\]</span></p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-90" class="exercise"><strong>Exercise 4.4  (IFR and DFR Distributions) </strong></span>When <span class="math inline">\(r_X\)</span> is decreasing (respectively increasing), <span class="math inline">\(F\)</span> is called a DFR (respectively IFR) distribution, standing for “Decreasing Failure Rate” (respectively “Increasing Failure Rate”). Clearly, a DFR claim distribution is less favorable for the insurer than an IFR distribution. Prove the following:</p>
<ol style="list-style-type: decimal">
<li>The cumulative distribution function <span class="math inline">\(F\)</span> of <span class="math inline">\(X\)</span> is IFR (respectively DFR) if, and only if, the inequality
<span class="math display">\[
\Pr[X-t_1&gt;x|X&gt;t_1]\geq\mbox{ (respectively} \leq)
\Pr[X-t_2&gt;x|X&gt;t_2],
\]</span>
holds for all <span class="math inline">\(x\in {\mathbb{R}}^+\)</span>, regardless of <span class="math inline">\(0\leq t_1\leq t_2\)</span>.</li>
<li>The cumulative distribution function <span class="math inline">\(F\)</span> of <span class="math inline">\(X\)</span> is IFR (respectively DFR) if, and only if,
<span class="math display">\[
y\mapsto\frac{\overline{F}(x+y)}{\overline{F}(y)}
\]</span>
is non-decreasing (respectively non-increasing) for any <span class="math inline">\(x\)</span>, meaning that <span class="math inline">\(y\mapsto\overline{F}(y)\)</span> is log-convex (respectively log-concave).</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-91" class="exercise"><strong>Exercise 4.5  (DFR Distributions and Exponential Mixtures) </strong></span>Show that all exponential mixtures are DFR distributions.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-92" class="exercise"><strong>Exercise 4.6  (Average Excess of Claims and Tail Function) </strong></span>Assuming that <span class="math inline">\(e_X(0)=\mathbb{E}[X]&lt;+\infty\)</span>, demonstrate that
<span class="math display">\[
\overline{F}_X(x)=\frac{e_X(0)}{e_X(x)}\exp\left(-\int_{\xi=0}^x\frac{1}{e_X(\xi)}d\xi\right).
\]</span></p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-93" class="exercise"><strong>Exercise 4.7  (IMRL and DMRL Distributions) </strong></span>When <span class="math inline">\(e_X\)</span> is increasing (respectively decreasing), <span class="math inline">\(F_X\)</span> is called an IMRL (respectively DMRL) distribution, standing for “Increasing Mean Residual Lifetime” (respectively “Decreasing Mean Residual Lifetime”). Prove the following implications:</p>
<ul>
<li><span class="math inline">\(F\)</span> is IFR <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(F\)</span> is DMRL;</li>
<li><span class="math inline">\(F\)</span> is DFR <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(F\)</span> is IMRL.</li>
</ul>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-94" class="exercise"><strong>Exercise 4.8  </strong></span>Show that a probability distribution whose hazard rate <span class="math inline">\(r_X\)</span> is completely monotone is a mixture of exponentials.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-95" class="exercise"><strong>Exercise 4.9  (Stop-Loss Premium and Variance) </strong></span>Show that for any risks <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> with the same mean <span class="math inline">\(\mu\)</span>,
<span class="math display" id="eq:EqSLVar">\[\begin{equation}
\int_{t=0}^{+\infty}\{\pi_X(t)-\pi_Y(t)\}dt=\frac{1}{2}\{\mathbb{V}[X]-\mathbb{V}[Y]\}.
\tag{4.25}
\end{equation}\]</span></p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-96" class="exercise"><strong>Exercise 4.10  </strong></span>Consider claim costs <span class="math inline">\(X_{0},X_{1},X_{2},\ldots\)</span>, assumed to be positive, continuous, independent, identically distributed according to the cumulative distribution function <span class="math inline">\(F\)</span>, and unbounded (i.e., <span class="math inline">\(F\left( x\right) &lt;1\)</span> for all <span class="math inline">\(x\)</span>). We want to determine when the next claim with a cost at least as high as <span class="math inline">\(X_0\)</span> will occur and the amount of this claim: let <span class="math inline">\(N\)</span> be the first integer such that <span class="math inline">\(X_{n}&gt;X_{0}\)</span>, and then set <span class="math inline">\(Y=X_{N}\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Show that <span class="math inline">\(\Pr[N=n]=\frac{1}{n(n+1)}\)</span>.</li>
<li>Deduce that <span class="math inline">\(\mathbb{E}[N]=+\infty\)</span> and interpret this result.</li>
<li>Show that
<span class="math display">\[
\Pr[Y&lt;x]=F(x)+\overline{F}(x)\ln\overline{F}(x).
\]</span></li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-97" class="exercise"><strong>Exercise 4.11  </strong></span>A large insurance company covers automobile liability risk. Two factors influence the claim amounts: the vehicle power (low-high) and the driver experience (novice-experienced). It is assumed that the insured population is evenly distributed among these categories (250,000 insured in each category). The average claim amounts according to risk profiles are given in the table below, <a href="#tabelow"><strong>??</strong></a>.</p>
<ol style="list-style-type: decimal">
<li>Let’s assume that only two companies, let’s say <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span>, operate on the market, and that insurance is compulsory. <span class="math inline">\(C_1\)</span> decides not to differentiate premiums (and charges 1250to all policyholders). The second company <span class="math inline">\(C_2\)</span> differentiates premiums on the basis of vehicle power. If information is perfect and policyholders systematically opt for the company with the most advantageous rate (meaning, among other things, that the scope of cover offered by <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span> is exactly the same), give the average results for <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span>. How should <span class="math inline">\(C_1\)</span> react?</li>
<li>Now let’s assume that <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span> apply a segmented tariff according to vehicle power. If a new company <span class="math inline">\(C_3\)</span> enters the market using driver experience to differentiate policyholders (regardless of vehicle power). How will the three companies fare? What will eventually happen in the market?</li>
</ol>
</div>
<table>
<thead>
<tr class="header">
<th align="center">Category</th>
<th align="center">Low.Power</th>
<th align="center">High.Power</th>
<th align="center">All.Vehicles</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Experienced</td>
<td align="center"><span class="math inline">\(100\)</span></td>
<td align="center"><span class="math inline">\(900\)</span></td>
<td align="center"><span class="math inline">\(500\)</span></td>
</tr>
<tr class="even">
<td align="center">Novice</td>
<td align="center"><span class="math inline">\(1,500\)</span></td>
<td align="center"><span class="math inline">\(2,500\)</span></td>
<td align="center"><span class="math inline">\(2,000\)</span></td>
</tr>
<tr class="odd">
<td align="center">All Drivers</td>
<td align="center"><span class="math inline">\(800\)</span></td>
<td align="center"><span class="math inline">\(1,700\)</span></td>
<td align="center"><span class="math inline">\(1,250\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="bibliographical-notes-1" class="section level2 hasAnchor" number="4.11">
<h2><span class="header-section-number">4.11</span> Bibliographical notes<a href="chap3.html#bibliographical-notes-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The non-life insurance basics presented in this chapter come mainly from <span class="citation">(<a href="#ref-beard1984risk" role="doc-biblioref">Beard and Pentikäinen 1984</a>)</span>, <span class="citation">(<a href="#ref-borch1990economics" role="doc-biblioref">Borch 1990</a>)</span>, <span class="citation">(<a href="#ref-buhlmann2007mathematical" role="doc-biblioref">Bühlmann 2007</a>)</span>,<span class="citation">(<a href="#ref-daykin1993practical" role="doc-biblioref">Daykin, Pentikainen, and Pesonen 1993</a>)</span>, <span class="citation">(<a href="#ref-gerber1979introduction" role="doc-biblioref">Gerber 1979</a>)</span>, <span class="citation">(<a href="#ref-kaas2001modern" role="doc-biblioref">Kaas et al. 2008</a>)</span>, <span class="citation">(<a href="#ref-petauton2000theorie" role="doc-biblioref">Pétauton 2000</a>)</span>,<span class="citation">(<a href="#ref-seal1969stochastic" role="doc-biblioref">Seal 1969</a>)</span>, <span class="citation">(<a href="#ref-straub1988non" role="doc-biblioref">Straub and Actuaries (Zürich) 1988</a>)</span>, <span class="citation">(<a href="#ref-sundt1999introduction" role="doc-biblioref">Sundt 1999</a>)</span> and <span class="citation">(<a href="#ref-tosetti2000assurance" role="doc-biblioref">Tosetti et al. 2000</a>)</span>. You can also consult <span class="citation">(<a href="#ref-booth2020modern" role="doc-biblioref">Booth et al. 2020</a>)</span> for an overview of insurance practice.</p>
<p>Poisson mixtures are presented very clearly in <span class="citation">(<a href="#ref-grandell1997mixed" role="doc-biblioref">Grandell 1997</a>)</span>.</p>
<p>The formalization of the segmentation concept proposed in Section <a href="chap3.html#DeWit">4.9.5</a> is inspired by <span class="citation">(<a href="#ref-de1984rate" role="doc-biblioref">De Wit and Van Eeghen 1984</a>)</span>.</p>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-beard1984risk" class="csl-entry">
Beard, Robert, and M. Pentikäinen T. And Pesonen. 1984. <em>Risk Theory: The Stochastic Basis of Insurance</em>. Springer.
</div>
<div id="ref-booth2020modern" class="csl-entry">
Booth, Philip, Robert Chadburn, Steven Haberman, Dewi James, Zaki Khorasanee, Robert H Plumb, and Ben Rickayzen. 2020. <em>Modern Actuarial Theory and Practice</em>. CRC Press.
</div>
<div id="ref-borch1990economics" class="csl-entry">
Borch, Karl. 1990. <em>Economics of Insurance</em>. Springer.
</div>
<div id="ref-buhlmann2007mathematical" class="csl-entry">
Bühlmann, Hans. 2007. <em>Mathematical Methods in Risk Theory</em>. Vol. 172. Springer.
</div>
<div id="ref-daykin1993practical" class="csl-entry">
Daykin, Chris D, Teivo Pentikainen, and Martti Pesonen. 1993. <em>Practical Risk Theory for Actuaries</em>. CRC Press.
</div>
<div id="ref-de1984rate" class="csl-entry">
De Wit, G Willem, and Jacob Van Eeghen. 1984. <span>“Rate Making and Society’s Sense of Fairness.”</span> <em>ASTIN Bulletin: The Journal of the IAA</em> 14 (2): 151–63.
</div>
<div id="ref-feller1950introduction" class="csl-entry">
Feller, William. 1950. <em>An Introduction to Probability Theory and Its Applications</em>. John Wiley &amp; Sons.
</div>
<div id="ref-gerber1979introduction" class="csl-entry">
Gerber, Hans. 1979. <em>An Introduction to Mathematical Risk Theory</em>. Huebner Foundation for Insurance Education.
</div>
<div id="ref-grandell1997mixed" class="csl-entry">
Grandell, Jan. 1997. <em>Mixed Poisson Processes</em>. Vol. 77. CRC Press.
</div>
<div id="ref-kaas2001modern" class="csl-entry">
Kaas, Rob, Marc Goovaerts, Jan Dhaene, and Michel Denuit. 2008. <em>Modern Actuarial Risk Theory: Using r</em>. Vol. 128. Springer.
</div>
<div id="ref-petauton2000theorie" class="csl-entry">
Pétauton, Pierre. 2000. <em>Th<span>é</span>orie de l’assurance Dommages</em>. Dunod.
</div>
<div id="ref-salanie1996theorie" class="csl-entry">
Salanié, Bernard. 1996. <em>Th<span>é</span>orie Des Contrats</em>. Economica.
</div>
<div id="ref-seal1969stochastic" class="csl-entry">
Seal, Hilary L. 1969. <em>Stochastic Theory of a Risk Business</em>. Wiley.
</div>
<div id="ref-shaked1980mixtures" class="csl-entry">
Shaked, M. 1980. <span>“On Mixtures from Exponential Families.”</span> <em>Journal of the Royal Statistical Society, Series B</em> 42: 192–98.
</div>
<div id="ref-straub1988non" class="csl-entry">
Straub, Erwin, and Swiss Association of Actuaries (Zürich). 1988. <em>Non-Life Insurance Mathematics</em>. Springer.
</div>
<div id="ref-sundt1999introduction" class="csl-entry">
Sundt, Bjørn. 1999. <em>An Introduction to Non-Life Insurance Mathematics</em>. Vol. 28. VVW GmbH.
</div>
<div id="ref-tosetti2000assurance" class="csl-entry">
Tosetti, Alain, Thomas Béhar, Michel Fromenteau, and Stéphane Ménart. 2000. <em>Assurance: Comptabilit<span>é</span> r<span>é</span>glementation Actuariat</em>. Economica.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chap2.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chap4.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-Pure-premium.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
